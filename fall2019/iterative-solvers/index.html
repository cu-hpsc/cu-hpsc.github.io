<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jed Brown">

  
  
  
    
  
  <meta name="description" content="Sparse and iterative linear algebra Many matrices in applications, particularly the study of physical systems and graphs/networks, have the property that most entries are zero. We can more efficiently store such systems by storing only the nonzero elements. We will discuss storage and optimized implementations later. Many of the methods for sparse systems apply to solving systems with matrices $A$ that can be applied to a vector ($y \gets A x$) in significantly less than $O(n^2)$ complexity, or that are &ldquo;well-conditioned&rdquo; such that an iterative method converges in significantly less than $n$ iterations.">

  
  <link rel="alternate" hreflang="en-us" href="https://cucs-hpsc.github.io/fall2019/iterative-solvers/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.dd629241ea9333c62c071f4a25f829ff.css">

  

  
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://cucs-hpsc.github.io/fall2019/iterative-solvers/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@five9a2">
  <meta property="twitter:creator" content="@five9a2">
  
  <meta property="og:site_name" content="HPSC">
  <meta property="og:url" content="https://cucs-hpsc.github.io/fall2019/iterative-solvers/">
  <meta property="og:title" content="Sparse and iterative linear algebra | HPSC">
  <meta property="og:description" content="Sparse and iterative linear algebra Many matrices in applications, particularly the study of physical systems and graphs/networks, have the property that most entries are zero. We can more efficiently store such systems by storing only the nonzero elements. We will discuss storage and optimized implementations later. Many of the methods for sparse systems apply to solving systems with matrices $A$ that can be applied to a vector ($y \gets A x$) in significantly less than $O(n^2)$ complexity, or that are &ldquo;well-conditioned&rdquo; such that an iterative method converges in significantly less than $n$ iterations."><meta property="og:image" content="https://cucs-hpsc.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://cucs-hpsc.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-10-09T06:49:25-06:00">
    
    <meta property="article:modified_time" content="2019-10-09T12:20:03-06:00">
  

  


  





  <title>Sparse and iterative linear algebra | HPSC</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">HPSC</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/fall2019/"><span>Fall 2019</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/">Logistics</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/syllabus/">Syllabus</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/intro-architecture/">Lecture Notes</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/intro-architecture/">2019-08-28 Architecture</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-vectorization/">2019-08-30 Vectorization</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-modeling/">2019-09-04 Modeling</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-parallel-scaling/">2019-09-06 Parallel Scaling</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp/">2019-09-11 OpenMP Basics</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-2/">2019-09-13 More OpenMP</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-3/">2019-09-16 OpenMP Tasks</a>
      </li>
      
      <li >
        <a href="/fall2019/strategies/">2019-09-18 Reductions and Scans</a>
      </li>
      
      <li >
        <a href="/fall2019/sorting-graphs/">2019-09-23 More bitonic sorting, graphs</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-mpi/">2019-09-24 Introduction to MPI</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg/">2019-09-30 Dense Linear Algebra</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-2/">2019-10-02 Dense Linear Algebra and Orthogonality</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-3/">2019-10-04 Orthogonality and Conditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/elemental/">2019-10-07 Elemental</a>
      </li>
      
      <li class="active">
        <a href="/fall2019/iterative-solvers/">2019-10-09 Sparse and Iterative</a>
      </li>
      
      <li >
        <a href="/fall2019/preconditioning/">2019-10-11 Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning/">2019-10-14 DD Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning-2/">2019-10-16 DD Preconditioning 2</a>
      </li>
      
      <li >
        <a href="/fall2019/mg-preconditioning/">2019-10-18 Multilevel Preconditioning</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/trends/">Resources</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/trends/">Trends</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
<ul>
<li><a href="#sparse-and-iterative-linear-algebra">Sparse and iterative linear algebra</a>
<ul>
<li><a href="#direct-solves">Direct solves</a>
<ul>
<li>
<ul>
<li><a href="#costs-for-banded-solves">Costs for banded solves</a></li>
</ul></li>
<li><a href="#nested-dissection">Nested dissection</a>
<ul>
<li><a href="#costs-for-nested-dissection">Costs for nested dissection</a></li>
</ul></li>
</ul></li>
<li><a href="#convergence-of-stationary-iterative-methods">Convergence of stationary iterative methods</a>
<ul>
<li><a href="#richardson-iteration">Richardson iteration</a></li>
<li><a href="#preconditioning">Preconditioning</a></li>
</ul></li>
</ul></li>
<li><a href="#krylov-subspaces">Krylov subspaces</a>
<ul>
<li>
<ul>
<li><a href="#arnoldi-iteration">Arnoldi iteration</a>
<ul>
<li><a href="#conditioning">Conditioning</a></li>
<li><a href="#gmres">GMRES</a></li>
</ul></li>
<li><a href="#lanczos-iteration-the-symmetric-case">Lanczos iteration: the symmetric case</a>
<ul>
<li><a href="#conjugate-gradients">Conjugate Gradients</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Sparse and iterative linear algebra</h1>

          <div class="article-style" itemprop="articleBody">
            

<h1 id="sparse-and-iterative-linear-algebra">Sparse and iterative linear algebra</h1>

<p>Many matrices in applications, particularly the study of physical systems and graphs/networks, have the property that most entries are zero.  We can more efficiently store such systems by storing only the nonzero elements.  We will discuss storage and optimized implementations later.  Many of the methods for sparse systems apply to solving systems with matrices $A$ that can be applied to a vector ($y \gets A x$) in significantly less than $O(n^2)$ complexity, or that are &ldquo;well-conditioned&rdquo; such that an iterative method converges in significantly less than $n$ iterations.</p>

<p><a href="https://mcs.anl.gov/petsc" target="_blank">PETSc</a>, the Portable Extensible Toolkit for Scientific computing, is an open source software package for the parallel solution of algebraic and differential-algebraic equations.  This includes linear algebra, for which PETSc offers a broad variety of implementations.  For general information about PETSc, I refer to <a href="https://jedbrown.org/files/20150924-PETScPrimer.pdf" target="_blank">this primer</a>.</p>

<h2 id="direct-solves">Direct solves</h2>

<p>The complexity of this solve is potentially dominant, so we should understand its cost in terms of the problem size.  The standard method for a direct solve is $LU$ (or Cholesky) factorization.  Given a $2\times 2$ block matrix, the algorithm proceeds as
\begin{split}
  \begin{bmatrix} A &amp; B \ C &amp; D \end{bmatrix} &amp;=
  \begin{bmatrix} L_A &amp; \ C U_A^{-1} &amp; S \end{bmatrix}
  \begin{bmatrix} U_A &amp; L_A^{-1} B \ &amp; 1 \end{bmatrix}
\end{split}
where $L_A U_A = A$ and $S = D - C A^{-1} B$.  The factorization continues by factoring the Schur complement, which may be more dense than its original entries $D$.</p>

<p>For a sparse operator, the complexity depends on the ordering of degrees of freedom.</p>

<ul>
<li>&ldquo;natural&rdquo; ordering</li>
<li>low-bandwidth ordering</li>
<li>nested dissection ordering</li>
</ul>

<p>For a structured grid, the &ldquo;natural&rdquo; ordering is the ordering of the original operator.</p>

<p><img src="sparse-natural.png" alt="Original operator in the natural ordering" /></p>

<p>The red values represent positive entries, blue negative, and cyan stored zeros.</p>

<p>A sparse direct solve of this system will result in fill up to the bandwidth (showing lower triangular factor here).</p>

<p><img src="factor-natural.png" alt="Fill in natural ordering" /></p>

<p>These plots can be produced in PETSc using <code>-mat_view draw</code> and <code>-pc_type lu -pc_factor_mat_ordering_type natural -mat_factor_view draw</code> (e.g., with <code>-draw_pause 2</code> to wait 2 seconds for the viewer).</p>

<p>The Reverse Cuthill-McKee (<code>rcm</code>) ordering applies a breadth-first search to produce a low-bandwidth ordering.</p>

<p><img src="factor-rcm.png" alt="Fill in RCM ordering" /></p>

<h4 id="costs-for-banded-solves">Costs for banded solves</h4>

<p>Suppose we have a grid containing $N = n^d$ points in $d$ dimensions.  The corresponding matrix is $N\times N$.  The furthest band is $k = n^{d-1}$ off the diagonal, and factorization creates
* Space: $kN = n^{2d-1} = N^{2-1/d}$
* Compute: $k^2N = n^{3d-2} = N^{3-2/d}$</p>

<h3 id="nested-dissection">Nested dissection</h3>

<p>The nested dissection (<code>nd</code>) ordering recursively bisects the domain by finding vertex separators.</p>

<p><img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Grid_separator.svg" alt="" /></p>

<p>The separator is ordered last so that each side can be factored independently.  That factorization is done by recursive bisection.  The Schur complement $S$ on the vertex separator is dense, and its factorization dominates the cost.</p>

<p><img src="factor-nd.png" alt="Fill in ND ordering" /></p>

<h4 id="costs-for-nested-dissection">Costs for nested dissection</h4>

<p>The size of the vertex separator is $n^{d-1}$ so its factorization costs $n^{3(d-1)}$.  This leads to
* $d=3$
  * Space: $N^{<sup>4</sup>&frasl;<sub>3</sub>}$
  * Time: $N^2$
* $d=2$
  * Space: $N \log N$
  * Time: $N^{<sup>3</sup>&frasl;<sub>2</sub>}$</p>

<h2 id="convergence-of-stationary-iterative-methods">Convergence of stationary iterative methods</h2>

<h3 id="richardson-iteration">Richardson iteration</h3>

<p>The simplest iterative method is <a href="https://en.wikipedia.org/wiki/Modified_Richardson_iteration" target="_blank">Richardson&rsquo;s method</a>, which solves $A x = b$ by the iteration
$$ x_{k+1} = x_k + \omega (b - A x_k) $$
where $\omega &gt; 0$ is a damping parameter and $x<em>0$ is an initial guess (possibly the zero vector).  If $b = A x</em><em>$, this iteration is equivalent to
$$ x<em>{k+1} - x</em></em> = (x<em>k - x</em><em>) - \omega A (x<em>k - x</em></em>) = (I - \omega A) (x<em>k - x</em><em>) .$$
It is convenient for convergence analysis to identify the &ldquo;error&rdquo; $e_k = x<em>k - x</em></em>$, in which this becomes
$$ e_{k+1} = (I - \omega A) e_k $$
or
$$ e_k = (I - \omega A)^k e_0 $$
in terms of the initial error.  Evidently powers of the <em>iteration matrix</em> $I - \omega A$ tell the whole story.
Suppose that the eigendecomposition
$$ X \Lambda X^{-1} = I - \omega A $$
exists.  Then
$$ (I - \omega A)^k = (X \Lambda X^{-1})^k = X \Lambda^k X^{-1} $$
and the convergence (or divergence) rate depends only on the largest magnitude eigenvalue.
This analysis isn&rsquo;t great for two reasons:</p>

<ol>
<li>Not all matrices are diagonalizable.</li>
<li>The matrix $X$ may be very ill-conditioned.</li>
</ol>

<p>We can repair these weaknesses by using the <a href="https://en.wikipedia.org/wiki/Schur_decomposition" target="_blank">Schur decomposition</a>
$$ Q R Q^h = I - \omega A $$
where $R$ is right-triangular and $Q$ is unitary (i.e., orthogonal if real-valued; $Q^h$ is the Hermitian conjugate of $Q$).
The Schur decomposition always exists and $Q$ has a condition number of 1.</p>

<ul>
<li>Where are the eigenvalues in $R$?</li>
</ul>

<p>Evidently we must find $\omega$ to minimize the maximum eigenvalue of $I - \omega A$.  We can do this if $A$ is well conditioned, but not in general.</p>

<h3 id="preconditioning">Preconditioning</h3>

<p>Preconditioning is the act of creating an &ldquo;affordable&rdquo; operation &ldquo;$P^{-1}$&rdquo; such that $P^{-1} A$ (or $A P^{-1}$) is is well-conditoned or otherwise has a &ldquo;nice&rdquo; spectrum.  We then solve the system</p>

<p>$$ P^{-1} A x = P^{-1} b \quad \text{or}\quad A P^{-1} \underbrace{(P x)}_y = b $$</p>

<p>in which case the convergence rate depends on the spectrum of the iteration matrix
$$ I - \omega P^{-1} A . $$</p>

<ul>
<li>The preconditioner must be applied on each iteration.</li>
<li>It is <em>not</em> merely about finding a good initial guess.</li>
</ul>

<p>There are two complementary techniques necessary for efficient iterative methods:</p>

<ul>
<li>&ldquo;accelerators&rdquo; or Krylov methods, which use orthogonality to adaptively converge faster than Richardson</li>
<li>preconditioners that improve the spectrum of the preconditioned operator</li>
</ul>

<p>Although there is ongoing research in Krylov methods and they are immensely useful, I would say preconditioning is 90% of the game for practical applications, particularly as a research area.</p>

<h1 id="krylov-subspaces">Krylov subspaces</h1>

<p>All matrix iterations work with approximations in a <em>Krylov subspace</em>, which has the form</p>

<p>$$ K_n = \big[ b \big| Ab \big| A^2 b \big| \dotsm \big| A^{n-1} b \big] . $$</p>

<p>This matrix is horribly ill-conditioned and cannot stably be computed as written.  Instead, we seek an orthogonal basis $Q_n$ that spans the same space as $K_n$.  We could write this as a factorization</p>

<p>$$ K_n = Q_n R_n $$</p>

<p>where the first column $q_0 = b / \lVert b \rVert$.  The $R_n$ is unnecessary and hopelessly ill-conditioned, so a slightly different procedure is used.</p>

<h3 id="arnoldi-iteration">Arnoldi iteration</h3>

<p>The Arnoldi iteration applies orthogonal similarity transformations to reduce $A$ to <a href="https://en.wikipedia.org/wiki/Hessenberg_matrix" target="_blank">Hessenberg form</a>, starting from a vector $q_0 = b$,</p>

<p>$$ A = Q H Q^h . $$</p>

<p>Let&rsquo;s multiply on the right by $Q$ and examine the first $n$ columns,</p>

<p>$$ A Q<em>n = Q</em>{n+1} H_n $$
where $H_n$ is an $(n+1) \times n$ Hessenberg matrix.</p>

<h4 id="conditioning">Conditioning</h4>

<p>This representation is well-conditioned because $Q$ is orthogonal and</p>

<p>$$ \lVert H<em>n \rVert \le \lVert Q</em>{n+1}^h \rVert \lVert A \rVert \lVert Q_n \rVert \le \lVert A \rVert $$.</p>

<p>For a lower bound, we have</p>

<p>$$ \sigma_{\min}(A)^2 \le x^h A^h A x $$</p>

<p>for all $x$ of norm 1.  It must also be true for any $x = Q_n y$ where $\lVert y\rVert = 1$, thus</p>

<p>$$ \sigma_{\min}(A)^2 \le y^h Q_n^h A^h A Q_n y = y^h H<em>n^h Q</em>{n+1}^h Q_{n+1} H_n y = y^h H_n^h H_n y . $$</p>

<h4 id="gmres">GMRES</h4>

<p>GMRES (Generalized Minimum Residual) minimizes
$$ \lVert A x - b \rVert $$
over the subspace $Q_n$.  I.e., $x = Q<em>n y$ for some $y$.  By the recurrence above, this is equivalent to
$$ \lVert Q</em>{n+1} H_n y - b \lVert $$
which can be solved by minimizing
$$ \lVert H<em>n y - Q</em>{n+1}^h b \rVert . $$
Since $q_0 = b/\lVert b \lVert$, the least squares problem is to minimize
$$ \Big\lVert H_n y - \lVert b \rVert e_0 \Big\rVert . $$
The solution of this least squares problem is achieved by incrementally updating a $QR$ factorization of $H_n$.</p>

<p><strong>Notes</strong></p>

<ul>
<li>GMRES minimizes the 2-norm of the residual $\lVert r_n \rVert$ which is equivalent to the $A^T A$ norm of the error $\lVert x<em>n - x</em>* \rVert_{A^T A}$.</li>
<li>The solution $x_n$ constructed by GMRES at iteration $n$ is not explicitly available.  If a solution is needed, it must be constructed by solving the $(n+1)\times n$ least squares problem and forming the solution as a linear combination of the $n$ vectors $Q_n$.  The leading cost is $2mn$ where $m \gg n$.</li>
<li>The residual vector $r_n = A x_n - b$ is not explicitly available in GMRES.  To compute it, first build the solution $x_n$ as above.</li>
<li>GMRES needs to store the full $Q_n$, which is unaffordable for large $n$ (many iterations).  The standard solution is to choose a &ldquo;restart&rdquo; $k$ and to discard $Q_n$ and start over with an initial guess $x_k$ after each $k$ iterations.  This algorithm is called GMRES(k).  PETSc&rsquo;s default solver is GMRES(30) and the restart can be controlled using the run-time option <code>-ksp_gmres_restart</code>.</li>
<li>Most implementations of GMRES use classical Gram-Schmidt because it is much faster in parallel (one reduction per iteration instead of $n$ reductions per iteration).  The PETSc option <code>-ksp_gmres_modifiedgramschmidt</code> can be used when you suspect that classical Gram-Schmidt may be causing instability.</li>
<li>There is a very similar (and older) algorithm called GCR that maintains $x_n$ and $r_n$.  This is useful, for example, if a convergence tolerance needs to inspect individual entries.  GCR requires $2n$ vectors instead of $n$ vectors, and can tolerate a nonlinear preconditioner.  FGMRES is a newer algorithm with similar properties to GCR.</li>
</ul>

<h3 id="lanczos-iteration-the-symmetric-case">Lanczos iteration: the symmetric case</h3>

<p>If $A$ is symmetric, then $H = Q^T A Q$ is also symmetric.  Since $H$ is Hessenberg, this means $H$ is tridiagonal.  Instead of storing $Q_n$, it is sufficient to store only the last two columns since the iteration satisfies a 3-term recurrence.  The analog of GMRES for the symmetric case is called MINRES and is also useful for solving symmetric indefinite problems.</p>

<h4 id="conjugate-gradients">Conjugate Gradients</h4>

<p>Instead of minimizing the $A^T A$ norm of the error, the Conjugate Gradient method minimizes the $A$ norm of the error.  For $A$ to induce a norm, it must be symmetric positive definite.  <a href="http://www.cs.cmu.edu/%7Equake-papers/painless-conjugate-gradient.pdf" target="_blank">Jeremy Shewchuck&rsquo;s guide to CG</a> is an excellent resource.</p>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/fall2019/preconditioning/" rel="next">Preconditioning</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/fall2019/elemental/" rel="prev">Elemental for distributed dense linear algebra</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Oct 9, 2019</p>

          
<p class="edit-page">
  <a href="https://github.com/cucs-hpsc/hpsc-class/edit/master/content/fall2019/iterative-solvers/index.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>



          

        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/c.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
