<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Logistics | HPSC</title>
    <link>https://cucs-hpsc.github.io/fall2019/</link>
      <atom:link href="https://cucs-hpsc.github.io/fall2019/index.xml" rel="self" type="application/rss+xml" />
    <description>Logistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://cucs-hpsc.github.io/img/icon-192.png</url>
      <title>Logistics</title>
      <link>https://cucs-hpsc.github.io/fall2019/</link>
    </image>
    
    <item>
      <title>Syllabus</title>
      <link>https://cucs-hpsc.github.io/fall2019/syllabus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/syllabus/</guid>
      <description>

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;This course will develop the skills necessary to reason about
performance of applications and modern architectures, to identify
opportunities and side-effects of changes, to develop high-performance
software, to transfer algorithmic patterns and lessons learned from
different domains, and to communicate such analyses with diverse
stakeholders.  These skills are important for research and development
of numerical methods and performance-sensitive science and engineering
applications, obtaining allocations via NSF&amp;rsquo;s
&lt;a href=&#34;https://www.xsede.org/&#34; target=&#34;_blank&#34;&gt;XSEDE&lt;/a&gt; and DOE &lt;a href=&#34;https://science.osti.gov/ascr/Facilities/Accessing-ASCR-Facilities&#34; target=&#34;_blank&#34;&gt;ASCR
facilities&lt;/a&gt;,
as well as in jobs affiliated with computing facilities at &lt;a href=&#34;https://www.alcf.anl.gov/about/careers&#34; target=&#34;_blank&#34;&gt;national
labs&lt;/a&gt;, industry, and academia.&lt;/p&gt;

&lt;p&gt;We will introduce widely-used parallel programming models such as
OpenMP, MPI, and CUDA, as well as ubiquitous parallel libraries, but
the purpose of the course is not to teach interfaces, but to develop
skills that will be durable and transferrable.&lt;/p&gt;

&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;

&lt;p&gt;This course does not assume prior experience with parallel
programming.  It will use Linux command-line tools, and some
activities will involve batch computing environments (SLURM).  Most
exercises will use the C programming language, though you can use any
appropriate language for projects.  Some of the exercises will involve
techniques from numerical computing (e.g., CSCI-3656).  I will do my
best to avoid assuming prior knowledge of these topics, and to provide
resources for you to learn or refresh your memory as we use them.&lt;/p&gt;

&lt;p&gt;Everyone here is capable of succeeding in the course, but the effort
level will be higher if most of the topics above are new to you.
Regardless of your preparation, it is normal to feel lost sometimes.
A big part of pragmatic HPC is learning to efficiently answer your
questions through documentation, online resources, and even consulting
the code or running experiments.  (Most of our software stack is open
source.)  That said, it&amp;rsquo;s easy to lose lots of time in a rabbit hole.
My hope is that you will have the courage to dive into that rabbit
hole occasionally, but also to &lt;a href=&#34;https://jvns.ca/blog/good-questions/&#34; target=&#34;_blank&#34;&gt;ask questions&lt;/a&gt; when stuck and to budget
your time for such excursions so that you can complete assignments
on-time without compromising your work/life balance.&lt;/p&gt;

&lt;h2 id=&#34;approximate-timeline&#34;&gt;Approximate timeline&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Week&lt;/th&gt;
&lt;th&gt;Topics&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Aug 26&lt;/td&gt;
&lt;td&gt;Introduction and modern computer architecture (vectorization and memory hierarchy)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 2&lt;/td&gt;
&lt;td&gt;Performance modeling, analysis, and scaling; profiling&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 9&lt;/td&gt;
&lt;td&gt;Intro to OpenMP and non-numerical algorithms (sorting and searching)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 16&lt;/td&gt;
&lt;td&gt;Parallel algorithmic patterns&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 23&lt;/td&gt;
&lt;td&gt;Dense linear algebra&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 30&lt;/td&gt;
&lt;td&gt;Intro to MPI and distributed memory parallelism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 7&lt;/td&gt;
&lt;td&gt;Sparse and iterative linear algebra&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 14&lt;/td&gt;
&lt;td&gt;Domain decomposition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 21&lt;/td&gt;
&lt;td&gt;Graph algorithms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 28&lt;/td&gt;
&lt;td&gt;GPU programming via OpenMP-5 and CUDA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 4&lt;/td&gt;
&lt;td&gt;Parallel file systems and IO&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 11&lt;/td&gt;
&lt;td&gt;Data analysis/machine learning algorithms and dynamic cloud environments&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 18&lt;/td&gt;
&lt;td&gt;Particles and N-body systems&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 25&lt;/td&gt;
&lt;td&gt;Fall Break&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Dec 2&lt;/td&gt;
&lt;td&gt;Multigrid, FFT, and FMM&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Dec 9&lt;/td&gt;
&lt;td&gt;Special topics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Activity&lt;/th&gt;
&lt;th&gt;Percentage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Participation&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Labs and homework assignments&lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Community contribution&lt;/td&gt;
&lt;td&gt;15%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Community analysis&lt;/td&gt;
&lt;td&gt;15%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Final project (written + presentation)&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;git-and-github&#34;&gt;Git and GitHub&lt;/h3&gt;

&lt;p&gt;Homework assignments and in-class activities will be submitted via Git.  This class will use GitHub classroom.
Homeworks will be completed by cloning GitHub repositories, completing coding and analysis activities, and pushing completed assignments back to GitHub.&lt;/p&gt;

&lt;p&gt;Assignments may be completed using &lt;a href=&#34;https://coding.csel.io/&#34; target=&#34;_blank&#34;&gt;Coding CSEL Hub&lt;/a&gt; and/or &lt;a href=&#34;https://www.colorado.edu/rc/resources/summit/specifications&#34; target=&#34;_blank&#34;&gt;RMACC Summit&lt;/a&gt; (&lt;a href=&#34;https://rcamp.rc.colorado.edu/accounts/account-request/create/organization&#34; target=&#34;_blank&#34;&gt;request an account&lt;/a&gt;).
Assignments will typically have written analysis, for which I recommend &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34;&gt;Jupyter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is notoriously difficult to predict the time required to develop
quality code and understand its performance, so please start early to
give yourself plenty of time.  You are welcome to work together on all
assignments, but must acknowledge collaborators.  You should ensure
that your written work is entirely your own.&lt;/p&gt;

&lt;h3 id=&#34;community-contributions-and-analysis&#34;&gt;Community contributions and analysis&lt;/h3&gt;

&lt;p&gt;Over the course of the semester, you will follow the development
activities of an active open source project of your choosing.  This
should be a project with an active developer community from multiple
institutions that discuss their rationale in public, such as a mailing
list and/or GitHub/GitLab issues and pull requests.  You will write
and present about the performance and capability needs of key
stakeholders, the way project resources are allocated, their metrics
for success, and any notable achievements made over the course of the
semester.&lt;/p&gt;

&lt;p&gt;You will also make a contribution to be merged by the project.  Adding
new examples and/or improving documentation are extremely valuable
contributions, but you may also add features or improve
implementations.  Please respect the time of project maintainers and
reviewers by learning about the project and its expectations and
process, communicating in advance if appropriate, and leaving plenty
of time for multiple rounds of review and revision.&lt;/p&gt;

&lt;h3 id=&#34;distance-sections-and-labs&#34;&gt;Distance sections and labs&lt;/h3&gt;

&lt;p&gt;The lectures for this class can be joined synchronously via Zoom (see
&lt;a href=&#34;fall2019/&#34; target=&#34;_blank&#34;&gt;instructions&lt;/a&gt;); they are also recorded and will be posted
&lt;a href=&#34;fall2019/#videos&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; (and automatically on Canvas).  Some labs
will be activities that can be completed within the time period (with
group discussion and compare/contrast) while others will be a jump
start for homeworks.  I envision that distance students will form
groups and set a time for virtual discussion in lieu of synchronous
discussion during the lab period.  In both settings, there will be a
peer evaluation component during which each participant credits one or
more peers with some specific contributions to the conversation.&lt;/p&gt;

&lt;h2 id=&#34;moodle&#34;&gt;Moodle&lt;/h2&gt;

&lt;p&gt;Moodle will be used to maintain grades.  Please enroll yourself at &lt;a href=&#34;https://moodle.cs.colorado.edu&#34; target=&#34;_blank&#34;&gt;https://moodle.cs.colorado.edu&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;

&lt;p&gt;This course will use a variety of online resources and papers.
There is no required textbook, but the following resources may be helpful.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/hpc-book&#34; target=&#34;_blank&#34;&gt;Hager and Wellein (2010), &lt;strong&gt;Introduction to High Performance Computing for Scientists and Engineers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.utexas.edu/users/flame/laff/pfhp/index.html&#34; target=&#34;_blank&#34;&gt;van de Geijn, Myers, Parikh (2019): &lt;strong&gt;LAFF on Programming for High Performance&lt;/strong&gt;&lt;/a&gt; (free online)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://pages.tacc.utexas.edu/~eijkhout/istc/istc.html&#34; target=&#34;_blank&#34;&gt;Eijkhout, Chow, van de Geijn (2017), &lt;strong&gt;Introduction to High-Performance Scientific Computing&lt;/strong&gt;&lt;/a&gt; (free PDF)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/&#34; target=&#34;_blank&#34;&gt;Grama, Gupta, Karypis, Kumar (2003), &lt;strong&gt;Introduction to Parallel Computing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;additional-resources&#34;&gt;Additional resources&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://press.princeton.edu/titles/9763.html&#34; target=&#34;_blank&#34;&gt;Greenbaum and Chartier (2012), &lt;strong&gt;Numerical Methods Design, Analysis, and Computer Implementation of Algorithms&lt;/strong&gt;&lt;/a&gt; &amp;ndash; an excellent, comprehensive book.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/~boyd/vmls/&#34; target=&#34;_blank&#34;&gt;Boyd and Vandenberghe (2018), &lt;strong&gt;Introduction to Applied Linear Algebra&lt;/strong&gt;&lt;/a&gt; &amp;ndash; practical introduction to linear algebra for computer scientists; free PDF&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://bookstore.siam.org/ot50/&#34; target=&#34;_blank&#34;&gt;Trefethen and Bau (1997), &lt;strong&gt;Numerical Linear Algebra&lt;/strong&gt;&lt;/a&gt; &amp;ndash; fantastic, but limited to numerical linear algebra and covers more advanced topics.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://physics.codes/&#34; target=&#34;_blank&#34;&gt;Scopatz and Huff (2015), &lt;strong&gt;Effective Computation in Physics&lt;/strong&gt;&lt;/a&gt; &amp;ndash; Python language, data science workflow, and computation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&#34;http://www.siam.org/students/memberships.php&#34; target=&#34;_blank&#34;&gt;SIAM Membership&lt;/a&gt; is free for CU students and provides a 30% discount on SIAM books.&lt;/p&gt;

&lt;h2 id=&#34;disability-accommodations&#34;&gt;Disability Accommodations&lt;/h2&gt;

&lt;p&gt;If you qualify for accommodations because of a disability, please submit to your professor a letter from Disability Services in a timely manner (for exam accommodations provide your letter at least one week prior to the exam) so that your needs can be addressed. Disability Services determines accommodations based on documented disabilities. Contact Disability Services at 303-492-8671 or by e-mail at dsinfo@colorado.edu. If you have a temporary medical condition or injury, see the Temporary Injuries guidelines under the Quick Links at the Disability Services website and discuss your needs with your professor.&lt;/p&gt;

&lt;h2 id=&#34;religious-observances&#34;&gt;Religious Observances&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.colorado.edu/policies/fac_relig.html&#34; target=&#34;_blank&#34;&gt;Campus policy regarding religious observances&lt;/a&gt; requires that faculty make every effort to deal reasonably and fairly with all students who, because of religious obligations, have conflicts with scheduled exams, assignments or required assignments/attendance. If this applies to you, please speak with me directly as soon as possible at the beginning of the term. See the &lt;a href=&#34;http://www.colorado.edu/policies/observance-religious-holidays-and-absences-classes-andor-exams&#34; target=&#34;_blank&#34;&gt;campus policy regarding religious observances&lt;/a&gt; for full details.&lt;/p&gt;

&lt;h2 id=&#34;classroom-behavior&#34;&gt;Classroom Behavior&lt;/h2&gt;

&lt;p&gt;Students and faculty each have responsibility for maintaining an appropriate learning environment. Those who fail to adhere to such behavioral standards may be subject to discipline. Professional courtesy and sensitivity are especially important with respect to individuals and topics dealing with differences of race, color, culture, religion, creed, politics, veteran&amp;rsquo;s status, sexual orientation, gender, gender identity and gender expression, age, disability,and nationalities. Class rosters are provided to the instructor with the student&amp;rsquo;s legal name. I will gladly honor your request to address you by an alternate name or gender pronoun. Please advise me of this preference early in the semester so that I may make appropriate changes to my records. For more information, see the policies on &lt;a href=&#34;http://www.colorado.edu/policies/student-classroom-and-course-related-behavior&#34; target=&#34;_blank&#34;&gt;classroom behavior&lt;/a&gt; and the &lt;a href=&#34;http://www.colorado.edu/osc/sites/default/files/attached-files/studentconductcode_16-17-a.pdf&#34; target=&#34;_blank&#34;&gt;student code&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;discrimination-and-harassment&#34;&gt;Discrimination and Harassment&lt;/h2&gt;

&lt;p&gt;The University of Colorado Boulder (CU Boulder) is committed to maintaining a positive learning, working, and living environment. CU Boulder will not tolerate acts of sexual misconduct, discrimination, harassment or related retaliation against or by any employee or student. CU&amp;rsquo;s Sexual Misconduct Policy prohibits sexual assault, sexual exploitation, sexual harassment,intimate partner abuse (dating or domestic violence), stalking or related retaliation. CU Boulder&amp;rsquo;s Discrimination and Harassment Policy prohibits discrimination, harassment or related retaliation based on race, color,national origin, sex, pregnancy, age, disability, creed, religion, sexual orientation, gender identity, gender expression, veteran status, political affiliation or political philosophy. Individuals who believe they have been subject to misconduct under either policy should contact the Office of Institutional Equity and Compliance (OIEC) at 303-492-2127. Information about the OIEC, the above referenced policies, and the campus resources available to assist individuals regarding sexual misconduct, discrimination, harassment or related retaliation can be found at the &lt;a href=&#34;http://www.colorado.edu/institutionalequity/&#34; target=&#34;_blank&#34;&gt;OIEC website&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;honor-code&#34;&gt;Honor Code&lt;/h2&gt;

&lt;p&gt;All students enrolled in a University of Colorado Boulder course are responsible for knowing and adhering to the &lt;a href=&#34;http://www.colorado.edu/policies/academic-integrity-policy&#34; target=&#34;_blank&#34;&gt;academic integrity policy&lt;/a&gt; of the institution. Violations of the policy may include: plagiarism, cheating,fabrication, lying, bribery, threat, unauthorized access, clicker fraud,resubmission, and aiding academic dishonesty.  All incidents of academic misconduct will be reported to the Honor Code Council (honor@colorado.edu; 303-735-2273). Students who are found responsible for violating the academic integrity policy will be subject to nonacademic sanctions from the Honor Code Council as well as academic sanctions from the faculty member. Additional information regarding the academic integrity policy can be found at &lt;a href=&#34;http://honorcode.colorado.edu&#34; target=&#34;_blank&#34;&gt;http://honorcode.colorado.edu&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Git Workflows</title>
      <link>https://cucs-hpsc.github.io/fall2019/git/</link>
      <pubDate>Mon, 02 Dec 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/git/</guid>
      <description>

&lt;h2 id=&#34;project-roles&#34;&gt;Project roles&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Users&lt;/strong&gt; stress features, report issues, ask questions that steer project.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Developers&lt;/strong&gt; fix bugs and create features. They write code and docs and generally are agents of change in a software project. There are often many more developers than reviewers or maintainers.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reviewers&lt;/strong&gt; are known experts in a part of a project and are called on to review the work of developers, mostly to make sure that the developers donâ€™t break anything, but also to point them to related work, ensure common development practices, and pass on institutional knowledge. There are often more developers than reviewers, and more reviewers than maintainers.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;strong&gt;Maintainers&lt;/strong&gt; are loosely aware of the entire project. They track ongoing work and make sure that it gets reviewed and merged in a timely manner. They direct the orchestra of developers and reviewers, making sure that they connect to each other appropriately, often serving as dispatcher.&lt;/p&gt;

&lt;p&gt;Maintainers also have final responsibility. If no reviewer can be found for an important contribution, they review. If no developer can be found to fix an important bug, they develop. If something goes wrong, itâ€™s eventually the maintainerâ€™s fault.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&amp;ndash; &lt;a href=&#34;https://matthewrocklin.com/blog//2019/05/18/maintainer&#34; target=&#34;_blank&#34;&gt;Rocklin: The Role of a Maintainer&lt;/a&gt;&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Each change has to be reviewed. &lt;strong&gt;This is the single biggest cost.&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;ndash; &lt;a href=&#34;https://rgommers.github.io/2019/06/the-cost-of-an-open-source-contribution/&#34; target=&#34;_blank&#34;&gt;Gommers: The cost of an open source contribution&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;principles-of-git-workflows&#34;&gt;Principles of Git workflows&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Reviewable

&lt;ul&gt;
&lt;li&gt;Prioritize time and accuracy for reviewers&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Testable

&lt;ul&gt;
&lt;li&gt;Untested code is usually broken&lt;/li&gt;
&lt;li&gt;Reviewing broken code is a waste of time&lt;/li&gt;
&lt;li&gt;Exception: &amp;ldquo;request for comment&amp;rdquo; (RFC) commits sketch an idea for discussion; will be revised before review/merging&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Atomic_commit#Atomic_commit_convention&#34; target=&#34;_blank&#34;&gt;Atomic&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://google.github.io/eng-practices/review/developer/small-cls.html&#34; target=&#34;_blank&#34;&gt;Small commits&lt;/a&gt; are easier to understand and make bug-free&lt;/li&gt;
&lt;li&gt;Also easier to revert&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://git-scm.com/docs/git-bisect&#34; target=&#34;_blank&#34;&gt;Bisectable&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Test suites are always incomplete&lt;/li&gt;
&lt;li&gt;When we learn about a bug&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Stable &lt;code&gt;master&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;Bugs in &lt;code&gt;master&lt;/code&gt; are highly disruptive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Minimize dependencies

&lt;ul&gt;
&lt;li&gt;Deliver the bug-fix and nothing but the bug-fix&lt;/li&gt;
&lt;li&gt;To anyone who has the bug&lt;/li&gt;
&lt;li&gt;Deliver the feature and nothing but the feature&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;examples&#34;&gt;Examples&lt;/h2&gt;

&lt;h3 id=&#34;gitworkflows-7-https-git-scm-com-docs-gitworkflows&#34;&gt;&lt;a href=&#34;https://git-scm.com/docs/gitworkflows&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;gitworkflows(7)&lt;/code&gt;&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;simplified-gitworkflows7.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;inspecting-history-in-the-git-project&#34;&gt;Inspecting history in the Git project&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! git -C ~/src/git log -20 --graph --decorate --pretty=oneline --abbrev-commit
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* [33m228f53135a[m[33m ([m[1;36mHEAD -&amp;gt; [m[1;32mmaster[m[33m, [m[1;31mgitster/master[m[33m)[m The second batch
*   [33m6c630f237e[m Merge branch &#39;jk/gitweb-anti-xss&#39;
[32m|[m[33m\[m  
[32m|[m * [33ma376e37b2c[m[33m ([m[1;31mgitster/jk/gitweb-anti-xss[m[33m)[m gitweb: escape URLs generated by href()
[32m|[m * [33mb178c207d7[m t/gitweb-lib.sh: set $REQUEST_URI
[32m|[m * [33mf28bceca75[m t/gitweb-lib.sh: drop confusing quotes
[32m|[m * [33m0eba60c9b7[m t9502: pass along all arguments in xss helper
* [33m|[m   [33m3288d99c92[m Merge branch &#39;ar/install-doc-update-cmds-needing-the-shell&#39;
[34m|[m[35m\[m [33m\[m  
[34m|[m * [33m|[m [33m932757b0cc[m[33m ([m[1;31mgitster/ar/install-doc-update-cmds-needing-the-shell[m[33m)[m INSTALL: use existing shell scripts as example
[34m|[m [33m|[m[33m/[m  
* [33m|[m   [33m4775e02a5c[m Merge branch &#39;ma/t7004&#39;
[36m|[m[1;31m\[m [33m\[m  
[36m|[m * [33m|[m [33mb018719927[m[33m ([m[1;31mgitster/ma/t7004[m[33m)[m t7004: check existence of correct tag
[36m|[m [33m|[m[33m/[m  
* [33m|[m   [33ma6c6f8d02a[m Merge branch &#39;js/complete-svn-recursive&#39;
[1;32m|[m[1;33m\[m [33m\[m  
[1;32m|[m * [33m|[m [33m1f9247a3bd[m[33m ([m[1;31mgitster/js/complete-svn-recursive[m[33m)[m completion: tab-complete &amp;quot;git svn --recursive&amp;quot;
[1;32m|[m [33m|[m[33m/[m  
* [33m|[m   [33m3ae8defaf9[m Merge branch &#39;jk/send-pack-remote-failure&#39;
[1;34m|[m[1;35m\[m [33m\[m  
[1;34m|[m * [33m|[m [33mad7a403268[m[33m ([m[1;31mgitster/jk/send-pack-remote-failure[m[33m)[m send-pack: check remote ref status on pack-objects failure
[1;34m|[m [33m|[m[33m/[m  
* [33m|[m   [33maec3b2e24f[m Merge branch &#39;jc/fsmonitor-sanity-fix&#39;
[1;36m|[m[31m\[m [33m\[m  
[1;36m|[m * [33m|[m [33m61eea521fe[m[33m ([m[1;31mgitster/jc/fsmonitor-sanity-fix[m[33m)[m fsmonitor: do not compare bitmap size with size of split index
* [31m|[m [33m|[m   [33m4ab9616c76[m Merge branch &#39;sg/skip-skipped-prereq&#39;
[32m|[m[33m\[m [31m\[m [33m\[m  
[32m|[m * [31m|[m [33m|[m [33me0316695ec[m[33m ([m[1;31mgitster/sg/skip-skipped-prereq[m[33m)[m test-lib: don&#39;t check prereqs of test cases that won&#39;t be run anyway
[32m|[m [33m|[m [31m|[m[33m/[m  
[32m|[m [33m|[m[33m/[m[31m|[m   
* [33m|[m [31m|[m   [33m723a8adba5[m Merge branch &#39;ds/test-read-graph&#39;
[34m|[m[35m\[m [33m\[m [31m\[m  
[34m|[m * [33m|[m [31m|[m [33m4bd0593e0f[m[33m ([m[1;31mgitster/ds/test-read-graph[m[33m)[m test-tool: use &#39;read-graph&#39; helper
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! git -C ~/src/git log -20 --graph --decorate --pretty=oneline --abbrev-commit --topo-order
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;* [33m228f53135a[m[33m ([m[1;36mHEAD -&amp;gt; [m[1;32mmaster[m[33m, [m[1;31mgitster/master[m[33m)[m The second batch
*   [33m6c630f237e[m Merge branch &#39;jk/gitweb-anti-xss&#39;
[32m|[m[33m\[m  
[32m|[m * [33ma376e37b2c[m[33m ([m[1;31mgitster/jk/gitweb-anti-xss[m[33m)[m gitweb: escape URLs generated by href()
[32m|[m * [33mb178c207d7[m t/gitweb-lib.sh: set $REQUEST_URI
[32m|[m * [33mf28bceca75[m t/gitweb-lib.sh: drop confusing quotes
[32m|[m * [33m0eba60c9b7[m t9502: pass along all arguments in xss helper
* [33m|[m   [33m3288d99c92[m Merge branch &#39;ar/install-doc-update-cmds-needing-the-shell&#39;
[34m|[m[35m\[m [33m\[m  
[34m|[m * [33m|[m [33m932757b0cc[m[33m ([m[1;31mgitster/ar/install-doc-update-cmds-needing-the-shell[m[33m)[m INSTALL: use existing shell scripts as example
[34m|[m [33m|[m[33m/[m  
* [33m|[m   [33m4775e02a5c[m Merge branch &#39;ma/t7004&#39;
[36m|[m[1;31m\[m [33m\[m  
[36m|[m * [33m|[m [33mb018719927[m[33m ([m[1;31mgitster/ma/t7004[m[33m)[m t7004: check existence of correct tag
[36m|[m [33m|[m[33m/[m  
* [33m|[m   [33ma6c6f8d02a[m Merge branch &#39;js/complete-svn-recursive&#39;
[1;32m|[m[1;33m\[m [33m\[m  
[1;32m|[m * [33m|[m [33m1f9247a3bd[m[33m ([m[1;31mgitster/js/complete-svn-recursive[m[33m)[m completion: tab-complete &amp;quot;git svn --recursive&amp;quot;
[1;32m|[m [33m|[m[33m/[m  
* [33m|[m   [33m3ae8defaf9[m Merge branch &#39;jk/send-pack-remote-failure&#39;
[1;34m|[m[1;35m\[m [33m\[m  
[1;34m|[m * [33m|[m [33mad7a403268[m[33m ([m[1;31mgitster/jk/send-pack-remote-failure[m[33m)[m send-pack: check remote ref status on pack-objects failure
[1;34m|[m [33m|[m[33m/[m  
* [33m|[m   [33maec3b2e24f[m Merge branch &#39;jc/fsmonitor-sanity-fix&#39;
[1;36m|[m[31m\[m [33m\[m  
[1;36m|[m * [33m|[m [33m61eea521fe[m[33m ([m[1;31mgitster/jc/fsmonitor-sanity-fix[m[33m)[m fsmonitor: do not compare bitmap size with size of split index
* [31m|[m [33m|[m   [33m4ab9616c76[m Merge branch &#39;sg/skip-skipped-prereq&#39;
[32m|[m[33m\[m [31m\[m [33m\[m  
[32m|[m * [31m|[m [33m|[m [33me0316695ec[m[33m ([m[1;31mgitster/sg/skip-skipped-prereq[m[33m)[m test-lib: don&#39;t check prereqs of test cases that won&#39;t be run anyway
[32m|[m [33m|[m [31m|[m[33m/[m  
[32m|[m [33m|[m[33m/[m[31m|[m   
* [33m|[m [31m|[m   [33m723a8adba5[m Merge branch &#39;ds/test-read-graph&#39;
[34m|[m[35m\[m [33m\[m [31m\[m  
[34m|[m * [33m|[m [31m|[m [33m4bd0593e0f[m[33m ([m[1;31mgitster/ds/test-read-graph[m[33m)[m test-tool: use &#39;read-graph&#39; helper
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! cd ~/src/git &amp;amp;&amp;amp; gitk
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;git-flow-https-nvie-com-posts-a-successful-git-branching-model&#34;&gt;&lt;a href=&#34;https://nvie.com/posts/a-successful-git-branching-model/&#34; target=&#34;_blank&#34;&gt;git-flow&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://nvie.com/img/git-model@2x.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;master&lt;/code&gt; sees only releases

&lt;ul&gt;
&lt;li&gt;very stable (like &lt;code&gt;maint&lt;/code&gt; in the standard model), but looks inactive&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;rebase-squash&#34;&gt;Rebase &amp;amp; Squash&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;A linear sequence of feature-complete commits&lt;/li&gt;
&lt;li&gt;Suitable for new developers&lt;/li&gt;
&lt;li&gt;Not atomic; bisection can land on huge commits&lt;/li&gt;
&lt;li&gt;Bug-fixes may be duplicated in &lt;code&gt;maint&lt;/code&gt; and &lt;code&gt;master&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;on-merging-from-upstream&#34;&gt;On merging from upstream&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;commit b8ffc1990c2cdad4f847a03479b787c8e1b99c7e (HEAD -&amp;gt; maint)
Merge: 77ec769c3b 9ff78c21f3
Author: Jed Brown &amp;lt;jed@jedbrown.org&amp;gt;
Date:   Mon Dec 2 10:55:51 2019 -0700

    Merge branch &#39;master&#39; into my/feature-branch
    
    * master: (218 commits)
      ex18 update
      DMSetFromOptions_Plex: add -dm_plex_check_all option
      doc: Make DMSetFromOptions() manpage a hub for all Check functions.
      DMSetFromOptions_Plex: process -dm_plex_check_pointsf and -dm_plex_check_interface_cones
      DMPlexCheckSkeleton: Pass for uninterpolated meshes.
      DMPlexCheckConesConformOnInterfaces -&amp;gt; DMPlexCheckInterfaceCones.
      Update CHANGELOG
      KSP ex49: add cholmod and superlu_dist cholesky tests
      Mat tests ex127: add test for MatMult and MatMultAdd for sbaij + hermitian
      MATSUPERLUDIST: fix MPIAIJ with commsize 1 case
      MatMPIAIJGetLocalMat: fix reuse case and clarify man page
      MATCHOLMOD: support for MatMatSolve and MatGetInfo
      Mat: propagate properly symmetry options
      MATSBAIJ: Fix Hermitian MatMult for Seq and MPI code paths
      KSPComputeOperator: do not assume a DM is attached to the KSP
      PetscLog: add utility routine to log external packages GPU time
      PCBDDC: adjust conversions and fix solver type for sub_schurs
      minor
      CHOLMOD: expose customizable GPU parameters and number of methods
      Add suitesparse to make check
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;This is a huge vulnerability: we get lots of features that could cause problems in this branch.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Almost always better to focus on your own work in the branch.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;If you must merge from upstream, explain why&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Merge branch &#39;master&#39; into my/feature-branch due to BaseClass API change
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Consider rebasing instead, but that may invalidate testing of earlier commits in your feature branch.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;philosophy&#34;&gt;Philosophy&lt;/h4&gt;

&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;A branch has a purpose. The most obvious is a topic branch you use for developing a new feature. A topic branch &amp;lsquo;add-frotz&amp;rsquo; would be about adding a new &amp;lsquo;frotz&amp;rsquo; feature and shouldn&amp;rsquo;t do anything else. In a well organized project, &amp;lsquo;master&amp;rsquo; branch (or &amp;lsquo;trunk&amp;rsquo; if you are coming from subversion) has the sole purpose of containing proven-to-be-good changes to produce the next release. Your per-customer branch is to contain the changes suitable for the next customer code dump and nothing else. It typically consists of bugfixes and selected features the particular customer asked (and paid for).&lt;/li&gt;
&lt;li&gt;The act of making a commit with one or more parents and advancing the tip of a branch with that commit is to make this statement: I have considered what all of these parent commits represent, and in my belief the state I am committing is more suitable for the purpose of this branch than any of them.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;&amp;ndash; &lt;a href=&#34;https://gitster.livejournal.com/42247.html&#34; target=&#34;_blank&#34;&gt;Junio Hamano: Fun with merges and purposes of branches&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;See also:
* &lt;a href=&#34;https://lwn.net/Articles/328436/&#34; target=&#34;_blank&#34;&gt;Rebasing and merging: some git best practices&lt;/a&gt;
* &lt;a href=&#34;https://yarchive.net/comp/linux/git_merges_from_upstream.html&#34; target=&#34;_blank&#34;&gt;Linus Torvalds on merging from upstream&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Molecular Dynamics</title>
      <link>https://cucs-hpsc.github.io/fall2019/md/</link>
      <pubDate>Fri, 22 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/md/</guid>
      <description>

&lt;h2 id=&#34;news-from-this-week-at-supercomputing&#34;&gt;News from this week at Supercomputing&lt;/h2&gt;

&lt;h3 id=&#34;a64fx&#34;&gt;A64FX&lt;/h3&gt;

&lt;p&gt;The most energy-efficient HPL machine today is pure CPU.  It is also among the &lt;em&gt;least&lt;/em&gt; &amp;ldquo;made for HPL&amp;rdquo; architectures on the list.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.top500.org/green500/list/2019/11/&#34; target=&#34;_blank&#34;&gt;https://www.top500.org/green500/list/2019/11/&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;daos-filesystem-performance&#34;&gt;DAOS filesystem performance&lt;/h3&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;DAOS declares #1 in IO-500 on the basis of performance-per-node (Weka on AWS was absolute performance). They maxed out I/O read bandwidth of the NVDIMMs in their cluster; iops were client limited. Pretty crazy efficiency. &lt;a href=&#34;https://twitter.com/hashtag/SC19?src=hash&amp;amp;ref_src=twsrc%5Etfw&#34;&gt;#SC19&lt;/a&gt; &lt;a href=&#34;https://t.co/u1cauolk1y&#34;&gt;pic.twitter.com/u1cauolk1y&lt;/a&gt;&lt;/p&gt;&amp;mdash; Glenn K. Lockwood (@glennklockwood) &lt;a href=&#34;https://twitter.com/glennklockwood/status/1197291164275109890?ref_src=twsrc%5Etfw&#34;&gt;November 20, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;EJ2h9s8U8AAbmNJ.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.vi4io.org/io500/start&#34; target=&#34;_blank&#34;&gt;https://www.vi4io.org/io500/start&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;force-models&#34;&gt;Force models&lt;/h2&gt;

&lt;p&gt;$$ V_{LJ}&amp;reg; = 4 \epsilon \Big[ \big(\frac{\sigma}{r}\big)^{12} - \big(\frac{\sigma}{r}\big)^6 \Big] $$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/5/51/12-6-Lennard-Jones-Potential.svg/640px-12-6-Lennard-Jones-Potential.svg.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)

# https://pubs.acs.org/doi/abs/10.1021/acs.inorgchem.7b00207
def phi_lj(r):
    eps = .4308
    sigma = 3.310
    return 4*eps*((sigma/r)**12 - (sigma/r)**6)

def phi_buckingham(r):
    A = 318418
    rho = .294276
    C = 2007.88
    return A * np.exp(-r/rho) - C/r**6

r = np.linspace(0.01, 10)
plt.plot(r, phi_lj(r), label=&#39;LJ&#39;);
plt.plot(r, phi_buckingham(r), label=&#39;Buckingham&#39;)
plt.ylim(-1,1)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The &lt;a href=&#34;https://en.wikipedia.org/wiki/Atomic_orbital#Orbitals_table&#34; target=&#34;_blank&#34;&gt;orbitals of real atoms&lt;/a&gt; are far more complicated than a radial function, and depend on other nearby atoms.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/5/5f/Lysine_fisher_structure_and_3d_ball.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;amber-http-ambermd-org-ambermodels-php-is-a-sophisticated-force-model-evaluator&#34;&gt;&lt;a href=&#34;http://ambermd.org/AmberModels.php&#34; target=&#34;_blank&#34;&gt;Amber&lt;/a&gt; is a sophisticated force model evaluator&lt;/h2&gt;

&lt;p&gt;Amber force fields can be used in other molecular dynamics packages, such as GROMACS and NAMD.&lt;/p&gt;

&lt;p&gt;The parameters in the force fields are estimated using optimization, &lt;a href=&#34;https://pubs.acs.org/doi/abs/10.1021/acs.jctc.5b00255&#34; target=&#34;_blank&#34;&gt;like this&lt;/a&gt; (see &lt;a href=&#34;https://pubs.acs.org/doi/suppl/10.1021/acs.jctc.5b00255/suppl_file/ct5b00255_si_001.pdf&#34; target=&#34;_blank&#34;&gt;supplement&lt;/a&gt; for coefficient values).  Some &lt;a href=&#34;https://www.nature.com/articles/s41467-018-06169-2&#34; target=&#34;_blank&#34;&gt;recent&lt;/a&gt; &lt;a href=&#34;https://www.nature.com/articles/s41467-019-12875-2&#34; target=&#34;_blank&#34;&gt;work&lt;/a&gt; seeks to use black-box machine learning methods (such as neural networks) to build multi-atom force models similar to the more explicit methods above.&lt;/p&gt;

&lt;h2 id=&#34;anton-2&#34;&gt;Anton-2&lt;/h2&gt;

&lt;p&gt;A special-purpose computer for molecular dynamics; winner of the &lt;a href=&#34;https://dl.acm.org/citation.cfm?id=2683599&#34; target=&#34;_blank&#34;&gt;2014 Gordon Bell Prize&lt;/a&gt; at Supercomputing.&lt;/p&gt;

&lt;h2 id=&#34;ab-initio-molecular-dynamics&#34;&gt;Ab initio molecular dynamics&lt;/h2&gt;

&lt;p&gt;The prior methods were all about molecular dynamics that calculate forces based on positions of nuclei.  Ab initio methods solve for electronic structure (electrons are fields/waves for this purpose), which is far more expensive.  There are a hierarchy of models.  Some examples, in order of increasing expense:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Density Functional Theory&lt;/li&gt;
&lt;li&gt;Coupled Cluster and Tensor Networks&lt;/li&gt;
&lt;li&gt;Quantum Monte-Carlo&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Combined, these methods account for a large fraction of global supercomputing time.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Long-range evaluation in N-body Simulation</title>
      <link>https://cucs-hpsc.github.io/fall2019/nbody-longrange/</link>
      <pubDate>Wed, 20 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/nbody-longrange/</guid>
      <description>

&lt;h2 id=&#34;recall-the-equations-of-motion&#34;&gt;Recall the equations of motion&lt;/h2&gt;

&lt;p&gt;Consider particles with mass $m_i$, position $\mathbf x_i(t) \in \mathbb R^3$, and momentum $\mathbf p_i(t) \in \mathbb R^3$, indexed by $i \in { 1, \dotsc, n }$.  Then their equation of motion is the ordinary differential equation&lt;/p&gt;

&lt;p&gt;\begin{align}
  \dot{\mathbf x_i} &amp;amp;= \frac{\mathbf p_i}{m_i} &lt;br /&gt;
  \dot{\mathbf p&lt;em&gt;i} &amp;amp;= \sum&lt;/em&gt;{j\ne i} \mathbf f_{ij} &lt;br /&gt;
\end{align}&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ \mathbf f_{ij} = G m_i m_j \frac{\mathbf x_j - \mathbf x_i}{\lVert \mathbf x_j - \mathbf x_i \rVert^3} $$&lt;/p&gt;

&lt;p&gt;is the force exerted on particle $i$ by particle $j$, and $G$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Gravitational_constant&#34; target=&#34;_blank&#34;&gt;gravitational constant&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;potential-equations&#34;&gt;Potential equations&lt;/h2&gt;

&lt;p&gt;Consider a scalar-valued field defined everywhere except at point charges,&lt;/p&gt;

&lt;p&gt;$$ \phi(\mathbf x) = - \sum_{j=1}^n \frac{G m_j}{\lVert \mathbf x - \mathbf x_j \rVert} . $$&lt;/p&gt;

&lt;p&gt;We call this the &lt;strong&gt;gravitational potential&lt;/strong&gt; and define the vector&lt;/p&gt;

&lt;p&gt;$$ \mathbf g(\mathbf x) = -\nabla \phi(\mathbf x) = \sum_{j=1}^n G m_j \frac{\mathbf x_j - \mathbf x}{\lVert \mathbf x - \mathbf x_j \rVert^3} $$&lt;/p&gt;

&lt;p&gt;which we call the &lt;strong&gt;gravitational field&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;This definition reminds us of $\mathbf f_{ij}$ above, the force applied to a mass $m_i$ at location $\mathbf x_i$ is&lt;/p&gt;

&lt;p&gt;$$ \sum&lt;em&gt;{j \ne i} \mathbf f&lt;/em&gt;{ij} = m_i \mathbf g(\mathbf x_i) $$&lt;/p&gt;

&lt;p&gt;where $\mathbf g$ is defined from a sum not including $i$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)

def potential(m, x, xx):
    &amp;quot;&amp;quot;&amp;quot;Evaluate gravitational potential from point masses at locations x&amp;quot;&amp;quot;&amp;quot;
    phi = np.zeros(xx.shape[0])
    for i in range(len(m)):
        phi -= m[i] / np.linalg.norm(x[i] - xx, axis=1)
    return phi

m = np.random.rand(5)
x = np.random.rand(5,1) * 2 - 1
xx = np.linspace(-2, 2, 200)[:, None]
phi = potential(m, x, xx)
plt.plot(xx, phi);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We need a way to
* exclude self-attraction from the potential
* avoid the need to represent the singularities in the potential
* evaluate the potential fast&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;ll interpret the gravitational potential $\phi(\mathbf x)$ as an integral&lt;/p&gt;

&lt;p&gt;$$ \phi(\mathbf x) = -G \int_{\mathbf x&amp;rsquo; \in \mathbb R^3} \frac{\rho(\mathbf x&amp;rsquo;)}{\lVert \mathbf x - \mathbf x&amp;rsquo; \rVert} $$&lt;/p&gt;

&lt;p&gt;in terms of the density distribution&lt;/p&gt;

&lt;p&gt;\begin{align}
\rho(\mathbf x) &amp;amp;= \sum_i m_i \delta(\mathbf x - \mathbf x_i) &lt;br /&gt;
&amp;amp;= \underbrace{\sum_i m_i \delta(\mathbf x - \mathbf x&lt;em&gt;i) - \rho^{sm}(\mathbf x)}&lt;/em&gt;{\text{local}} + \underbrace{\rho^{sm}(\mathbf x)}_{\text{smooth}}
\end{align}&lt;/p&gt;

&lt;p&gt;where $\delta(\mathbf x)$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Dirac_delta_function&#34; target=&#34;_blank&#34;&gt;Dirac delta function&lt;/a&gt; and $\rho^{sm}(\mathbf x)$ is chosen such that&lt;/p&gt;

&lt;p&gt;$$ \int&lt;em&gt;{\mathbf x&amp;rsquo; \in \Omega} \frac{\rho^{sm}(\mathbf x&amp;rsquo;)}{\lVert \mathbf x - \mathbf x&amp;rsquo; \rVert} \approx \int&lt;/em&gt;{\mathbf x&amp;rsquo; \in \Omega} \frac{\rho(\mathbf x&amp;rsquo;)}{\lVert \mathbf x - \mathbf x&amp;rsquo; \rVert} $$&lt;/p&gt;

&lt;p&gt;whenever $\mathbf x$ is &amp;ldquo;far from&amp;rdquo; $\Omega \subset \mathbb R^3$.&lt;/p&gt;

&lt;p&gt;The resulting algorithm works by
* compute smooth term via $\phi^{sm}(\mathbf x)$ from $\rho^{sm}(\mathbf x)$
* direct $O(n^2)$ force evaluation for close-range interactions (subtracting off the close-range smooth part)&lt;/p&gt;

&lt;h2 id=&#34;computing-the-long-range-part&#34;&gt;Computing the long-range part&lt;/h2&gt;

&lt;p&gt;We need a fast way to evaluate&lt;/p&gt;

&lt;p&gt;$$ \phi^{sm}(\mathbf x) = -G \int_{\mathbf x&amp;rsquo; \in \mathbb R^3} \frac{\rho^{sm}(\mathbf x&amp;rsquo;)}{\lVert \mathbf x - \mathbf x&amp;rsquo; \rVert} $$&lt;/p&gt;

&lt;p&gt;which is the solution of a Poisson equation&lt;/p&gt;

&lt;p&gt;$$ -\nabla\cdot \big( \nabla \phi^{sm} \big) = G \rho^{sm}(\mathbf x) . $$&lt;/p&gt;

&lt;h3 id=&#34;fast-evaluation&#34;&gt;Fast evaluation&lt;/h3&gt;

&lt;p&gt;| Method | Complexity | Representation |
|&amp;ndash;|&amp;ndash;|&amp;ndash;|
| Multigrid | $O(n)$ | field |
| Fast Fourier Transform | $O(n \log n)$ | field |
| Treecodes | $O(n \log n)$ | particle&amp;ndash;multipole |
| Fast Multipole Method | $O(n)$ | particle&amp;ndash;multipole, multipole-multipole, multipole&amp;ndash;particle |&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://link.aps.org/pdf/10.1103/PhysRevE.88.063308&#34; target=&#34;_blank&#34;&gt;Comparison of scalable fast methods for long-range interactions&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1209.3516&#34; target=&#34;_blank&#34;&gt;An FMM Based on Dual Tree Traversal for Many-core Architectures&lt;/a&gt; (compares different FMM representations)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;yokota-treecodes.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to N-body Simulation</title>
      <link>https://cucs-hpsc.github.io/fall2019/nbody/</link>
      <pubDate>Mon, 18 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/nbody/</guid>
      <description>

&lt;h2 id=&#34;equations-of-motion&#34;&gt;Equations of motion&lt;/h2&gt;

&lt;p&gt;Consider particles with mass $m_i$, position $\mathbf x_i(t) \in \mathbb R^3$, and momentum $\mathbf p_i(t) \in \mathbb R^3$, indexed by $i \in { 1, \dotsc, n }$.  Then their equation of motion is the ordinary differential equation&lt;/p&gt;

&lt;p&gt;\begin{align}
  \dot{\mathbf x_i} &amp;amp;= \frac{\mathbf p_i}{m_i} &lt;br /&gt;
  \dot{\mathbf p&lt;em&gt;i} &amp;amp;= \sum&lt;/em&gt;{j\ne i} \mathbf f_{ij} &lt;br /&gt;
\end{align}&lt;/p&gt;

&lt;p&gt;where&lt;/p&gt;

&lt;p&gt;$$ \mathbf f_{ij} = G m_i m_j \frac{\mathbf x_j - \mathbf x_i}{\lVert \mathbf x_j - \mathbf x_i \rVert^3} $$&lt;/p&gt;

&lt;p&gt;is the force exerted on particle $i$ by particle $j$, and $G$ is the &lt;a href=&#34;https://en.wikipedia.org/wiki/Gravitational_constant&#34; target=&#34;_blank&#34;&gt;gravitational constant&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)

G = 6.6743015e-11 # gravitational constant

def force(m, x):
    n = len(x)
    f = np.zeros_like(x)
    i = np.arange(n, dtype=int)
    for jj in range(1, n):
        j = ((i + jj) % n).tolist()
        r = x[j] - x  # Vector from x_i to x_j
        f += (G * m * m[j] / np.linalg.norm(r, axis=1)**3)[:, None] * r
    return f

def init_earth_ball():
    m = np.array([5.9722e24, 1])
    x = np.array([[0, 0],
                  [6.37e6, 0]])
    return m, x
m, x = init_earth_ball()
force(m, x)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 9.82338804,  0.        ],
       [-9.82338804,  0.        ]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Compare the magnitude to the acceleration due to gravity on earth ($9.8 m/s^2$) and observe symmetry (&lt;a href=&#34;https://en.wikipedia.org/wiki/Newton&#39;s_laws_of_motion&#34; target=&#34;_blank&#34;&gt;Newton&amp;rsquo;s third law&lt;/a&gt;).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def step(m, x, p, dt):
    x += dt * p / m[:,None]
    p += dt * force(m, x)

m, x = init_earth_ball()
p = np.array([[0, 0],
             [3e3, 10e3]])
for s in range(200):
    plt.plot(x[:,0], x[:,1], &#39;.&#39;)
    step(m, x, p, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_3_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;optimizing-force-evaluation&#34;&gt;Optimizing force evaluation&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
    from IPython.display import Markdown
    with open(filename) as f:
        contents = f.read()
    return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)

render_c(&#39;force.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;math.h&amp;gt;

void force1(int m, const float xmass[], const float x[],
            int n, const float ymass[], const float y[],
            float f[]) {
  for (int i=0; i&amp;lt;m; i++) {
    for (int j=0; j&amp;lt;n; j++) {
      float r[3] = {y[j*3+0] - x[i*3+0],
                    y[j*3+1] - x[i*3+1],
                    y[j*3+2] - x[i*3+2]};
      float r2 = r[0]*r[0] + r[1]*r[1] + r[2]*r[2];
      float Gmm = xmass[i] * ymass[j] / (r2 * sqrt(r2));
      for (int k=0; k&amp;lt;3; k++)
        f[i*3+k] += Gmm * r[k];
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.display import HTML
HTML(r&#39;&#39;&#39;&amp;lt;iframe width=&amp;quot;1200px&amp;quot; height=&amp;quot;800px&amp;quot; src=&amp;quot;https://gcc.godbolt.org/e#g:!((g:!((g:!((h:codeEditor,i:(fontScale:14,j:1,lang:___c,source:&#39;%23include+%3Cmath.h%3E%0A%0Avoid+force1(int+m,+const+float+xmass%5B%5D,+const+float+x%5B%5D,%0A++++++++++++int+n,+const+float+ymass%5B%5D,+const+float+y%5B%5D,%0A++++++++++++float+f%5B%5D)+%7B%0A++for+(int+i%3D0%3B+i%3Cm%3B+i%2B%2B)+%7B%0A++++for+(int+j%3D0%3B+j%3Cn%3B+j%2B%2B)+%7B%0A++++++float+r%5B3%5D+%3D+%7By%5Bj*3%2B0%5D+-+x%5Bi*3%2B0%5D,%0A++++++++++++++++++++y%5Bj*3%2B1%5D+-+x%5Bi*3%2B1%5D,%0A++++++++++++++++++++y%5Bj*3%2B2%5D+-+x%5Bi*3%2B2%5D%7D%3B%0A++++++float+r2+%3D+r%5B0%5D*r%5B0%5D+%2B+r%5B1%5D*r%5B1%5D+%2B+r%5B2%5D*r%5B2%5D%3B%0A++++++float+Gmm+%3D+xmass%5Bi%5D+*+ymass%5Bj%5D+/+(r2+*+sqrt(r2))%3B%0A++++++for+(int+k%3D0%3B+k%3C3%3B+k%2B%2B)%0A++++++++f%5Bi*3%2Bk%5D+%2B%3D+Gmm+*+r%5Bk%5D%3B%0A++++%7D%0A++%7D%0A%7D%0A&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;C+source+%231&#39;,t:&#39;0&#39;)),k:43.054234062797335,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:cg92,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,commentOnly:&#39;0&#39;,demangle:&#39;1&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;1&#39;,trim:&#39;0&#39;),fontScale:14,lang:___c,libs:!(),options:&#39;-Ofast+-march%3Dskylake-avx512+-fopenmp-simd&#39;,source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;x86-64+gcc+9.2+(Editor+%231,+Compiler+%231)+C&#39;,t:&#39;0&#39;)),k:56.945765937202665,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&#39;&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#34;1200px&#34; height=&#34;800px&#34; src=&#34;https://gcc.godbolt.org/e#g:!((g:!((g:!((h:codeEditor,i:(fontScale:14,j:1,lang:___c,source:&#39;%23include+%3Cmath.h%3E%0A%0Avoid+force1(int+m,+const+float+xmass%5B%5D,+const+float+x%5B%5D,%0A++++++++++++int+n,+const+float+ymass%5B%5D,+const+float+y%5B%5D,%0A++++++++++++float+f%5B%5D)+%7B%0A++for+(int+i%3D0%3B+i%3Cm%3B+i%2B%2B)+%7B%0A++++for+(int+j%3D0%3B+j%3Cn%3B+j%2B%2B)+%7B%0A++++++float+r%5B3%5D+%3D+%7By%5Bj*3%2B0%5D+-+x%5Bi*3%2B0%5D,%0A++++++++++++++++++++y%5Bj*3%2B1%5D+-+x%5Bi*3%2B1%5D,%0A++++++++++++++++++++y%5Bj*3%2B2%5D+-+x%5Bi*3%2B2%5D%7D%3B%0A++++++float+r2+%3D+r%5B0%5D*r%5B0%5D+%2B+r%5B1%5D*r%5B1%5D+%2B+r%5B2%5D*r%5B2%5D%3B%0A++++++float+Gmm+%3D+xmass%5Bi%5D+*+ymass%5Bj%5D+/+(r2+*+sqrt(r2))%3B%0A++++++for+(int+k%3D0%3B+k%3C3%3B+k%2B%2B)%0A++++++++f%5Bi*3%2Bk%5D+%2B%3D+Gmm+*+r%5Bk%5D%3B%0A++++%7D%0A++%7D%0A%7D%0A&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;C+source+%231&#39;,t:&#39;0&#39;)),k:43.054234062797335,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:cg92,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,commentOnly:&#39;0&#39;,demangle:&#39;1&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;1&#39;,trim:&#39;0&#39;),fontScale:14,lang:___c,libs:!(),options:&#39;-Ofast+-march%3Dskylake-avx512+-fopenmp-simd&#39;,source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;x86-64+gcc+9.2+(Editor+%231,+Compiler+%231)+C&#39;,t:&#39;0&#39;)),k:56.945765937202665,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4&#34;&gt;&lt;/iframe&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;force2.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;math.h&amp;gt;

void force2(int m, const float xmass[], const float x[],
            int n, const float ymass[], const float y[],
            float f[]) {
  for (int i=0; i&amp;lt;m; i++) {
    for (int j=0; j&amp;lt;n; j++) {
      float r[3] = {y[0*m+j] - x[0*n+i],
                    y[1*m+j] - x[1*n+i],
                    y[2*m+j] - x[2*n+i]};
      float r2 = r[0]*r[0] + r[1]*r[1] + r[2]*r[2];
      float Gmm = xmass[i] * ymass[j] / (r2 * sqrt(r2));
      for (int k=0; k&amp;lt;3; k++)
        f[k*m+i] += Gmm * r[k];
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;HTML(r&#39;&#39;&#39;&amp;lt;iframe width=&amp;quot;1200px&amp;quot; height=&amp;quot;800px&amp;quot; src=&amp;quot;https://gcc.godbolt.org/e#g:!((g:!((g:!((h:codeEditor,i:(fontScale:14,j:1,lang:___c,source:&#39;%23include+%3Cmath.h%3E%0A%0Avoid+force2(int+m,+const+float+xmass%5B%5D,+const+float+x%5B%5D,+%0A++++++++++++int+n,+const+float+ymass%5B%5D,+const+float+y%5B%5D,%0A++++++++++++float+f%5B%5D)+%7B%0A++for+(int+i%3D0%3B+i%3Cm%3B+i%2B%2B)+%7B%0A++++for+(int+j%3D0%3B+j%3Cn%3B+j%2B%2B)+%7B%0A++++++float+r%5B3%5D+%3D+%7By%5B0*m%2Bj%5D+-+x%5B0*n%2Bi%5D,%0A++++++++++++++++++++y%5B1*m%2Bj%5D+-+x%5B1*n%2Bi%5D,%0A++++++++++++++++++++y%5B2*m%2Bj%5D+-+x%5B2*n%2Bi%5D%7D%3B%0A++++++float+r2+%3D+r%5B0%5D*r%5B0%5D+%2B+r%5B1%5D*r%5B1%5D+%2B+r%5B2%5D*r%5B2%5D%3B%0A++++++float+Gmm+%3D+xmass%5Bi%5D+*+ymass%5Bj%5D+/+(r2+*+sqrt(r2))%3B%0A++++++for+(int+k%3D0%3B+k%3C3%3B+k%2B%2B)%0A++++++++f%5Bk*m%2Bi%5D+%2B%3D+Gmm+*+r%5Bk%5D%3B%0A++++%7D%0A++%7D%0A%7D%0A&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;C+source+%231&#39;,t:&#39;0&#39;)),k:43.054234062797335,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:cg92,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,commentOnly:&#39;0&#39;,demangle:&#39;1&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;1&#39;,trim:&#39;0&#39;),fontScale:14,lang:___c,libs:!(),options:&#39;-Ofast+-march%3Dskylake-avx512+-fopenmp-simd&#39;,source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;x86-64+gcc+9.2+(Editor+%231,+Compiler+%231)+C&#39;,t:&#39;0&#39;)),k:56.945765937202665,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4&amp;quot;&amp;gt;&amp;lt;/iframe&amp;gt;&#39;&#39;&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#34;1200px&#34; height=&#34;800px&#34; src=&#34;https://gcc.godbolt.org/e#g:!((g:!((g:!((h:codeEditor,i:(fontScale:14,j:1,lang:___c,source:&#39;%23include+%3Cmath.h%3E%0A%0Avoid+force2(int+m,+const+float+xmass%5B%5D,+const+float+x%5B%5D,+%0A++++++++++++int+n,+const+float+ymass%5B%5D,+const+float+y%5B%5D,%0A++++++++++++float+f%5B%5D)+%7B%0A++for+(int+i%3D0%3B+i%3Cm%3B+i%2B%2B)+%7B%0A++++for+(int+j%3D0%3B+j%3Cn%3B+j%2B%2B)+%7B%0A++++++float+r%5B3%5D+%3D+%7By%5B0*m%2Bj%5D+-+x%5B0*n%2Bi%5D,%0A++++++++++++++++++++y%5B1*m%2Bj%5D+-+x%5B1*n%2Bi%5D,%0A++++++++++++++++++++y%5B2*m%2Bj%5D+-+x%5B2*n%2Bi%5D%7D%3B%0A++++++float+r2+%3D+r%5B0%5D*r%5B0%5D+%2B+r%5B1%5D*r%5B1%5D+%2B+r%5B2%5D*r%5B2%5D%3B%0A++++++float+Gmm+%3D+xmass%5Bi%5D+*+ymass%5Bj%5D+/+(r2+*+sqrt(r2))%3B%0A++++++for+(int+k%3D0%3B+k%3C3%3B+k%2B%2B)%0A++++++++f%5Bk*m%2Bi%5D+%2B%3D+Gmm+*+r%5Bk%5D%3B%0A++++%7D%0A++%7D%0A%7D%0A&#39;),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;C+source+%231&#39;,t:&#39;0&#39;)),k:43.054234062797335,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;),(g:!((h:compiler,i:(compiler:cg92,filters:(b:&#39;0&#39;,binary:&#39;1&#39;,commentOnly:&#39;0&#39;,demangle:&#39;1&#39;,directives:&#39;0&#39;,execute:&#39;1&#39;,intel:&#39;0&#39;,libraryCode:&#39;1&#39;,trim:&#39;0&#39;),fontScale:14,lang:___c,libs:!(),options:&#39;-Ofast+-march%3Dskylake-avx512+-fopenmp-simd&#39;,source:1),l:&#39;5&#39;,n:&#39;0&#39;,o:&#39;x86-64+gcc+9.2+(Editor+%231,+Compiler+%231)+C&#39;,t:&#39;0&#39;)),k:56.945765937202665,l:&#39;4&#39;,m:100,n:&#39;0&#39;,o:&#39;&#39;,s:0,t:&#39;0&#39;)),l:&#39;2&#39;,n:&#39;0&#39;,o:&#39;&#39;,t:&#39;0&#39;)),version:4&#34;&gt;&lt;/iframe&gt;

&lt;ul&gt;
&lt;li&gt;Big-O of this algorithm?&lt;/li&gt;
&lt;li&gt;Cache reuse?&lt;/li&gt;
&lt;li&gt;Vectorization?&lt;/li&gt;
&lt;li&gt;Instruction-level parallelism?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;further-resources&#34;&gt;Further resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://hipacc.ucsc.edu/Talk_single.php%3FTid=114&amp;amp;SerId=12&amp;amp;Aid=12.html&#34; target=&#34;_blank&#34;&gt;Michael Warren (LANL): Optimizing the inner loop of the gravitational force interaction on modern processors&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/abs/1310.4502&#34; target=&#34;_blank&#34;&gt;2HOT: An Improved Parallel Hashed Oct-Tree N-Body Algorithm for Cosmological Simulation&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Dynamic/Interactive Parallelism</title>
      <link>https://cucs-hpsc.github.io/fall2019/interactive/</link>
      <pubDate>Fri, 15 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/interactive/</guid>
      <description>

&lt;h2 id=&#34;interactive-parallelism&#34;&gt;Interactive Parallelism&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Batch parallelism (e.g., MPI)

&lt;ul&gt;
&lt;li&gt;Computation more expensive than data load/store&lt;/li&gt;
&lt;li&gt;Thinking up-front to maximize efficiency&lt;/li&gt;
&lt;li&gt;Scalable and low-latency&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Interactive/exploratory analysis

&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t know the question until seeing data&lt;/li&gt;
&lt;li&gt;Iterative exploration&lt;/li&gt;
&lt;li&gt;Some analyses are cheap, others are expensive&lt;/li&gt;
&lt;li&gt;Data load/store and preprocessing expensive compared to (some) analysis&lt;/li&gt;
&lt;li&gt;Modest scale (single node to perhaps dozens of hundreds of nodes for the right problem)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;example-platforms&#34;&gt;Example platforms&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hadoop.apache.org/&#34; target=&#34;_blank&#34;&gt;Hadoop&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Reliable MapReduce system with disk-based storage and replication for fault tolerance&lt;/li&gt;
&lt;li&gt;Java with bindings for other languages&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://spark.apache.org/docs/latest/quick-start.html&#34; target=&#34;_blank&#34;&gt;Spark&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;In-memory child of Hadoop
&lt;img src=&#34;https://spark.apache.org/images/logistic-regression.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://dask.org/&#34; target=&#34;_blank&#34;&gt;Dask&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Python-based platform that integrates with NumPy, SciPy, Pandas, and Scikit-Learn&lt;/li&gt;
&lt;li&gt;Lead developer employed by NVIDIA&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://ipyparallel.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;IPyParallel&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Control-worker design&lt;/li&gt;
&lt;li&gt;Can use MPI&lt;/li&gt;
&lt;li&gt;Expressive parallel algorithms&lt;/li&gt;
&lt;li&gt;A bit flaky, especially after error conditions (in my experience)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1-OFjrk1q3L1d3uakr2xkozrPn2c2VZpZ/view&#34; target=&#34;_blank&#34;&gt;On NERSC&amp;rsquo;s Cori&lt;/a&gt;
&lt;img src=&#34;ipyparallel-cori.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://parsl-project.org/&#34; target=&#34;_blank&#34;&gt;Parsl-python&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://drive.google.com/file/d/1Yy_jUWLvdSPHsXd4wtsfcIXoGvO2DY9g/view&#34; target=&#34;_blank&#34;&gt;Slides&lt;/a&gt;
&lt;img src=&#34;parsl-slide.png&#34; alt=&#34;&#34; /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://jupyter-workshop-2019.lbl.gov/agenda&#34; target=&#34;_blank&#34;&gt;Workshop: Jupyter for Science User Facilities and High Performance Computing&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;dask-notes&#34;&gt;Dask notes&lt;/h2&gt;

&lt;p&gt;Distributed API operations are lazy, returning futures. Computation actually occurs when you ask for &lt;code&gt;.result()&lt;/code&gt; (gathers result locally) or call &lt;code&gt;.persist()&lt;/code&gt; to start computing a distributed result.&lt;/p&gt;

&lt;h4 id=&#34;overhead&#34;&gt;Overhead&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;Partitions should fit comfortably in memory (smaller than a gigabyte) but also not be too many. &lt;strong&gt;Every operation on every partition takes the central scheduler a few hundred microseconds to process.&lt;/strong&gt; If you have a few thousand tasks this is barely noticeable, but it is nice to reduce the number if possible.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df = dd.read_csv(&#39;s3://bucket/path/to/*.csv&#39;)
df = df[df.name == &#39;Alice&#39;]  # only 1/100th of the data
df = df.repartition(npartitions=df.npartitions // 100)

df = df.persist()  # if on a distributed system
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.dask.org/en/latest/dataframe-best-practices.html&#34; target=&#34;_blank&#34;&gt;https://docs.dask.org/en/latest/dataframe-best-practices.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://distributed.readthedocs.io/en/latest/limitations.html&#34; target=&#34;_blank&#34;&gt;https://distributed.readthedocs.io/en/latest/limitations.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;keeping-data-distributed&#34;&gt;Keeping data distributed&lt;/h4&gt;

&lt;p&gt;&lt;a href=&#34;https://distributed.readthedocs.io/en/latest/efficiency.html&#34; target=&#34;_blank&#34;&gt;https://distributed.readthedocs.io/en/latest/efficiency.html&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from dask.distributed import Client

client = Client()
client
&lt;/code&gt;&lt;/pre&gt;

&lt;table style=&#34;border: 2px solid white;&#34;&gt;
&lt;tr&gt;
&lt;td style=&#34;vertical-align: top; border: 0px solid white&#34;&gt;
&lt;h3 style=&#34;text-align: left;&#34;&gt;Client&lt;/h3&gt;
&lt;ul style=&#34;text-align: left; list-style: none; margin: 0; padding: 0;&#34;&gt;
  &lt;li&gt;&lt;b&gt;Scheduler: &lt;/b&gt;tcp://127.0.0.1:45897&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;td style=&#34;vertical-align: top; border: 0px solid white&#34;&gt;
&lt;h3 style=&#34;text-align: left;&#34;&gt;Cluster&lt;/h3&gt;
&lt;ul style=&#34;text-align: left; list-style:none; margin: 0; padding: 0;&#34;&gt;
  &lt;li&gt;&lt;b&gt;Workers: &lt;/b&gt;4&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Cores: &lt;/b&gt;4&lt;/li&gt;
  &lt;li&gt;&lt;b&gt;Memory: &lt;/b&gt;16.67 GB&lt;/li&gt;
&lt;/ul&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np

x = client.submit(np.random.random, (1000, 1000))
x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;b&gt;Future: random&lt;/b&gt; &lt;font color=&#34;gray&#34;&gt;status: &lt;/font&gt;&lt;font color=&#34;black&#34;&gt;pending&lt;/font&gt;, &lt;font color=&#34;gray&#34;&gt;key: &lt;/font&gt;random-4fead107d39a451af48ce8db919b0254&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;b&gt;Future: random&lt;/b&gt; &lt;font color=&#34;gray&#34;&gt;status: &lt;/font&gt;&lt;font color=&#34;black&#34;&gt;finished&lt;/font&gt;, &lt;font color=&#34;gray&#34;&gt;type: &lt;/font&gt;numpy.ndarray, &lt;font color=&#34;gray&#34;&gt;key: &lt;/font&gt;random-4fead107d39a451af48ce8db919b0254&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x.result().shape # Moves data to control process, then computes shape
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1000, 1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;client.submit(lambda a: a.shape, x).result()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(1000, 1000)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/dask/dask-org/master/images/bokeh-task-stream.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://distributed.readthedocs.io/en/latest/diagnosing-performance.html&#34; target=&#34;_blank&#34;&gt;https://distributed.readthedocs.io/en/latest/diagnosing-performance.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;qr-factorization&#34;&gt;QR factorization&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://arxiv.org/pdf/1301.1071.pdf&#34; target=&#34;_blank&#34;&gt;Direct QR factorizations for tall-and-skinnymatrices in MapReduce architectures&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indirect-approach-compute-r-then-q-a-r-1&#34;&gt;Indirect approach: compute $R$, then $Q = A R^{-1}$&lt;/h3&gt;

&lt;p&gt;$$ R^T R = A^T A $$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-chol-qr.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;direct-householder-qr-a&#34;&gt;&amp;ldquo;Direct&amp;rdquo; Householder $QR = A$&lt;/h3&gt;

&lt;p&gt;Operates one column at a time; inefficient parallel distribution and memory access.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-householder.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;direct-tsqr&#34;&gt;Direct TSQR&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-tsqr.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-figure6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Value&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Nodes&lt;/td&gt;
&lt;td&gt;10&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Processor&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://ark.intel.com/content/www/us/en/ark/products/37151/intel-core-i7-960-processor-8m-cache-3-20-ghz-4-80-gt-s-intel-qpi.html&#34; target=&#34;_blank&#34;&gt;i7-960&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Memory/node&lt;/td&gt;
&lt;td&gt;24 GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Total memory&lt;/td&gt;
&lt;td&gt;240 GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Memory BW/node&lt;/td&gt;
&lt;td&gt;25 GB/s&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Cores/node&lt;/td&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Clock&lt;/td&gt;
&lt;td&gt;3.2 GHz&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;flops/cycle/core&lt;/td&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;GF/s/node&lt;/td&gt;
&lt;td&gt;25.6&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;flops/byte&lt;/td&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-table2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import pandas
df = pandas.DataFrame(dict(rows=[4e9, 2.5e9, .6e9, .5e9, .15e9], cols=[4,10,25,50,100]))
df[&#39;bytes&#39;] = 8 * df.rows * df.cols
df[&#39;flops&#39;] = 2 * df.rows * df.cols**2
bandwidth = 125e9  # 50% of peak
flops = 256e9 * .2 # 20% of peak
df[&#39;sec_mem&#39;] = df.bytes / bandwidth
df[&#39;sec_flops&#39;] = df.flops / flops
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;rows&lt;/th&gt;
      &lt;th&gt;cols&lt;/th&gt;
      &lt;th&gt;bytes&lt;/th&gt;
      &lt;th&gt;flops&lt;/th&gt;
      &lt;th&gt;sec_mem&lt;/th&gt;
      &lt;th&gt;sec_flops&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;4.000000e+09&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.280000e+11&lt;/td&gt;
      &lt;td&gt;1.280000e+11&lt;/td&gt;
      &lt;td&gt;1.024&lt;/td&gt;
      &lt;td&gt;2.500000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;2.500000e+09&lt;/td&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;2.000000e+11&lt;/td&gt;
      &lt;td&gt;5.000000e+11&lt;/td&gt;
      &lt;td&gt;1.600&lt;/td&gt;
      &lt;td&gt;9.765625&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;6.000000e+08&lt;/td&gt;
      &lt;td&gt;25&lt;/td&gt;
      &lt;td&gt;1.200000e+11&lt;/td&gt;
      &lt;td&gt;7.500000e+11&lt;/td&gt;
      &lt;td&gt;0.960&lt;/td&gt;
      &lt;td&gt;14.648438&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;5.000000e+08&lt;/td&gt;
      &lt;td&gt;50&lt;/td&gt;
      &lt;td&gt;2.000000e+11&lt;/td&gt;
      &lt;td&gt;2.500000e+12&lt;/td&gt;
      &lt;td&gt;1.600&lt;/td&gt;
      &lt;td&gt;48.828125&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;1.500000e+08&lt;/td&gt;
      &lt;td&gt;100&lt;/td&gt;
      &lt;td&gt;1.200000e+11&lt;/td&gt;
      &lt;td&gt;3.000000e+12&lt;/td&gt;
      &lt;td&gt;0.960&lt;/td&gt;
      &lt;td&gt;58.593750&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;img src=&#34;mapreduce-table6.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;notes&#34;&gt;Notes&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;The data always fits in (distributed) memory&lt;/li&gt;
&lt;li&gt;Limited by flops for all numbers of columns

&lt;ul&gt;
&lt;li&gt;What about on today&amp;rsquo;s computers?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Using disk and the present algorithm is tens to hundreds of times slower than an efficient in-memory algorithm.&lt;/li&gt;
&lt;li&gt;The many passes over data in (unblocked) Householder is crippling&lt;/li&gt;
&lt;li&gt;Direct TSQR and Cholesky QR with refinement are good algorithms&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;k-means-clustering-https-en-wikipedia-org-wiki-k-means-clustering&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/K-means_clustering&#34; target=&#34;_blank&#34;&gt;K-means clustering&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;Given $n$ points $x_i$ in $d$-dimensional space, the k-means algorithm finds $K$ clusters by
1. Initialize centers ${ c&lt;em&gt;k \in R^d }&lt;/em&gt;{k=1}^K $
2. Repeat (Lloyd&amp;rsquo;s algorithm)
  * Assign each $x_i$ to the nearest center $c_k$
  * Shift each center $c_k$ to the mean (centroid) of its $x_i$&lt;/p&gt;

&lt;p&gt;This minimizes the cost function&lt;/p&gt;

&lt;p&gt;$$ \phi(\mathcal C) = \sum_{x\in X} \min_k \lVert x - c_k \rVert^2 $$&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/e/ea/K-means_convergence.gif&#34; alt=&#34;&#34; /&gt;
By &lt;a href=&#34;//commons.wikimedia.org/wiki/User:Chire&#34; title=&#34;User:Chire&#34;&gt;Chire&lt;/a&gt; - &lt;span class=&#34;int-own-work&#34; lang=&#34;en&#34;&gt;Own work&lt;/span&gt;, &lt;a href=&#34;https://creativecommons.org/licenses/by-sa/4.0&#34; title=&#34;Creative Commons Attribution-Share Alike 4.0&#34;&gt;CC BY-SA 4.0&lt;/a&gt;, &lt;a href=&#34;https://commons.wikimedia.org/w/index.php?curid=59409335&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;initialization-matters&#34;&gt;Initialization matters&lt;/h3&gt;

&lt;p&gt;&lt;blockquote class=&#34;twitter-tweet&#34;&gt;&lt;p lang=&#34;en&#34; dir=&#34;ltr&#34;&gt;K-means++ defines a seeding strategy which is approximately optimal up to a logarithmic factor. Running k-means afterward only marginally improves the quantization error (as opposed to bad seeding). &lt;a href=&#34;https://t.co/L8w45IE9gV&#34;&gt;https://t.co/L8w45IE9gV&lt;/a&gt; &lt;a href=&#34;https://t.co/7DtaTZukTU&#34;&gt;pic.twitter.com/7DtaTZukTU&lt;/a&gt;&lt;/p&gt;&amp;mdash; Gabriel PeyrÃ© (@gabrielpeyre) &lt;a href=&#34;https://twitter.com/gabrielpeyre/status/1194495104855052288?ref_src=twsrc%5Etfw&#34;&gt;November 13, 2019&lt;/a&gt;&lt;/blockquote&gt; &lt;script async src=&#34;https://platform.twitter.com/widgets.js&#34; charset=&#34;utf-8&#34;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h4 id=&#34;serial-kmeans-and-parallel-kmeans&#34;&gt;Serial &lt;code&gt;kmeans++&lt;/code&gt; and parallel &lt;code&gt;kmeans||&lt;/code&gt;&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;kmeans-plusplus.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;kmeans-parallel.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Data and Probability</title>
      <link>https://cucs-hpsc.github.io/fall2019/data-probability/</link>
      <pubDate>Wed, 13 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/data-probability/</guid>
      <description>

&lt;h2 id=&#34;sampling-probability-distributions&#34;&gt;Sampling probability distributions&lt;/h2&gt;

&lt;p&gt;There are many applications in which one wishes to draw samples from probability distributions.  For example, the function &lt;code&gt;np.random.randn(t)&lt;/code&gt; draws samples from the &amp;ldquo;standard normal&amp;rdquo;, or Gaussian, distribution.&lt;/p&gt;

&lt;p&gt;$$ p(t) = \frac{1}{\sqrt{2\pi}} e^{-t^&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;} . $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
import numpy as np
plt.style.use(&#39;ggplot&#39;)
plt.rc(&#39;figure&#39;, figsize=(12,8))

def stdnormal(t):
    return np.exp(-t**2/2) / np.sqrt(2*np.pi)

n = 1000
w = np.random.randn(n)
plt.hist(w, bins=40, range=(-3,3), density=True)
t = np.linspace(-3, 3)
plt.plot(t, stdnormal(t))
plt.xlabel(&#39;$t$&#39;)
plt.ylabel(&#39;$P(t)$&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_1_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;statistics-for-hackers&#34;&gt;Statistics for Hackers&lt;/h3&gt;

&lt;p&gt;Statistical simulation as a simpler surrogate for tedious analysis (also a primer for more advanced methods in which analysis is intractable):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://christopherroach.com/articles/statistics-for-hackers/&#34; target=&#34;_blank&#34;&gt;Notebook&lt;/a&gt; version of &lt;a href=&#34;https://youtu.be/Iq9DzN6mvYA&#34; target=&#34;_blank&#34;&gt;this talk&lt;/a&gt; (&lt;a href=&#34;https://speakerdeck.com/jakevdp/statistics-for-hackers&#34; target=&#34;_blank&#34;&gt;slides&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;transforming&#34;&gt;Transforming&lt;/h3&gt;

&lt;p&gt;To say that our sample $w$ is draw from a standard normal distribution, we write&lt;/p&gt;

&lt;p&gt;$$ w \sim \mathcal N(0,1) . $$&lt;/p&gt;

&lt;p&gt;How do we generate samples of a distribution with nonzero mean or non-unit variance?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import statsmodels

n = 1000
w = 2 + .5*np.random.randn(n)
plt.hist(w, bins=40, range=(-1,5), density=True)
plt.xlabel(&#39;$t$&#39;)
plt.ylabel(&#39;$P(t)$&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_4_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;multivariate-distributions&#34;&gt;Multivariate distributions&lt;/h3&gt;

&lt;p&gt;Sometimes we have multiple variables that are related, such as the temperature in different cities.  On any given day, we observe the weather in Boulder, Denver, Fort Collins, and Seattle.  What is the probability of any given observation?&lt;/p&gt;

&lt;p&gt;For convenience, suppose that each distribution is independently a Gaussian distribution.  Taking products, we can motivate a linear algebraic formulation,&lt;/p&gt;

&lt;p&gt;$$ e^{-s^&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;} e^{-t^&lt;sup&gt;2&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;} = e^{-\frac 1 2 \begin{bmatrix} s &amp;amp; t \end{bmatrix} \begin{bmatrix} 1 &amp;amp; 0 \ 0 &amp;amp; 1 \end{bmatrix} \begin{bmatrix} s \ t \end{bmatrix}} $$&lt;/p&gt;

&lt;p&gt;More generally, we may express a multidimensional distribution for $\mathbf x$ with mean $\mathbf \mu$ and covariance matrix $\Sigma$ as&lt;/p&gt;

&lt;p&gt;$$ P(\mathbf x) = \frac 1 Z e^{-\frac 1 2 (\mathbf x - \mathbf \mu)^T \Sigma^{-1} (\mathbf x - \mathbf \mu)} $$&lt;/p&gt;

&lt;p&gt;where $Z$ is a normalizing factor necessary for the integral to equal 1.  Covaniance matrices are symmetric positive definite, and rarely sparse, though they may have exploitable structure (such as low-rank off-diagonal blocks).&lt;/p&gt;

&lt;p&gt;Many statistical computations involve&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;drawing samples from such distributions (bootstrapping, etc., and Bayesian Monte-Carlo methods)&lt;/li&gt;
&lt;li&gt;optimizing parameters (such as $\mathbf \mu$ and $\Sigma$) over a training set of observations (maximum likelihood estimation and variational inference)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;negative-log&#34;&gt;Negative log&lt;/h4&gt;

&lt;p&gt;Probabilities become inconveniently small when far from the mean.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;stdnormal(10)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;7.69459862670642e-23
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Taking the negative log provides a more convenient expression&lt;/p&gt;

&lt;p&gt;$$ -\log P(\mathbf x) = \frac 1 2 (\mathbf x - \mathbf \mu)^T \Sigma^{-1} (\mathbf x - \mathbf \mu) + \log Z $$&lt;/p&gt;

&lt;p&gt;which involves a quadratic matrix expression (convenient for optimization) plus a regularization term.&lt;/p&gt;

&lt;h4 id=&#34;normalization&#34;&gt;Normalization&lt;/h4&gt;

&lt;p&gt;It can be shown that the normalization factor has the form&lt;/p&gt;

&lt;p&gt;$$ Z = \sqrt{\det(2 \pi \Sigma)} . $$&lt;/p&gt;

&lt;p&gt;In some circumstances, such as when estimating $\mathbf \mu$ given known $\Sigma$, it is not necessary to evaluate or optimize the determinant.  In other settings, it is necessary and a nontrivial cost.
Computing the determinant is typically done via factorization, such as&lt;/p&gt;

&lt;p&gt;$$ L L^T = \Sigma $$&lt;/p&gt;

&lt;p&gt;or&lt;/p&gt;

&lt;p&gt;$$ L L^T = \Sigma^{-1} $$&lt;/p&gt;

&lt;p&gt;if one is working directly with the &amp;ldquo;precision matrix&amp;rdquo; $\Sigma^{-1}$.  This can be advantageous when the precision matrix is sparse, which represents conditional independence and is common even when the covariance matrix is dense.&lt;/p&gt;

&lt;p&gt;For example, the weather in Boulder is conditionally independent of the weather in Seattle: if we know the weather in Denver and Fort Collins, adding knowledge of the weather in Seattle provides us no additional information about the weather in Boulder.  This leads to a zero in $\Sigma^{-1}$.&lt;/p&gt;

&lt;p&gt;However, knowing the weather in Seattle might help determine whether it is summer or winter, or whether we&amp;rsquo;re in an El NiÃ±o year.  This leads to a nonzero entry in $\Sigma$.&lt;/p&gt;

&lt;h4 id=&#34;sampling&#34;&gt;Sampling&lt;/h4&gt;

&lt;p&gt;We wish to draw samples such that the expected covariance matches our $\Sigma$,&lt;/p&gt;

&lt;p&gt;$$ \mathbb E\Big[ (\mathbf x - \mathbf \mu) (\mathbf x - \mathbf \mu)^T \Big] = \Sigma . $$&lt;/p&gt;

&lt;p&gt;For this, we seek a transformation $\mathbf x = \mu + T \mathbf y$ such that each entry of $y \sim \mathcal N(0,1)$.  To this end,&lt;/p&gt;

&lt;p&gt;$$ \Sigma = \mathbb E\Big[ T \mathbf y \mathbf y^T T^T \Big] = T \mathbb E[\mathbf y \mathbf y^T] T^T = T T^T $$
so we need to determine such a matrix $T$.&lt;/p&gt;

&lt;p&gt;One approach is eigendecomposition,&lt;/p&gt;

&lt;p&gt;$$ \Sigma = Q \Lambda Q^T = \big(Q \sqrt{\Lambda} \big) \big(Q \sqrt{\Lambda} \big)^T $$&lt;/p&gt;

&lt;p&gt;and another is Cholesky factorization&lt;/p&gt;

&lt;p&gt;$$ \Sigma = L L^T, $$&lt;/p&gt;

&lt;p&gt;which is generally more efficient (if perhaps less intuitive).&lt;/p&gt;

&lt;h2 id=&#34;gaussian-processes&#34;&gt;Gaussian processes&lt;/h2&gt;

&lt;p&gt;A Gaussian process is a probability model for continuous independent variables.  In the temperature example, we might consider latitude and longitude as independent variables.  Given any finite sample of locations (Boulder, Denver, etc.), we build a covariance matrix between any two points $u$ and $v$ by evaluating a &amp;ldquo;kernel&amp;rdquo; function $k(u,v)$.  Sometimes one uses &amp;ldquo;stationary&amp;rdquo; kernels that depend only on distance,&lt;/p&gt;

&lt;p&gt;$$ k(u,v) = \hat k\big(\lVert u - v \rVert \big) $$&lt;/p&gt;

&lt;p&gt;and sometimes the kernels are squared exponentials,&lt;/p&gt;

&lt;p&gt;$$ \hat k&amp;reg; = e^{-r^2/\ell^2} $$&lt;/p&gt;

&lt;p&gt;where $\ell$ is a length scale.  But these are not essential features.&lt;/p&gt;

&lt;p&gt;Note: although the squared exponential kernel has the same functional form as a Gaussian distribution, this is entirely optional and not what &amp;ldquo;Gaussian&amp;rdquo; in &amp;ldquo;Gaussian process&amp;rdquo; refers to.&lt;/p&gt;

&lt;p&gt;In a &lt;a href=&#34;https://en.wikipedia.org/wiki/Kriging&#34; target=&#34;_blank&#34;&gt;Gaussian Process Regression&lt;/a&gt; (also known as &amp;ldquo;kriging&amp;rdquo;), one &amp;ldquo;trains&amp;rdquo; (optimizes) kernel parameters $\theta$ in&lt;/p&gt;

&lt;p&gt;$$ k(u, v; \theta) $$&lt;/p&gt;

&lt;p&gt;such that the model fits some training data.  Once trained, predictions can be made at arbitrary points $u$, and those predictions come with uncertainty.&lt;/p&gt;

&lt;p&gt;The classical training involves Cholesky factorization as part of each iteration of a gradient-based optimization algorithm.&lt;/p&gt;

&lt;h4 id=&#34;further-reading&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://planspace.org/20181226-gaussian_processes_are_not_so_fancy/&#34; target=&#34;_blank&#34;&gt;Gaussian Processes are Not So Fancy&lt;/a&gt; (notebook)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://adamian.github.io/talks/Damianou_GP_tutorial.html&#34; target=&#34;_blank&#34;&gt;Gaussian process introductory tutorial in Python&lt;/a&gt; (notebook)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/gaussian_process.html&#34; target=&#34;_blank&#34;&gt;GPR in scikit-learn&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gpytorch.readthedocs.io/en/latest/&#34; target=&#34;_blank&#34;&gt;GPyTorch&lt;/a&gt;, which contains some &lt;a href=&#34;https://arxiv.org/abs/1809.11165&#34; target=&#34;_blank&#34;&gt;structure-exploiting methods&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Data-intensive workflows and parallelism</title>
      <link>https://cucs-hpsc.github.io/fall2019/data-methods/</link>
      <pubDate>Mon, 11 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/data-methods/</guid>
      <description>

&lt;h2 id=&#34;seismic-tomography&#34;&gt;Seismic Tomography&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.display import HTML

####HTML(&#39;&amp;lt;iframe width=&amp;quot;854&amp;quot; height=&amp;quot;422&amp;quot; src=&amp;quot;https://www.youtube.com/embed/7zuICgLxSIk?rel=0&amp;amp;amp;controls=0&amp;amp;amp;showinfo=0&amp;quot; frameborder=&amp;quot;0&amp;quot; allowfullscreen&amp;gt;&amp;lt;/iframe&amp;gt;&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe width=&#34;854&#34; height=&#34;422&#34; src=&#34;https://www.youtube.com/embed/7zuICgLxSIk?rel=0&amp;amp;controls=0&amp;amp;showinfo=0&#34; frameborder=&#34;0&#34; allowfullscreen&gt;&lt;/iframe&gt;

&lt;h3 id=&#34;observed-and-synthectic-seismograms&#34;&gt;Observed and synthectic seismograms&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;flexwin.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;data-sizes&#34;&gt;Data sizes&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Name&lt;/th&gt;
&lt;th&gt;Count/size&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Seismic events (earthquakes)&lt;/td&gt;
&lt;td&gt;100&amp;ndash;1000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Seismic stations that observe each event&lt;/td&gt;
&lt;td&gt;100&amp;ndash;1000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Seismograms (observed and synthetic)&lt;/td&gt;
&lt;td&gt;1-1000 TB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Elastic structure (3D mesh)&lt;/td&gt;
&lt;td&gt;1-1000 GB&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Simulate one earthquake&lt;/td&gt;
&lt;td&gt;100-1000 CPU hours&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Optimization iterations&lt;/td&gt;
&lt;td&gt;~30&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;ul&gt;
&lt;li&gt;Problem: Local minima when high-frequency windows are included in early iterations.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;adaptable-seismic-data-format-https-asdf-definition-readthedocs-io-en-latest-big-picture-html-based-on-hdf5&#34;&gt;&lt;a href=&#34;https://asdf-definition.readthedocs.io/en/latest/big_picture.html&#34; target=&#34;_blank&#34;&gt;Adaptable Seismic Data Format&lt;/a&gt; (based on HDF5)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://asdf-definition.readthedocs.io/en/latest/_images/ASDF_container.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://camo.githubusercontent.com/5be343ed266374f6108049a952b8be81e984ba27/68747470733a2f2f7261772e6769746875622e636f6d2f6f627370792f776562736974652f6d61737465722f6c6f676f2f6f627370795f6c6f676f5f66756c6c5f686967687265732e706e67&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;parallelism-in-machine-learning&#34;&gt;Parallelism in Machine Learning&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://unixer.de/publications/img/distdl-preprint.pdf&#34; target=&#34;_blank&#34;&gt;http://unixer.de/publications/img/distdl-preprint.pdf&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=xtxxLWZznBI&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;bennun-parallel-dl.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;bennun-parallel-param.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;curse-of-dimensionality&#34;&gt;Curse of dimensionality&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
import numpy as np
plt.style.use(&#39;ggplot&#39;)
plt.rc(&#39;figure&#39;, figsize=(12,8))

def hypercube(d):
    return dict(name=&#39;hypercube&#39;, dim=d, npoints=2**d, volume=1)

def simplex(d):
    return dict(name=&#39;simplex&#39;, dim=d, npoints=d+1, volume=1/np.math.factorial(d))

df = pandas.DataFrame([hypercube(d) for d in range(1,20)] + [simplex(d) for d in range(1,20)])
df.head()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;dim&lt;/th&gt;
      &lt;th&gt;npoints&lt;/th&gt;
      &lt;th&gt;volume&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;0&lt;/th&gt;
      &lt;td&gt;hypercube&lt;/td&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;1&lt;/th&gt;
      &lt;td&gt;hypercube&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;2&lt;/th&gt;
      &lt;td&gt;hypercube&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;3&lt;/th&gt;
      &lt;td&gt;hypercube&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;4&lt;/th&gt;
      &lt;td&gt;hypercube&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;1.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df.tail()
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;name&lt;/th&gt;
      &lt;th&gt;dim&lt;/th&gt;
      &lt;th&gt;npoints&lt;/th&gt;
      &lt;th&gt;volume&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;33&lt;/th&gt;
      &lt;td&gt;simplex&lt;/td&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;7.647164e-13&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;34&lt;/th&gt;
      &lt;td&gt;simplex&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;4.779477e-14&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;35&lt;/th&gt;
      &lt;td&gt;simplex&lt;/td&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;2.811457e-15&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;36&lt;/th&gt;
      &lt;td&gt;simplex&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;1.561921e-16&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;37&lt;/th&gt;
      &lt;td&gt;simplex&lt;/td&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;8.220635e-18&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.lineplot(x=&#39;npoints&#39;, y=&#39;volume&#39;, hue=&#39;name&#39;, data=df)
grid.axes.set(xscale=&#39;log&#39;, xlim=(1, 1e5));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_9_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MPI-IO and HDF5</title>
      <link>https://cucs-hpsc.github.io/fall2019/mpi-io/</link>
      <pubDate>Fri, 08 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/mpi-io/</guid>
      <description>

&lt;h2 id=&#34;mpi-io&#34;&gt;MPI-IO&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://press3.mcs.anl.gov//atpesc/files/2019/08/ATPESC_2019_Track-3_4_8-2_1030am_Latham-Introduction_to_MPI_IO.pdf&#34; target=&#34;_blank&#34;&gt;ATPESC 2019: Introduction to MPI-IO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;[ATPESC 2019:&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;unstructured-mesh-load-from-vÃ¡clav-hapla-https-geophysics-ethz-ch-people-person-detail-mjqxmdm0-tglzdc8xmjgyldexodqwmdm0mti-html&#34;&gt;Unstructured mesh load (from &lt;a href=&#34;https://geophysics.ethz.ch/people/person-detail.MjQxMDM0.TGlzdC8xMjgyLDExODQwMDM0MTI=.html&#34; target=&#34;_blank&#34;&gt;VÃ¡clav Hapla&lt;/a&gt;)&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;hapla-collective-hdf5.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hapla-collective-disappointment.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hapla-lustre.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hapla-scaling-1.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;hapla-dmplex-load-striped.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;daos-distributed-asynchronous-object-storage-https-daos-stack-github-io-overview-storage&#34;&gt;&lt;a href=&#34;https://daos-stack.github.io/overview/storage/&#34; target=&#34;_blank&#34;&gt;DAOS: Distributed Asynchronous Object Storage&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;daos-containers.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;cf-conventions-http-cfconventions-org&#34;&gt;&lt;a href=&#34;http://cfconventions.org/&#34; target=&#34;_blank&#34;&gt;CF conventions&lt;/a&gt;&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;CF = Climate and Forecast; widely used in earth sciences&lt;/li&gt;
&lt;li&gt;Based on NetCDF, which builds on top of HDF5&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cfconventions.org/Data/cf-conventions/cf-conventions-1.7/cf-conventions.html&#34; target=&#34;_blank&#34;&gt;Documented standard, v1.7&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cfconventions.org/Data/cf-standard-names/current/build/cf-standard-name-table.html&#34; target=&#34;_blank&#34;&gt;Standard Names Table&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://pumatest.nerc.ac.uk/cgi-bin/cf-checker.pl&#34; target=&#34;_blank&#34;&gt;Compliance checker&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;unstructured-mesh-formats&#34;&gt;Unstructured mesh formats&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;ExodusII (uses NetCDF uses HDF5)&lt;/li&gt;
&lt;li&gt;CGNS (uses HDF5)&lt;/li&gt;
&lt;li&gt;MED (uses HDF5)&lt;/li&gt;
&lt;li&gt;&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;squaremotor.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!ncdump -h squaremotor-30.exo
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;netcdf squaremotor-30 {
dimensions:
    len_string = 33 ;
    len_line = 81 ;
    four = 4 ;
    time_step = UNLIMITED ; // (0 currently)
    num_dim = 2 ;
    num_nodes = 719 ;
    num_elem = 659 ;
    num_el_blk = 2 ;
    num_qa_rec = 1 ;
    num_side_sets = 2 ;
    num_side_ss1 = 108 ;
    num_df_ss1 = 216 ;
    num_side_ss2 = 12 ;
    num_df_ss2 = 24 ;
    num_el_in_blk1 = 117 ;
    num_nod_per_el1 = 4 ;
    num_att_in_blk1 = 1 ;
    num_el_in_blk2 = 542 ;
    num_nod_per_el2 = 4 ;
    num_att_in_blk2 = 1 ;
variables:
    double time_whole(time_step) ;
    char qa_records(num_qa_rec, four, len_string) ;
    char coor_names(num_dim, len_string) ;
    char eb_names(num_el_blk, len_string) ;
    int ss_status(num_side_sets) ;
    int ss_prop1(num_side_sets) ;
        ss_prop1:name = &amp;quot;ID&amp;quot; ;
    char ss_names(num_side_sets, len_string) ;
    int elem_ss1(num_side_ss1) ;
    int side_ss1(num_side_ss1) ;
    double dist_fact_ss1(num_df_ss1) ;
    int elem_ss2(num_side_ss2) ;
    int side_ss2(num_side_ss2) ;
    double dist_fact_ss2(num_df_ss2) ;
    int elem_map(num_elem) ;
    int eb_status(num_el_blk) ;
    int eb_prop1(num_el_blk) ;
        eb_prop1:name = &amp;quot;ID&amp;quot; ;
    double attrib1(num_el_in_blk1, num_att_in_blk1) ;
    int connect1(num_el_in_blk1, num_nod_per_el1) ;
        connect1:elem_type = &amp;quot;SHELL4&amp;quot; ;
    double attrib2(num_el_in_blk2, num_att_in_blk2) ;
    int connect2(num_el_in_blk2, num_nod_per_el2) ;
        connect2:elem_type = &amp;quot;SHELL4&amp;quot; ;
    double coordx(num_nodes) ;
    double coordy(num_nodes) ;

// global attributes:
        :api_version = 4.98f ;
        :version = 4.98f ;
        :floating_point_word_size = 8 ;
        :file_size = 1 ;
        :title = &amp;quot;cubit(squaremotor-30.exo): 11/20/2012: 15:12:45&amp;quot; ;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!h5dump -H cylinder.med
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;HDF5 &amp;quot;cylinder.med&amp;quot; {
GROUP &amp;quot;/&amp;quot; {
   ATTRIBUTE &amp;quot;descripteur de fichier&amp;quot; {
      DATATYPE  H5T_STRING {
         STRSIZE 27;
         STRPAD H5T_STR_NULLTERM;
         CSET H5T_CSET_ASCII;
         CTYPE H5T_C_S1;
      }
      DATASPACE  SCALAR
   }
   GROUP &amp;quot;ENS_MAA&amp;quot; {
      GROUP &amp;quot;box_3d_1&amp;quot; {
         ATTRIBUTE &amp;quot;DES&amp;quot; {
            DATATYPE  H5T_STRING {
               STRSIZE 23;
               STRPAD H5T_STR_NULLTERM;
               CSET H5T_CSET_ASCII;
               CTYPE H5T_C_S1;
            }
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;DIM&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;ESP&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;NOM&amp;quot; {
            DATATYPE  H5T_STRING {
               STRSIZE 1;
               STRPAD H5T_STR_NULLTERM;
               CSET H5T_CSET_ASCII;
               CTYPE H5T_C_S1;
            }
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;NXI&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;NXT&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;REP&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;SRT&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;TYP&amp;quot; {
            DATATYPE  H5T_STD_I32LE
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;UNI&amp;quot; {
            DATATYPE  H5T_STRING {
               STRSIZE 1;
               STRPAD H5T_STR_NULLTERM;
               CSET H5T_CSET_ASCII;
               CTYPE H5T_C_S1;
            }
            DATASPACE  SCALAR
         }
         ATTRIBUTE &amp;quot;UNT&amp;quot; {
            DATATYPE  H5T_STRING {
               STRSIZE 1;
               STRPAD H5T_STR_NULLTERM;
               CSET H5T_CSET_ASCII;
               CTYPE H5T_C_S1;
            }
            DATASPACE  SCALAR
         }
         GROUP &amp;quot;-0000000000000000001-0000000000000000001&amp;quot; {
            ATTRIBUTE &amp;quot;CGT&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;NDT&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;NOR&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;NXI&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;NXT&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;PDT&amp;quot; {
               DATATYPE  H5T_IEEE_F64LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;PVI&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            ATTRIBUTE &amp;quot;PVT&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
            GROUP &amp;quot;MAI&amp;quot; {
               ATTRIBUTE &amp;quot;CGT&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;TE4&amp;quot; {
                  ATTRIBUTE &amp;quot;CGS&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;CGT&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;GEO&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;PFL&amp;quot; {
                     DATATYPE  H5T_STRING {
                        STRSIZE 24;
                        STRPAD H5T_STR_NULLTERM;
                        CSET H5T_CSET_ASCII;
                        CTYPE H5T_C_S1;
                     }
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;FAM&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SIMPLE { ( 161 ) / ( 161 ) }
                     ATTRIBUTE &amp;quot;CGT&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                     ATTRIBUTE &amp;quot;NBR&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                  }
                  DATASET &amp;quot;NOD&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SIMPLE { ( 644 ) / ( 644 ) }
                     ATTRIBUTE &amp;quot;CGT&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                     ATTRIBUTE &amp;quot;NBR&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                  }
               }
               GROUP &amp;quot;TR3&amp;quot; {
                  ATTRIBUTE &amp;quot;CGS&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;CGT&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;GEO&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;PFL&amp;quot; {
                     DATATYPE  H5T_STRING {
                        STRSIZE 24;
                        STRPAD H5T_STR_NULLTERM;
                        CSET H5T_CSET_ASCII;
                        CTYPE H5T_C_S1;
                     }
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;FAM&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SIMPLE { ( 56 ) / ( 56 ) }
                     ATTRIBUTE &amp;quot;CGT&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                     ATTRIBUTE &amp;quot;NBR&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                  }
                  DATASET &amp;quot;NOD&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SIMPLE { ( 168 ) / ( 168 ) }
                     ATTRIBUTE &amp;quot;CGT&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                     ATTRIBUTE &amp;quot;NBR&amp;quot; {
                        DATATYPE  H5T_STD_I32LE
                        DATASPACE  SCALAR
                     }
                  }
               }
            }
            GROUP &amp;quot;NOE&amp;quot; {
               ATTRIBUTE &amp;quot;CGS&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               ATTRIBUTE &amp;quot;CGT&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               ATTRIBUTE &amp;quot;PFL&amp;quot; {
                  DATATYPE  H5T_STRING {
                     STRSIZE 24;
                     STRPAD H5T_STR_NULLTERM;
                     CSET H5T_CSET_ASCII;
                     CTYPE H5T_C_S1;
                  }
                  DATASPACE  SCALAR
               }
               DATASET &amp;quot;COO&amp;quot; {
                  DATATYPE  H5T_IEEE_F64LE
                  DATASPACE  SIMPLE { ( 168 ) / ( 168 ) }
                  ATTRIBUTE &amp;quot;CGT&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
               }
               DATASET &amp;quot;FAM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SIMPLE { ( 56 ) / ( 56 ) }
                  ATTRIBUTE &amp;quot;CGT&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
               }
            }
         }
      }
   }
   GROUP &amp;quot;FAS&amp;quot; {
      GROUP &amp;quot;box_3d_1&amp;quot; {
         GROUP &amp;quot;ELEME&amp;quot; {
            GROUP &amp;quot;F_2D_1&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_126&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_128&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_130&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_132&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_134&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_136&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_2D_2&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
            GROUP &amp;quot;F_3D_1&amp;quot; {
               ATTRIBUTE &amp;quot;NUM&amp;quot; {
                  DATATYPE  H5T_STD_I32LE
                  DATASPACE  SCALAR
               }
               GROUP &amp;quot;GRO&amp;quot; {
                  ATTRIBUTE &amp;quot;NBR&amp;quot; {
                     DATATYPE  H5T_STD_I32LE
                     DATASPACE  SCALAR
                  }
                  DATASET &amp;quot;NOM&amp;quot; {
                     DATATYPE  H5T_ARRAY { [80] H5T_STD_I8LE }
                     DATASPACE  SIMPLE { ( 1 ) / ( 1 ) }
                  }
               }
            }
         }
         GROUP &amp;quot;FAMILLE_ZERO&amp;quot; {
            ATTRIBUTE &amp;quot;NUM&amp;quot; {
               DATATYPE  H5T_STD_I32LE
               DATASPACE  SCALAR
            }
         }
      }
   }
   GROUP &amp;quot;INFOS_GENERALES&amp;quot; {
      ATTRIBUTE &amp;quot;MAJ&amp;quot; {
         DATATYPE  H5T_STD_I32LE
         DATASPACE  SCALAR
      }
      ATTRIBUTE &amp;quot;MIN&amp;quot; {
         DATATYPE  H5T_STD_I32LE
         DATASPACE  SCALAR
      }
      ATTRIBUTE &amp;quot;REL&amp;quot; {
         DATATYPE  H5T_STD_I32LE
         DATASPACE  SCALAR
      }
   }
}
}
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>HPC I/O</title>
      <link>https://cucs-hpsc.github.io/fall2019/io/</link>
      <pubDate>Wed, 06 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/io/</guid>
      <description>

&lt;h2 id=&#34;hiding-latency&#34;&gt;Hiding latency&lt;/h2&gt;

&lt;p&gt;Throughout this course, we&amp;rsquo;ve discussed ways in which computer architecture and algorithms hide latency.
* instruction-level parallelism
* SMT/SIMT multi-threading
* memory prefetch
* organizing data structures for streaming access and cache reuse
* tiling, etc.&lt;/p&gt;

&lt;p&gt;File latency is vastly higher than memory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from IPython.display import IFrame    
IFrame(&#39;https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#39;, width=1200, height=700)
&lt;/code&gt;&lt;/pre&gt;

&lt;iframe
    width=&#34;1200&#34;
    height=&#34;700&#34;
    src=&#34;https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#34;
    frameborder=&#34;0&#34;
    allowfullscreen
&gt;&lt;/iframe&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Device&lt;/th&gt;
&lt;th&gt;Bandwidth (GB/s)&lt;/th&gt;
&lt;th&gt;Cost (\$/TB)&lt;/th&gt;
&lt;th&gt;Seek Latency ($\mu$s)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;7200 RPM disk&lt;/td&gt;
&lt;td&gt;0.3&lt;/td&gt;
&lt;td&gt;50&lt;/td&gt;
&lt;td&gt;&amp;gt;3000&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;SSD (SATA 3.0)&lt;/td&gt;
&lt;td&gt;0.6&lt;/td&gt;
&lt;td&gt;100-200&lt;/td&gt;
&lt;td&gt;15-50&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;SSD/NVMe (PCIe-3 x4)&lt;/td&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;200-1000&lt;/td&gt;
&lt;td&gt;10-20&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;DRAM DDR4&lt;/td&gt;
&lt;td&gt;25&lt;/td&gt;
&lt;td&gt;5000&lt;/td&gt;
&lt;td&gt;0.1&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;&lt;img src=&#34;scientific-workflows.png&#34; alt=&#34;&#34; /&gt;
&lt;a href=&#34;http://www.pdsw.org/pdsw-discs18/slides/luttgau-pdsw-discs18-slides.pdf&#34; target=&#34;_blank&#34;&gt;slide credit&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&#34;how-much-storage-bandwidth-does-a-similation-need&#34;&gt;How much storage bandwidth does a similation need?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;nek_gpu_new3.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;wall_clock_per_timestep = 0.6
dofs_per_node = 1800 * 1e4
MBps_per_node = dofs_per_node * 8 / wall_clock_per_timestep / 1e6
dofs = 95e6
MBps = dofs * 8 / wall_clock_per_timestep / 1e6
MBps_per_node, MBps
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(240.0, 1266.6666666666667)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;seconds_per_day = 24 * 60 * 60
TB_per_day = MBps * seconds_per_day / 1e6 # TB
TB_per_day
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;109.44
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What if all nodes used storage at this rate?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;MBps_per_node * 4600 / 1e6 # TB/s
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1.104
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;TB_per_day * 4600 / 8 / 1e3 # PB/day
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;62.928
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;summit-file-systems-https-www-olcf-ornl-gov-for-users-system-user-guides-summit-summit-user-guide-file-systems&#34;&gt;&lt;a href=&#34;https://www.olcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/#file-systems&#34; target=&#34;_blank&#34;&gt;Summit File Systems&lt;/a&gt;&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Capacity: 250 PB&lt;/li&gt;
&lt;li&gt;Theoretical Bandwidth: 2.5 TB/s&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;storage-architecture&#34;&gt;Storage architecture&lt;/h2&gt;

&lt;h3 id=&#34;hadoop-file-system-medium-long-term-storage-collocated-with-compute-nodes&#34;&gt;Hadoop File System: Medium/long-term storage collocated with compute nodes&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;Client-Writes-Span-Cluster.PNG&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;hpc-style-parallel-storage&#34;&gt;HPC-style parallel storage&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;lockwood-parallel-storage.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.olcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/#file-systems&#34; target=&#34;_blank&#34;&gt;https://www.olcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/#file-systems&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;recommended-slide-decks&#34;&gt;Recommended slide decks&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://press3.mcs.anl.gov//atpesc/files/2019/08/ATPESC_2019_Track-3_1_8-2_830am_Carns-Principles_of_HPC_IO.pdf&#34; target=&#34;_blank&#34;&gt;ATPESC 2019: Principles of HPC I/O:Everything you always wanted to know about HPC I/O but were afraid to ask&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://press3.mcs.anl.gov//atpesc/files/2019/08/ATPESC_2019_Track-3_7_8-2_345pm_Lockwood-IO_Architectures_and_Technology.pdf&#34; target=&#34;_blank&#34;&gt;ATPESC 2019: I/O Architectures and Technology&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;burst-buffers-https-www-olcf-ornl-gov-for-users-system-user-guides-summit-summit-user-guide-burst-buffer&#34;&gt;&lt;a href=&#34;https://www.olcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/#burst-buffer&#34; target=&#34;_blank&#34;&gt;Burst buffers&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;Slide1-400x300.jpg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;nvme_ior_summit.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! strace python -c &#39;import numpy&#39; |&amp;amp; grep open
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/haswell/x86_64&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/haswell&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/x86_64&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/tls&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/haswell/x86_64&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/haswell&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/x86_64&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
stat(&amp;quot;/opt/pgi/linux86-64/19.4/mpi/openmpi/lib&amp;quot;, 0x7ffc51a1a890) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/tls/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/tls/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/tls/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/tls/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/paraview/lib/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/tls/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/tls/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/tls/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/tls/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/haswell/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/haswell/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/x86_64/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libc.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libpython3.7m.so.1.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libpython3.7m.so.1.0&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libpthread.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libpthread.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libdl.so.2&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libdl.so.2&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libutil.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libutil.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libm.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libm.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/locale/locale-archive&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/gconv/gconv-modules.cache&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/gconv/gconv-modules&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/bin/pyvenv.cfg&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;pyvenv.cfg&amp;quot;, O_RDONLY) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/home/jed/usr/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/petsc/lib/petsc/bin&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/codecs.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/codecs.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/__pycache__/aliases.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/aliases.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/__pycache__/utf_8.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/utf_8.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/__pycache__/latin_1.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/encodings/latin_1.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/io.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/io.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/abc.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/abc.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_bootlocale.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_bootlocale.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/usr/lib/python3.7/site-packages/__pycache__/site.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/os.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/os.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/stat.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/stat.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/posixpath.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/posixpath.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/genericpath.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/genericpath.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_collections_abc.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_collections_abc.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/imp.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/imp.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/types.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/types.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/warnings.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/warnings.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/__pycache__/machinery.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/machinery.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/__pycache__/util.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/util.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/__pycache__/abc.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/importlib/abc.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/contextlib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/contextlib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/collections/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/collections/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/operator.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/operator.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/keyword.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/keyword.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/heapq.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/heapq.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_heapq.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/reprlib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/reprlib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/functools.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/functools.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/tokenize.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/tokenize.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/re.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/re.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/enum.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/enum.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/sre_compile.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/sre_compile.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/sre_parse.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/sre_parse.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/sre_constants.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/sre_constants.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/copyreg.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/copyreg.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/token.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/token.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/site.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_sitebuiltins.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_sitebuiltins.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages/easy-install.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages/python_graph_core-1.8.2-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 4
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages/sphinxcontrib_spelling-4.2.0-py3.6-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/matplotlib-3.1.1-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 4
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/protobuf-3.10.0-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/pytest-cov.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/ruamel.yaml-0.16.5-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_applehelp-1.0.1-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/src/nbgrader&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 4
openat(AT_FDCWD, &amp;quot;/home/jed/.local/lib/python3.7/site-packages/jupyter-1.0.0-py3.7.egg&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 4
openat(AT_FDCWD, &amp;quot;/home/jed/src/meshio&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 4
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_devhelp-1.0.1-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_htmlhelp-1.0.2-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_jsmath-1.0.1-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_qthelp-1.0.2-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/sphinxcontrib_serializinghtml-1.1.3-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.component-4.5-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.deferredimport-4.3.1-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.deprecation-4.4.0-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.event-4.4-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.hookable-4.2.0-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.interface-4.6.0-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/zope.proxy-4.3.2-py3.7-nspkg.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/usr/lib/python3.7/site-packages&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/usr/lib/python3.7/site-packages/easy-install.pth&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/petsc/lib/petsc/bin&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/cu/hpsc/hpsc-class/content/fall2019/io&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/src/python-vote-core&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/home/jed/src/academic-admin&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/__future__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__future__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/_globals.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/_globals.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/__config__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__config__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/version.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/version.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/_distributor_init.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/_distributor_init.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/info.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/info.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/multiarray.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/multiarray.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/overrides.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/overrides.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/textwrap.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/textwrap.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_multiarray_umath.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libcblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libcblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/tls/haswell/x86_64/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/tls/haswell/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/tls/x86_64/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/tls/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/haswell/x86_64/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/haswell/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/x86_64/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libblas.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libgomp.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libgomp.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/sys/devices/system/cpu&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/sys/devices/system/cpu&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/datetime.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/datetime.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/etc/localtime&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/math.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_datetime.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/__pycache__/_inspect.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/_inspect.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/__pycache__/py3k.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/compat/py3k.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/pathlib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/pathlib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/fnmatch.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/fnmatch.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/ntpath.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ntpath.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/urllib/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/urllib/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/urllib&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/urllib/__pycache__/parse.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/urllib/parse.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/pickle.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/pickle.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/struct.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/struct.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_struct.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_compat_pickle.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_compat_pickle.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_pickle.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/umath.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/umath.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/numerictypes.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/numerictypes.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/numbers.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/numbers.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_string_helpers.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_string_helpers.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_type_aliases.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_type_aliases.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_dtype.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_dtype.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/numeric.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/numeric.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_exceptions.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_exceptions.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_asarray.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_asarray.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_ufunc_config.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_ufunc_config.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/collections&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/collections/__pycache__/abc.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/collections/abc.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/fromnumeric.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/fromnumeric.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_methods.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_methods.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/arrayprint.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/arrayprint.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/defchararray.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/defchararray.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/records.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/records.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/memmap.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/memmap.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/function_base.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/function_base.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/machar.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/machar.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/getlimits.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/getlimits.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/shape_base.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/shape_base.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/einsumfunc.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/einsumfunc.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_add_newdocs.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_add_newdocs.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_multiarray_tests.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_dtype_ctypes.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_dtype_ctypes.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_ctypes.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libffi.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libffi.so.6&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ctypes/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ctypes/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ctypes&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ctypes/__pycache__/_endian.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ctypes/_endian.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/proc/self/status&amp;quot;, O_RDONLY) = 3
openat(AT_FDCWD, &amp;quot;/proc/mounts&amp;quot;, O_RDONLY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/__pycache__/_internal.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/core/_internal.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/platform.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/platform.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/subprocess.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/subprocess.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/signal.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/signal.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_posixsubprocess.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/select.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/selectors.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/selectors.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/threading.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/threading.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/traceback.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/traceback.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/linecache.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/linecache.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_weakrefset.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_weakrefset.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/_pytesttester.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/_pytesttester.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/info.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/info.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/type_check.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/type_check.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/ufunclike.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/ufunclike.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/index_tricks.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/index_tricks.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/matrixlib/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/matrixlib/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/matrixlib&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/matrixlib/__pycache__/defmatrix.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/matrixlib/defmatrix.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/ast.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/ast.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/__pycache__/info.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/info.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/__pycache__/linalg.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/linalg.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/twodim_base.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/twodim_base.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/lapack_lite.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/liblapack.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/liblapack.so.3&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libgfortran.so.5&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libgfortran.so.5&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libgcc_s.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/libgcc_s.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/tls/haswell/x86_64/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/tls/haswell/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/tls/x86_64/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/tls/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/haswell/x86_64/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/haswell/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/x86_64/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/usr/lib/../lib/libquadmath.so.0&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/linalg/_umath_linalg.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/function_base.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/function_base.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/histograms.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/histograms.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/stride_tricks.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/stride_tricks.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/mixins.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/mixins.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/nanfunctions.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/nanfunctions.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/shape_base.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/shape_base.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/scimath.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/scimath.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/polynomial.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/polynomial.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/utils.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/utils.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/arraysetops.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/arraysetops.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/npyio.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/npyio.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/weakref.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/weakref.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/format.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/format.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/_datasource.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/_datasource.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/shutil.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/shutil.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/zlib.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libz.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libz.so.1&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/bz2.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/bz2.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/_compression.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/_compression.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_bz2.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libbz2.so.1.0&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libbz2.so.1.0&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/lzma.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lzma.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_lzma.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/liblzma.so.5&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/liblzma.so.5&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/grp.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/_iotools.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/_iotools.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/financial.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/financial.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/decimal.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/decimal.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_decimal.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libmpdec.so.2&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libmpdec.so.2&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/arrayterator.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/arrayterator.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/arraypad.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/arraypad.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/__pycache__/_version.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/lib/_version.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/__pycache__/_pocketfft.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/_pocketfft.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/_pocketfft_internal.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/__pycache__/helper.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/fft/helper.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/polynomial.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/polynomial.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/polyutils.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/polyutils.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/_polybase.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/_polybase.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/chebyshev.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/chebyshev.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/legendre.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/legendre.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/hermite.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/hermite.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/hermite_e.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/hermite_e.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/__pycache__/laguerre.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/polynomial/laguerre.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/__pycache__/_pickle.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/_pickle.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/mtrand.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/common.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/bounded_integers.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/mt19937.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/bit_generator.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/secrets.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/secrets.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/base64.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/base64.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/binascii.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/hmac.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/hmac.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_hashlib.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/R/lib/libcrypto.so.1.1&amp;quot;, O_RDONLY|O_CLOEXEC) = -1 ENOENT (No such file or directory)
openat(AT_FDCWD, &amp;quot;/etc/ld.so.cache&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/libcrypto.so.1.1&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/hashlib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/hashlib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_blake2.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_sha3.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/random.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/random.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/bisect.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/bisect.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_bisect.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/lib-dynload/_random.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/philox.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/pcg64.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/sfc64.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/random/generator.cpython-37m-x86_64-linux-gnu.so&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/__pycache__/ctypeslib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ctypeslib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/__pycache__/core.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/core.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/__pycache__/extras.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/ma/extras.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/result.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/result.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/util.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/util.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/case.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/case.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/difflib.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/difflib.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/logging/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/logging/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/string.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/string.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/pprint.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/pprint.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/suite.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/suite.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/loader.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/loader.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/main.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/main.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/argparse.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/argparse.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/gettext.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/gettext.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/locale.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/locale.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/runner.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/runner.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/__pycache__/signals.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/unittest/signals.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/__pycache__/__init__.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/__init__.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private&amp;quot;, O_RDONLY|O_NONBLOCK|O_CLOEXEC|O_DIRECTORY) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/__pycache__/utils.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/utils.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/__pycache__/tempfile.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/tempfile.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/__pycache__/decorators.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/decorators.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/__pycache__/nosetester.cpython-37.pyc&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
openat(AT_FDCWD, &amp;quot;/usr/lib/python3.7/site-packages/numpy/testing/_private/nosetester.py&amp;quot;, O_RDONLY|O_CLOEXEC) = 3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;pynamic-sierra.png&#34; alt=&#34;&#34; /&gt;
&lt;a href=&#34;https://www.osti.gov/servlets/purl/1088439&#34; target=&#34;_blank&#34;&gt;figure&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;further-reading&#34;&gt;Further reading&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://extremecomputingtraining.anl.gov/agenda-2019/&#34; target=&#34;_blank&#34;&gt;ATPESC 2019 Presentations&lt;/a&gt; (see August 2 slides)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=adHRqgtL4lE&amp;amp;list=PLGj2a3KTwhRY6N5GJG-kICMYfUBm6dK-L&#34; target=&#34;_blank&#34;&gt;ATPESC 2019 Videos: Data Intensive Computing and I/O&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://glennklockwood.blogspot.com/2014/05/hadoops-uncomfortable-fit-in-hpc.html?spref=tw&#34; target=&#34;_blank&#34;&gt;Hadoop&amp;rsquo;s Uncomfortable Fit in HPC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>ISPC, OpenMP target, OpenACC, and all that</title>
      <link>https://cucs-hpsc.github.io/fall2019/openmp-target/</link>
      <pubDate>Mon, 04 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/openmp-target/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
    from IPython.display import Markdown
    with open(filename) as f:
        contents = f.read()
    return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Architecture&lt;/th&gt;
&lt;th&gt;Directives&lt;/th&gt;
&lt;th&gt;SIMD&lt;/th&gt;
&lt;th&gt;SPMD&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Intel AVX+ (SIMD)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;#pragma omp simd&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://software.intel.com/sites/landingpage/IntrinsicsGuide/#&#34; target=&#34;_blank&#34;&gt;intrinsics&lt;/a&gt;&lt;/td&gt;
&lt;td&gt;&lt;a href=&#34;https://ispc.github.io/ispc.html&#34; target=&#34;_blank&#34;&gt;ISPC&lt;/a&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;CUDA (SIMT)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;#pragma omp target&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;C++ templates and other high-level APIs&lt;/td&gt;
&lt;td&gt;CUDA&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;ispc-intel-spmd-program-compiler-https-ispc-github-io-ispc-html&#34;&gt;&lt;a href=&#34;https://ispc.github.io/ispc.html&#34; target=&#34;_blank&#34;&gt;ISPC: Intel SPMD Program Compiler&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;We can program SIMT (e.g., CUDA) devices using directives, but we can also program SIMD (e.g., Intel CPUs) using a SPMD (CUDA-like, acronym comes from &amp;ldquo;single program&amp;rdquo; versus &amp;ldquo;single instruction&amp;rdquo;) programming model.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;simple-ispc.ispc&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;export void simple_ispc(uniform double vin[], uniform double vout[],
                        uniform int count) {
  foreach (index = 0 ... count) {
    double v = vin[index];
    if (v &amp;lt; 3.)
      v = v * v;
    else
      v = sqrt(v);
    vout[index] = v;
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This function is callable from native C code.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;simple.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;math.h&amp;gt;

void simple_ispc(double vin[], double vout[], int count);

void simple_c(double vin[], double vout[], int count) {
  for (int index=0; index&amp;lt;count; index++) {
    double v = vin[index];
    if (v &amp;lt; 3.)
      v = v * v;
    else
      v = sqrt(v);
    vout[index] = v;
  }
}

int main() {
  double vin[16], vout[16];
  for (int i = 0; i &amp;lt; 16; ++i)
    vin[i] = i;

  simple_ispc(vin, vout, 16);

  for (int i = 0; i &amp;lt; 16; ++i)
    printf(&amp;quot;%d: simple_ispc(%f) = %f\n&amp;quot;, i, vin[i], vout[i]);

  simple_c(vin, vout, 16);

  for (int i = 0; i &amp;lt; 16; ++i)
    printf(&amp;quot;%d: simple_c(%f) = %f\n&amp;quot;, i, vin[i], vout[i]);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! make -B simple &amp;amp;&amp;amp; ./simple
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -O3 -march=native   -c -o simple.o simple.c
ispc -O3 --target=avx2-i32x8 simple-ispc.ispc -o simple-ispc.o
cc   simple.o simple-ispc.o  -lm -o simple
0: simple_ispc(0.000000) = 0.000000
1: simple_ispc(1.000000) = 1.000000
2: simple_ispc(2.000000) = 4.000000
3: simple_ispc(3.000000) = 1.732051
4: simple_ispc(4.000000) = 2.000000
5: simple_ispc(5.000000) = 2.236068
6: simple_ispc(6.000000) = 2.449490
7: simple_ispc(7.000000) = 2.645751
8: simple_ispc(8.000000) = 2.828427
9: simple_ispc(9.000000) = 3.000000
10: simple_ispc(10.000000) = 3.162278
11: simple_ispc(11.000000) = 3.316625
12: simple_ispc(12.000000) = 3.464102
13: simple_ispc(13.000000) = 3.605551
14: simple_ispc(14.000000) = 3.741657
15: simple_ispc(15.000000) = 3.872983
0: simple_c(0.000000) = 0.000000
1: simple_c(1.000000) = 1.000000
2: simple_c(2.000000) = 4.000000
3: simple_c(3.000000) = 1.732051
4: simple_c(4.000000) = 2.000000
5: simple_c(5.000000) = 2.236068
6: simple_c(6.000000) = 2.449490
7: simple_c(7.000000) = 2.645751
8: simple_c(8.000000) = 2.828427
9: simple_c(9.000000) = 3.000000
10: simple_c(10.000000) = 3.162278
11: simple_c(11.000000) = 3.316625
12: simple_c(12.000000) = 3.464102
13: simple_c(13.000000) = 3.605551
14: simple_c(14.000000) = 3.741657
15: simple_c(15.000000) = 3.872983
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! objdump -d --prefix-addresses -M intel simple | grep sqrt
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0000000000001050 &amp;lt;sqrt@plt&amp;gt; jmp    QWORD PTR [rip+0x2fd2]        # 0000000000004028 &amp;lt;sqrt@GLIBC_2.2.5&amp;gt;
0000000000001056 &amp;lt;sqrt@plt+0x6&amp;gt; push   0x2
000000000000105b &amp;lt;sqrt@plt+0xb&amp;gt; jmp    0000000000001020 &amp;lt;.plt&amp;gt;
00000000000012ec &amp;lt;simple_c+0x4c&amp;gt; vsqrtsd xmm1,xmm0,xmm0
0000000000001302 &amp;lt;simple_c+0x62&amp;gt; call   0000000000001050 &amp;lt;sqrt@plt&amp;gt;
000000000000142d &amp;lt;simple_ispc___un_3C_und_3E_un_3C_und_3E_uni+0xdd&amp;gt; vsqrtpd ymm1,ymm4
0000000000001431 &amp;lt;simple_ispc___un_3C_und_3E_un_3C_und_3E_uni+0xe1&amp;gt; vsqrtpd ymm7,ymm5
000000000000156e &amp;lt;simple_ispc___un_3C_und_3E_un_3C_und_3E_uni+0x21e&amp;gt; vsqrtpd ymm2,ymm6
0000000000001577 &amp;lt;simple_ispc___un_3C_und_3E_un_3C_und_3E_uni+0x227&amp;gt; vsqrtpd ymm3,ymm7
000000000000168d &amp;lt;simple_ispc+0xdd&amp;gt; vsqrtpd ymm1,ymm4
0000000000001691 &amp;lt;simple_ispc+0xe1&amp;gt; vsqrtpd ymm7,ymm5
00000000000017ce &amp;lt;simple_ispc+0x21e&amp;gt; vsqrtpd ymm2,ymm6
00000000000017d7 &amp;lt;simple_ispc+0x227&amp;gt; vsqrtpd ymm3,ymm7
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ISPC is a good option for code with cross-lane dependencies or vector lane divergence (branches that affect some lanes differently than others).  Writing such code with intrinsics is laborious and compilers often do a poor job of inferring good vectorization strategies (despite &lt;code&gt;#pragma omp simd&lt;/code&gt; and the like).  An example of successful use of ISPC is Intel&amp;rsquo;s &lt;a href=&#34;https://www.embree.org/&#34; target=&#34;_blank&#34;&gt;Embree&lt;/a&gt; ray tracing engine.&lt;/p&gt;

&lt;p&gt;(As with most vendor-reported performance numbers, we can probably take this with a grain of salt. But it indicates that CPUs remain highly competitive for ray tracing.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;embree-performance.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;openmp-target-offload-and-openacc&#34;&gt;OpenMP target offload and OpenACC&lt;/h2&gt;

&lt;p&gt;CUDA is relatively hard to maintain and logic/tuning is spread out (between the kernel launch and the device code).  OpenMP target offload and OpenACC attempt to provide a more friendly story for maintenance and incremental migration of legacy code.&lt;/p&gt;

&lt;h3 id=&#34;terminology&#34;&gt;Terminology&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;CUDA Concept&lt;/th&gt;
&lt;th&gt;CUDA keyword&lt;/th&gt;
&lt;th&gt;OpenACC&lt;/th&gt;
&lt;th&gt;OpenMP &lt;code&gt;target&lt;/code&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Thread block&lt;/td&gt;
&lt;td&gt;&lt;code&gt;blockIdx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;gang&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;teams&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Warp&lt;/td&gt;
&lt;td&gt;(implicit)&lt;/td&gt;
&lt;td&gt;&lt;code&gt;worker&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;thread&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Thread&lt;/td&gt;
&lt;td&gt;&lt;code&gt;threadIdx&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;vector&lt;/code&gt;&lt;/td&gt;
&lt;td&gt;&lt;code&gt;simd&lt;/code&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;incremental-porting-with-unified-memory&#34;&gt;Incremental porting with unified memory&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;openacc-steps.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;

&lt;p&gt;OpenACC example from a Lattice-Boltzman miniapp&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-cpp&#34;&gt;void LBM::stream(Real* const __restrict a_f,
                 const Real* const __restrict a_f_post,
                 const int* a_loStr,
                 const int* a_hiStr,
                 const int* a_loAll,
                 const int* a_hiAll,
                 const int a_numPts) const
{

  const int* const __restrict latI = &amp;amp;m_lattice[0][0];
  const int* const __restrict latJ = &amp;amp;m_lattice[1][0];
  const int* const __restrict latK = &amp;amp;m_lattice[2][0];

  const int
    klo = a_loStr[2], khi = a_hiStr[2],
    jlo = a_loStr[1], jhi = a_hiStr[1],
    ilo = a_loStr[0], ihi = a_hiStr[0];

#pragma acc parallel loop independent collapse(3) \
        copyin(a_loAll[SPACEDIM],a_hiAll[SPACEDIM],a_f_post[a_numPts*m_numVels]) \
        copyout(a_f[a_numPts*m_numVels]) vector_length(256)
  for (int k = klo; k &amp;lt;= khi; ++k) {
    for (int j = jlo; j &amp;lt;= jhi; ++j) {
      for (int i = ilo; i &amp;lt;= ihi; ++i) {
#pragma acc loop seq independent
        for (int m = 0; m &amp;lt; NUMV; ++m) {
          const long int offset = m * a_numPts;
          const long int index0 = INDEX(i          ,           j,           k, a_loAll, a_hiAll);
          const long int index2 = INDEX(i - latI[m], j - latJ[m], k - latK[m], a_loAll, a_hiAll);
          a_f[index0 + offset]    = a_f_post[index2 + offset];  // new f comes from upwind
        }
      }
    }
  }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devblogs.nvidia.com/getting-started-openacc/&#34; target=&#34;_blank&#34;&gt;Getting started with OpenACC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://icl.cs.utk.edu/classes/cosc462/2017/pdf/OpenACC_3.pdf&#34; target=&#34;_blank&#34;&gt;Advanced OpenACC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openmp.org/resources/openmp-presentations/resources-openmp-presentations-sc18-booth-talks/&#34; target=&#34;_blank&#34;&gt;SC18 OpenMP Presentations (with videos)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://developer.download.nvidia.com/video/gputechconf/gtc/2019/presentation/s9353-openmp-5-for-accelerators-and-what-comes-next.pdf&#34; target=&#34;_blank&#34;&gt;OpenMP 5.0 for Accelerators and What Comes Next&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openacc.org/hackathons&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Hackathon series&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Practical CUDA</title>
      <link>https://cucs-hpsc.github.io/fall2019/cuda-practical/</link>
      <pubDate>Fri, 01 Nov 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/cuda-practical/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;GPUs have 2-4x greater floating point and bandwidth peak for the watts

&lt;ul&gt;
&lt;li&gt;also for the $ if you buy enterprise gear&lt;/li&gt;
&lt;li&gt;better for the $ if you buy gaming gear&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Step 1 is to assess workload and latency requirements&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;VecDot_CPU_vs_GPU_size.png&#34; alt=&#34;&#34; /&gt;
&lt;img src=&#34;VecDot_CPU_vs_GPU_time.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Don&amp;rsquo;t waste time with GPUs if

&lt;ul&gt;
&lt;li&gt;your problem size or time to solution requirements don&amp;rsquo;t align&lt;/li&gt;
&lt;li&gt;if the work you&amp;rsquo;d like to move to the GPU is not a bottleneck&lt;/li&gt;
&lt;li&gt;if the computation cost will be dwarfed by moving data to/from the GPU&lt;/li&gt;
&lt;li&gt;often you need to restructure so that caller passes in data already on the device&lt;/li&gt;
&lt;li&gt;can require nonlocal refactoring&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Almost never: pick one kernel at a time and move it to the GPU

&lt;ul&gt;
&lt;li&gt;DOE ACME/E3SM (to pick on one high-profile application) has basically done this for five years and it still doesn&amp;rsquo;t help their production workloads so they bought a non-GPU machine
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Okay, okay, okay.  What if I have the right workload?&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&#34;terminology-intro&#34;&gt;Terminology/intro&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devblogs.nvidia.com/even-easier-introduction-cuda/&#34; target=&#34;_blank&#34;&gt;An even easier introduction to CUDA&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model&#34; target=&#34;_blank&#34;&gt;CUDA Programming Model&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;On the CPU, we have a thread with vector registers/instructions&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;In CUDA, we write code inside a single vector lane (&amp;ldquo;confusingly&amp;rdquo; called a CUDA thread)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;To get inside the lane, we launch a &lt;strong&gt;kernel&lt;/strong&gt; from the CPU using special syntax&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;add&amp;lt;&amp;lt;&amp;lt;numBlocks, blockSize&amp;gt;&amp;gt;&amp;gt;(N, x, y);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;needs to be compiled using &lt;code&gt;nvcc&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Logically 1D/2D/3D rectangular tiled iteration space&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;grid-of-thread-blocks.png&#34; width=&#34;40%&#34;&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;There are &lt;a href=&#34;https://en.wikipedia.org/wiki/CUDA#Version_features_and_specifications&#34; target=&#34;_blank&#34;&gt;many&lt;/a&gt; constraints and limitations to the iteration &amp;ldquo;grid&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;cuda-constraints.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Control flow for CUDA threads is nominally independent, but performance will be poor if you don&amp;rsquo;t coordinate threads within each block.

&lt;ul&gt;
&lt;li&gt;Implicit coordination&lt;/li&gt;
&lt;li&gt;Memory coalescing&lt;/li&gt;
&lt;li&gt;Organize your algorithm to limit &amp;ldquo;divergence&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Explicit coordination&lt;/li&gt;
&lt;li&gt;Shared memory&lt;/li&gt;
&lt;li&gt;&lt;code&gt;__syncthreads()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Warp shuffles&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;We implement the kernel by using the &lt;code&gt;__global__&lt;/code&gt; attribute

&lt;ul&gt;
&lt;li&gt;Visible from the CPU&lt;/li&gt;
&lt;li&gt;Special &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#built-in-variables&#34; target=&#34;_blank&#34;&gt;built-in variables&lt;/a&gt; are defined&lt;/li&gt;
&lt;li&gt;&lt;code&gt;gridDim&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;blockIdx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;blockDim&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;threadIdx&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;There is also &lt;code&gt;__device__&lt;/code&gt;, which is callable from other device functions&lt;/li&gt;
&lt;li&gt;Can use &lt;code&gt;__host__ __device__&lt;/code&gt; to compile two versions&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;cuda_indexing.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;how-does-this-relate-to-the-hardware&#34;&gt;How does this relate to the hardware?&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Each thread block is assigned to one streaming multiprocessor (SM)&lt;/li&gt;
&lt;li&gt;Executed in warps (number of hardware lanes)&lt;/li&gt;
&lt;li&gt;Multiple warps (from the same or different thread blocks) execute like hyperthreads&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;practical-cuda&#34;&gt;Practical CUDA&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://images.dailykos.com/images/201610/story_image/Question_authority_says_who_Capture.PNG?1454006844&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;cuda-best-practices-guide-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html&#34;&gt;&lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html&#34; target=&#34;_blank&#34;&gt;CUDA Best Practices Guide&lt;/a&gt;&lt;/h3&gt;

&lt;h4 id=&#34;occupancy&#34;&gt;Occupancy&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;Thread instructions are executed sequentially in CUDA, and, as a result, executing other warps when one warp is paused or stalled is the only way to hide latencies and keep the hardware busy. Some metric related to the number of active warps on a multiprocessor is therefore important in &lt;strong&gt;determining how effectively the hardware is kept busy&lt;/strong&gt; [emphasis added]. This metric is occupancy.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;Reality: occupancy is just one aspect, and often inversely correlated with keeping the hardware busy (and with performance).&lt;/li&gt;
&lt;/ul&gt;

&lt;blockquote&gt;
&lt;p&gt;Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
&lt;li&gt;If your kernel uses fewer registers/less shared memory, more warps can be scheduled.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Register/shared memory usage is determined by the compiler.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
from IPython.display import Markdown
with open(filename) as f:
    contents = f.read()
return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)

render_c(&#39;add.cu&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;__global__ void add(int n, float *x, float *y) {
int index = blockIdx.x * blockDim.x + threadIdx.x;
int stride = blockDim.x * gridDim.x;
for (int i = index; i &amp;lt; n; i += stride)
y[i] += x[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! nvcc -arch sm_75 --resource-usage -c add.cu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &amp;lsquo;&lt;em&gt;Z3addiPfS&lt;/em&gt;&amp;rsquo; for &amp;lsquo;sm_75&amp;rsquo;
ptxas info    : Function properties for &lt;em&gt;Z3addiPfS&lt;/em&gt;
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 12 registers, 376 bytes cmem[0]&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;copy.cu&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;__global__ void copy(float *dst, float *src) {
int iblock = blockIdx.x + blockIdx.y * gridDim.x;
int index  = threadIdx.x + TILE_SIZE * iblock * blockDim.x;
float a[TILE_SIZE]; // allocated in registers
for (int i=0; i&amp;lt;TILE_SIZE; i++)
a[i] = src[index + i * blockDim.x];
for (int i=0; i&amp;lt;TILE_SIZE; i++)
dst[index + i * blockDim.x] = a[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! nvcc -arch sm_75 --resource-usage -DTILE_SIZE=16 -c copy.cu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &amp;lsquo;&lt;em&gt;Z4copyPfS&lt;/em&gt;&amp;rsquo; for &amp;lsquo;sm_75&amp;rsquo;
ptxas info    : Function properties for &lt;em&gt;Z4copyPfS&lt;/em&gt;
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 64 registers, 368 bytes cmem[0]&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;The &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-occupancy-calculator/index.html&#34; target=&#34;_blank&#34;&gt;Occupancy Calculator&lt;/a&gt; can compute occupancy based on the register and shared memory usage.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can tell the compiler to reduce register usage, sometimes at the expense of spills.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! nvcc -arch sm_75 --resource-usage -DTILE_SIZE=16 --maxrregcount 24 -c copy.cu
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &amp;lsquo;&lt;em&gt;Z4copyPfS&lt;/em&gt;&amp;rsquo; for &amp;lsquo;sm_75&amp;rsquo;
ptxas info    : Function properties for &lt;em&gt;Z4copyPfS&lt;/em&gt;
    80 bytes stack frame, 76 bytes spill stores, 76 bytes spill loads
ptxas info    : Used 24 registers, 368 bytes cmem[0]&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;further-reading&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Vasily Volkov (2010) &lt;a href=&#34;https://www.nvidia.com/content/GTC-2010/pdfs/2238_GTC2010.pdf&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Better Performance at Lower Occupancy&lt;/strong&gt;&lt;/a&gt; (slides)&lt;/li&gt;
&lt;li&gt;Vasily Volkov (2016) &lt;a href=&#34;https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Understanding Latency Hiding on GPUs&lt;/strong&gt;&lt;/a&gt; (very in-depth)&lt;/li&gt;
&lt;li&gt;Kasia Swirydowicz (2018) &lt;a href=&#34;https://www.paranumal.com/single-post/2018/03/02/Finite-Element-Stiffness-Matrix-Action-monolithic-kernel-optimization-on-Titan-V&#34; target=&#34;_blank&#34;&gt;&lt;strong&gt;Finite Element Stiffness Matrix Action: monolithic kernel optimization on Titan V&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;memory&#34;&gt;Memory&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;GPU memory is not CPU memory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://en.wikichip.org/w/images/4/47/summit_single-socket.svg&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Duh&lt;/strong&gt;, so why does NVIDIA &lt;a href=&#34;https://devblogs.nvidia.com/unified-memory-cuda-beginners/&#34; target=&#34;_blank&#34;&gt;publish this&lt;/a&gt;?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://devblogs.nvidia.com/wp-content/uploads/2017/06/Unified-Memory-MultiGPU.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;getting-your-memory-into-position-is-often-the-hardest-part-of-cuda-programming&#34;&gt;Getting your memory into position is often the hardest part of CUDA programming.&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Allocate memory on the GPU&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;cudaMalloc(&amp;amp;xdevice, N*sizeof(double));
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Populate it from the host&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;cudaMemcpy(xdevice, xhost, N*sizeof(double), cudaMemcpyHostToDevice);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Repeat for all data, including control parameters&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Easy to forget, ongoing maintenance/complexity cost&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;unified-managed-memory-https-devblogs-nvidia-com-unified-memory-cuda-beginners&#34;&gt;&lt;a href=&#34;https://devblogs.nvidia.com/unified-memory-cuda-beginners/&#34; target=&#34;_blank&#34;&gt;Unified/managed memory&lt;/a&gt;&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Allocate &amp;ldquo;managed&amp;rdquo; memory, accessible from CPU and GPU&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;cudaMallocManaged(&amp;amp;x, N*sizeof(float));
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How?&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;maximizing-unified-memory.png&#34; width=&#34;50%&#34;&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;With OpenACC, make all dynamic allocations in managed memory: &lt;code&gt;pgcc -ta=tesla:managed&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;The GPU probably has a lot less memory than you have DRAM&lt;/li&gt;
&lt;li&gt;Really convenient for incremental work in legacy code&lt;/li&gt;
&lt;li&gt;Performance isn&amp;rsquo;t great without &lt;code&gt;cudaMemPrefetchAsync&lt;/code&gt;
&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;pngbase6479f3c9825c97fa94.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Further reading&lt;/strong&gt;: &lt;a href=&#34;https://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/&#34; target=&#34;_blank&#34;&gt;Maximizing Unified Memory Performance in CUDA&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;on-memory-coalescing-and-strided-access-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html-strided-accesses&#34;&gt;On memory coalescing and &lt;a href=&#34;https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#strided-accesses&#34; target=&#34;_blank&#34;&gt;strided access&lt;/a&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;__global__ void strideCopy(float *odata, float* idata, int stride) {
    int xid = (blockIdx.x*blockDim.x + threadIdx.x)*stride;
    odata[xid] = idata[xid];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;adjacent-threads-accessing-memory-with-stride-of-2.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Lose half your bandwidth for &lt;code&gt;stride=2&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;performance-of-stridecopy-kernel.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>GPUs and CUDA</title>
      <link>https://cucs-hpsc.github.io/fall2019/cuda/</link>
      <pubDate>Wed, 30 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/cuda/</guid>
      <description>

&lt;ul&gt;
&lt;li&gt;GPU vs CPU characterization&lt;/li&gt;
&lt;li&gt;CUDA preview&lt;/li&gt;
&lt;li&gt;Execution heirarchy&lt;/li&gt;
&lt;li&gt;Memory managerie&lt;/li&gt;
&lt;li&gt;Optimizations&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;graphics-processing-units&#34;&gt;Graphics Processing Units&lt;/h2&gt;

&lt;p&gt;Graphics Processing Units (GPUs) evolved from commercial demand for high-definition graphics.  HPC general purpose computing with GPUs picked up after programmable shaders were added in early 2000s.&lt;/p&gt;

&lt;p&gt;GPU compute performance relative to CPU is not magic, rather it is based on difference in goals; GPUs were unpolluted by CPU demands for user-adaptability.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;gpu-devotes-more-transistors-to-data-processing.png&#34; width=&#34;600&#34;/&gt;
&lt;center&gt;&lt;i&gt;Nvidia.com: real-estate difference&lt;/i&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;GPUs have no* branch prediction and no speculative execution.  (In the early days, computational uses even needed to implement their own error correction in software!)  Longer memory access latencies from tiny cache size is meant to be hidden behind co-resident compute.  The difference in mentality allowed GPUs to far surpass CPU compute efficiency.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;*: recent devices use branch prediction to group divergent threads&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;karlrupp.net_costpercomputetrend.png&#34; alt=&#34;karlrupp.net: compute efficiency&#34; /&gt;
&lt;center&gt;&lt;i&gt;karlrupp.net: compute efficiency&lt;/i&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;Power can dominant the cost in HPC. Consider the Summit supercomputer:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;#2 GREEN500 (was #3, but #1 was decomissioned)&lt;/li&gt;
&lt;li&gt;cost \$200 million to build&lt;/li&gt;
&lt;li&gt;13 MW to run compute+interconnect+file systems =&amp;gt; roughly \$7 million/year in raw electricity to power&lt;/li&gt;
&lt;li&gt;(does not count facilities/infrastructure cost to actually supply this power, nor cooling)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The drawbacks: GPU efficiency needs the problem to fit well into SIMD and have a relatively high computation intensity.&lt;/p&gt;

&lt;h2 id=&#34;cuda&#34;&gt;CUDA&lt;/h2&gt;

&lt;p&gt;Early general purpose computing GPU efforts required formulating problems in terms of graphics primatives (e.g. DirectX).&lt;/p&gt;

&lt;p&gt;NVIDIA publicly launched CUDA in 2006, allowing programming in C (and Fortran).&lt;/p&gt;

&lt;p&gt;Flash forward to 2019: AMD has its own language and there are also several vendor-independent languages (dominant: OpenCL), but CUDA still dominates overall.&lt;/p&gt;

&lt;p&gt;Nvidia maintains good documentation to ease adoption, like its &lt;a href=&#34;programming guide&#34; target=&#34;_blank&#34;&gt;https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;kernel-syntax-example&#34;&gt;Kernel syntax example&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;// Add two matrices A and B of size NxN and stores the result into matrix C:
// Kernel definition
__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i &amp;lt; N &amp;amp;&amp;amp; j &amp;lt; N)
        C[i][j] = A[i][j] + B[i][j];
}

int main()
{
    ...
    // Kernel invocation
    dim3 threadsPerBlock(16, 16);
    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
    MatAdd&amp;lt;&amp;lt;&amp;lt;numBlocks, threadsPerBlock&amp;gt;&amp;gt;&amp;gt;(A, B, C);
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;CUDA-specific additions:
* Kernels are defined with a &lt;code&gt;__global__&lt;/code&gt; specifier (when called by the host).
* &lt;code&gt;&amp;lt;&amp;lt;&amp;lt;numBlocks, threadsPerBlock&amp;gt;&amp;gt;&amp;gt;&lt;/code&gt; gives the &lt;em&gt;execution configuration&lt;/em&gt;.
* Ways for threads to query their location: &lt;code&gt;threadIdx&lt;/code&gt;, &lt;code&gt;blockIdx&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;thread-heirarchy&#34;&gt;Thread Heirarchy&lt;/h3&gt;

&lt;p&gt;Threads each have their own register allocation.  They are always executed in &amp;ldquo;SIMT&amp;rdquo; &lt;strong&gt;warps&lt;/strong&gt; of up to 32 (could change, but hasn&amp;rsquo;t yet).  This means:
* any divergence of instructions between threads within a warp causes some of the threads to no-op (relaxed recently);
* &lt;code&gt;product(threadsPerBlock)&lt;/code&gt; should be a multiple of 32 (maximum 1024) where possible.&lt;/p&gt;

&lt;p&gt;Blocks each have their own shared memory allocation.  All threads in a block are resident on the same processing core.  Thread layout can be up to three dimensions.
* can perform a lightweight synchronization within a block;
* co-resident blocks can be helpful at masking latency, but this is limited by block memory and register use.&lt;/p&gt;

&lt;p&gt;Blocks themselves are layed out on a &lt;strong&gt;grid&lt;/strong&gt; of up to three dimensions (on recent compute capabilities).  They must be logically executable in parallel or any serial order.
* no synchronization across blocks within a kernel;
* embarassingly parallel only, although caches can be reused.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;grid-of-thread-blocks.png&#34; width=&#34;400&#34;/&gt;
&lt;center&gt;&lt;i&gt;Nvidia.com: 2d grid and threads&lt;/i&gt;&lt;/center&gt;&lt;/p&gt;

&lt;h3 id=&#34;memory&#34;&gt;Memory&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;hardware-model.png&#34; width=&#34;400&#34;/&gt;
&lt;center&gt;&lt;i&gt;Nvidia.com: model of memory connections&lt;/i&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Global&lt;/strong&gt;, &lt;strong&gt;constant&lt;/strong&gt;, and &lt;strong&gt;texture&lt;/strong&gt; memories persist across kernel calls, and each has its own cache per SM (L2 cache shared by SMs).  By default, host and device are assumed to maintain separate memory:
* explicit device allocation and deallocation;
* explicit transfer between host and device.&lt;/p&gt;

&lt;p&gt;Alternatively, there is a &amp;ldquo;Unified Memory&amp;rdquo; configuration that automates these on an as-needed basis, pretending there is one common address space.&lt;/p&gt;

&lt;p&gt;Each block has &lt;strong&gt;shared&lt;/strong&gt; memory which tends to be fast (equivalent to a user-managed L1 cache).&lt;/p&gt;

&lt;p&gt;Each thread has &amp;ldquo;&lt;strong&gt;local&lt;/strong&gt;&amp;rdquo; memory (that is actually no more local than global memory!), which is mostly used for register spilling.  (Register and shared memory usage are reported by the compiler when compiling with the &lt;code&gt;-ptxas-options=-v&lt;/code&gt; option.)&lt;/p&gt;

&lt;h3 id=&#34;memory-transfer-example&#34;&gt;Memory transfer example&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;__global__ void VecAdd(float* A, float* B, float* C, int N)
{
    int i = blockDim.x * blockIdx.x + threadIdx.x;
    if (i &amp;lt; N)
        C[i] = A[i] + B[i];
}

int main()
{
    int N = ...;
    size_t size = N * sizeof(float);
    
    // Allocate input vectors h_A and h_B in host memory
    float* h_A = (float*)malloc(size);
    float* h_B = (float*)malloc(size);
    float* h_C = (float*)malloc(size);

    // Initialize input vectors
    ...

    
    // Allocate vectors in device memory
    float* d_A;
    cudaMalloc(&amp;amp;d_A, size);
    float* d_B;
    cudaMalloc(&amp;amp;d_B, size);
    float* d_C;
    cudaMalloc(&amp;amp;d_C, size);

    // Copy vectors from host memory to device memory
    cudaMemcpy(d_A, h_A, size, cudaMemcpyHostToDevice);
    cudaMemcpy(d_B, h_B, size, cudaMemcpyHostToDevice);


    // Invoke kernel
    int threadsPerBlock = 256;
    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;
    VecAdd&amp;lt;&amp;lt;&amp;lt;blocksPerGrid, threadsPerBlock&amp;gt;&amp;gt;&amp;gt;(d_A, d_B, d_C, N);


    // Copy result from device memory to host memory
    // h_C contains the result in host memory
    cudaMemcpy(h_C, d_C, size, cudaMemcpyDeviceToHost);

    // Free device memory
    cudaFree(d_A);
    cudaFree(d_B);
    cudaFree(d_C);
            
    // Free host memory
    ...
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;hline&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;optimization-details&#34;&gt;Optimization Details&lt;/h2&gt;

&lt;p&gt;Often details depend on the particular &amp;ldquo;compute capability&amp;rdquo; of the device.&lt;/p&gt;

&lt;h3 id=&#34;intrinsic-function-instructions&#34;&gt;Intrinsic function instructions&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;similar tradeoffs to &amp;ndash;ffast-math&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;memory-1&#34;&gt;Memory&lt;/h3&gt;

&lt;h4 id=&#34;hiding-memory-transfers&#34;&gt;Hiding Memory Transfers:&lt;/h4&gt;

&lt;p&gt;Memory transfers between host and device generally have the greatest latency.  Modern capabilities can hide data transfer between host and device by giving the device other tasks to work on and having the host use asynchronous versions of the transfer functions.&lt;/p&gt;

&lt;p&gt;This is managed through  &lt;strong&gt;streams&lt;/strong&gt; on the host, where cuda calls within a stream are guaranteed to execute on the device in order, but those between streams may be out of order or overlap &lt;em&gt;depending on the compute capability&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;To minimize waiting with the following code, the compute capability needs to allow concurrent data transfers, concurrent kernel execution, and overlap of data transfer and kernel execution.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;for (int i = 0; i &amp;lt; 2; ++i) {
    cudaMemcpyAsync(inputDevPtr + i * size, hostPtr + i * size,
                    size, cudaMemcpyHostToDevice, stream[i]);
    MyKernel &amp;lt;&amp;lt;&amp;lt;100, 512, 0, stream[i]&amp;gt;&amp;gt;&amp;gt;
          (outputDevPtr + i * size, inputDevPtr + i * size, size);
    cudaMemcpyAsync(hostPtr + i * size, outputDevPtr + i * size,
                    size, cudaMemcpyDeviceToHost, stream[i]);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;global-memory-access-size-and-alignment&#34;&gt;Global memory access size and alignment:&lt;/h4&gt;

&lt;p&gt;Example: an array of this struct would have elements that aren&amp;rsquo;t aligned if not for the &lt;code&gt;__align__(16)&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;struct __align__(16) {
    float x;
    float y;
    float z;
};
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This usually crops up with 2d arrays, which are more efficient if width-padded to a multiple of the warp size.&lt;/p&gt;

&lt;h4 id=&#34;coalescence&#34;&gt;Coalescence:&lt;/h4&gt;

&lt;p&gt;Global (and local*) memory requests must be &lt;strong&gt;coalesced&lt;/strong&gt;&amp;mdash;falling into the same 128-byte wide+aligned window (for all modern capabilities)&amp;mdash;or they will require multiple instructions.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;*: the compiler will generally ensure that local memory use is coalesced&lt;/em&gt;&lt;/p&gt;

&lt;h4 id=&#34;bank-distribution&#34;&gt;Bank Distribution:&lt;/h4&gt;

&lt;p&gt;Similar, but different from global-memory coalescence.  Shared memory is divided into &lt;strong&gt;banks&lt;/strong&gt; (typically 32), where each bank can be accessed simultaneously.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;six-examples-of-shared-memory-accesses.png&#34; width=&#34;450&#34;/&gt;
&lt;center&gt;&lt;i&gt;Nvidia.com: A) conflict-free, B) conflict depth 2, C) conflict-free, D) conflict-free, E) conflict-free, F) conflict-free&lt;/i&gt;&lt;/center&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;My impression is that most programmers rely on the compiler to sensibly structure bank accesses for temporary variables, but occasionally breaking into the &amp;ldquo;CUDA assembly&amp;rdquo; language &lt;code&gt;PTX&lt;/code&gt; will yeild significant performance improvements.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;The combination of coalescence and shared banks can cause an interesting interplay for certain problems.  Consider:
* Mx31 array made of structs of 2 32-bit floats.
* Coalescence would suggest padding the array to 32 wide when reading from global memory, but then once it resides in a shared memory with 32-bit strided banks, a warp of threads accessing the first of the pair of floats will cause bank conflicts of depth 2.
* Shared memory would be better served by padding the array width to 31.5.&lt;/p&gt;

&lt;p&gt;(the better solution might be to pull the struct apart&amp;hellip;)&lt;/p&gt;

&lt;h4 id=&#34;texture-specific-memory-features&#34;&gt;Texture-specific memory features:&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Optimized for 2d locality; can be faster than non-coalesced global/constant memory requests.&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Ability to automatically cast &lt;sup&gt;8&lt;/sup&gt;&amp;frasl;&lt;sub&gt;16&lt;/sub&gt;-bit integers into [0,1] 32-bit floats.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Coprocessor architectures</title>
      <link>https://cucs-hpsc.github.io/fall2019/coprocessor/</link>
      <pubDate>Mon, 28 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/coprocessor/</guid>
      <description>&lt;h2 id=&#34;coprocessor-architectures&#34;&gt;Coprocessor architectures&lt;/h2&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;https://en.wikichip.org/w/images/0/06/summit_single-node.svg&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;CUDA devices (NVIDIA)

&lt;ul&gt;
&lt;li&gt;Programmable via &lt;strong&gt;CUDA&lt;/strong&gt;, OpenACC, OpenMP-5, OpenCL, HIP-&amp;gt;CUDA, SYCL-&amp;gt;CUDA&lt;/li&gt;
&lt;li&gt;Example machine: &lt;a href=&#34;https://en.wikichip.org/wiki/supercomputers/summit&#34;&gt;OLCF Summit&lt;/a&gt; (details from &lt;a href=&#34;https://www.olcf.ornl.gov/for-users/system-user-guides/summit/summit-user-guide/&#34;&gt;user guide&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;ROCm devices (AMD)

&lt;ul&gt;
&lt;li&gt;Programmable via &lt;strong&gt;HIP&lt;/strong&gt;, OpenMP-5, OpenCL, SYCL-&amp;gt;HIP&lt;/li&gt;
&lt;li&gt;Example machine: &lt;a href=&#34;https://www.olcf.ornl.gov/wp-content/uploads/2019/05/frontier_specsheet_v4.pdf&#34;&gt;OLCF Frontier&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Intel X GPUs

&lt;ul&gt;
&lt;li&gt;Programmable via &lt;strong&gt;SYCL&lt;/strong&gt;, OpenMP-5, OpenCL?&lt;/li&gt;
&lt;li&gt;Example machine: &lt;a href=&#34;https://aurora.alcf.anl.gov/&#34;&gt;ALCF Aurora/A21&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Upcoming non-coprocessor Supercomputers

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.hpcwire.com/2019/05/23/riken-post-k-supercomputer-named-after-japans-tallest-peak/&#34;&gt;RIKEN Fugaku (Post-K)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.tacc.utexas.edu/systems/frontera&#34;&gt;TACC Frontera&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;fundamental-capabilities&#34;&gt;Fundamental capabilities&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from io import StringIO
import pandas
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;ggplot&#39;)

data = StringIO(&amp;quot;&amp;quot;&amp;quot;
package,cores,lanes/core,clock (MHz),peak (GF),bandwidth (GB/s),TDP (W),MSRP
Xeon 8280,28,8,2700,2400,141,205,10000
NVIDIA V100,80,64,1455,7800,900,300,10664
AMD MI60,64,64,1800,7362,1024,300,
AMD Rome,64,4,2000,2048,205,200,6450
&amp;quot;&amp;quot;&amp;quot;)

df = pandas.read_csv(data, index_col=&#39;package&#39;)
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;cores&lt;/th&gt;
      &lt;th&gt;lanes/core&lt;/th&gt;
      &lt;th&gt;clock (MHz)&lt;/th&gt;
      &lt;th&gt;peak (GF)&lt;/th&gt;
      &lt;th&gt;bandwidth (GB/s)&lt;/th&gt;
      &lt;th&gt;TDP (W)&lt;/th&gt;
      &lt;th&gt;MSRP&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;package&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon 8280&lt;/th&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;2700&lt;/td&gt;
      &lt;td&gt;2400&lt;/td&gt;
      &lt;td&gt;141&lt;/td&gt;
      &lt;td&gt;205&lt;/td&gt;
      &lt;td&gt;10000.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;NVIDIA V100&lt;/th&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1455&lt;/td&gt;
      &lt;td&gt;7800&lt;/td&gt;
      &lt;td&gt;900&lt;/td&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;10664.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;AMD MI60&lt;/th&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;1800&lt;/td&gt;
      &lt;td&gt;7362&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;300&lt;/td&gt;
      &lt;td&gt;NaN&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;AMD Rome&lt;/th&gt;
      &lt;td&gt;64&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;2000&lt;/td&gt;
      &lt;td&gt;2048&lt;/td&gt;
      &lt;td&gt;205&lt;/td&gt;
      &lt;td&gt;200&lt;/td&gt;
      &lt;td&gt;6450.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;amdahls-lawhttpsenwikipediaorgwikiamdahl27slaw-for-energy-efficiency&#34;&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34;&gt;Amdahl&#39;s Law&lt;/a&gt; for energy efficiency&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;efficiency (GF/W)&#39;] = df[&#39;peak (GF)&#39;] / df[&#39;TDP (W)&#39;]
df[&#39;efficiency (GF/W)&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;package
Xeon 8280      11.707317
NVIDIA V100    26.000000
AMD MI60       24.540000
AMD Rome       10.240000
Name: efficiency (GF/W), dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ngpu = np.arange(0, 9)
overhead = 100 # Power supply, DRAM, disk, etc.
peak = (ngpu == 0)*df.loc[&#39;Xeon 8280&#39;][&#39;peak (GF)&#39;] + ngpu*df.loc[&#39;NVIDIA V100&#39;][&#39;peak (GF)&#39;]
tdp = overhead + df.loc[&#39;Xeon 8280&#39;][&#39;TDP (W)&#39;] + ngpu*df.loc[&#39;NVIDIA V100&#39;][&#39;TDP (W)&#39;]
plt.plot(ngpu, peak / tdp)
plt.xlabel(&#39;number of GPUs per CPU&#39;)
plt.title(&#39;DP Peak efficiency (GF/W)&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_5_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;compare-to-green-500-listhttpswwwtop500orggreen500lists201906&#34;&gt;Compare to &lt;a href=&#34;https://www.top500.org/green500/lists/2019/06/&#34;&gt;Green 500 list&lt;/a&gt;&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.top500.org/system/179166&#34;&gt;#1 system&lt;/a&gt; is &lt;strong&gt;15.1 GF/W&lt;/strong&gt; (2x Xeon E5-2698v4, 8x V100)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.top500.org/system/179397&#34;&gt;#2 system&lt;/a&gt; (Summit) is &lt;strong&gt;14.7 GF/W&lt;/strong&gt; (2x Power9, 6x V100)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.top500.org/system/179683&#34;&gt;#27 system&lt;/a&gt; is &lt;strong&gt;5.8 GF/W&lt;/strong&gt; on Xeon 6248 (no GPU)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;amdahl-for-cost-efficiency&#34;&gt;Amdahl for cost efficiency&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;df[&#39;cost (GF/$)&#39;] = df[&#39;peak (GF)&#39;] / df[&#39;MSRP&#39;]
df[&#39;cost (GF/$)&#39;]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;package
Xeon 8280      0.240000
NVIDIA V100    0.731433
AMD MI60            NaN
AMD Rome       0.317519
Name: cost (GF/$), dtype: float64
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;overhead = 3000 + 2000*ngpu # power supply, memory, cooling, maintenance
cost = overhead + df.loc[&#39;Xeon 8280&#39;][&#39;MSRP&#39;] + ngpu*df.loc[&#39;NVIDIA V100&#39;][&#39;MSRP&#39;]
plt.plot(ngpu, peak / cost)
plt.xlabel(&#39;number of GPUs per CPU&#39;)
plt.title(&#39;DP cost efficiency (GF/$)&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;what-fraction-of-datacenter-cost-goes-to-the-power-bill&#34;&gt;What fraction of datacenter cost goes to the power bill?&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;OLCF Summit is reportedly a \$200M machine.&lt;/li&gt;
&lt;li&gt;What if we just buy the GPUs at retail?

&lt;ul&gt;
&lt;li&gt;256 racks&lt;/li&gt;
&lt;li&gt;18 nodes per rack&lt;/li&gt;
&lt;li&gt;6 GPUs per node&lt;/li&gt;
&lt;li&gt;V100 MSRP of about $10k&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;256 * 18 * 6 * 10e3 / 1e6 # millions
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;276.48
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Rule of thumb: $ \lesssim \$1M $ per MW-year&lt;/li&gt;
&lt;li&gt;We know Summit is a 13 MW facility&lt;/li&gt;
&lt;li&gt;Check &lt;a href=&#34;https://www.electricitylocal.com/states/tennessee/knoxville/&#34;&gt;industrial electricity rates&lt;/a&gt;
&lt;figure&gt;&lt;img src=&#34;knoxville-electricity.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;.0638 * 24 * 365
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;558.8879999999999
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;olcf-4-foia.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h2 id=&#34;programming-models&#34;&gt;Programming models&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Directives

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openmp.org/resources/refguides/&#34;&gt;OpenMP-5&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openacc.org/&#34;&gt;OpenACC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#pragma acc data copy(A) create(Anew)
while ( error &amp;gt; tol  &amp;amp;&amp;amp;  iter  &amp;lt;  iter_max )  {
  error = 0.0;
#pragma acc kernels {
#pragma acc loop independent collapse(2)
  for (  int  j = 1; j &amp;lt; n-1;  j++ )  {
    for (  int  i = 1; i &amp;lt; m-1; i++ )  {
       Anew [j] [i] = 0.25 * ( A [j] [i+1] + A [j] [i-1] +
                                      A [j-1] [i] + A [j+1] [i]);
       error = max ( error, fabs (Anew [j] [i] - A [j] [i]));
      }
    }
  } 
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Comparison slides: &lt;a href=&#34;https://openmpcon.org/wp-content/uploads/2018_Session1_Diaz.pdf&#34;&gt;Is OpenMP 4.5 Target Off-load Ready for Real Life? A Case Study of Three Benchmark Kernels (2018)&lt;/a&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Thread &amp;quot;kernel&amp;quot; and control

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://devblogs.nvidia.com/even-easier-introduction-cuda/&#34;&gt;CUDA&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rocm-documentation.readthedocs.io/en/latest/Programming_Guides/HIP-GUIDE.html&#34;&gt;HIP&lt;/a&gt; (&lt;a href=&#34;https://vimeo.com/channels/olcftraining/359154970&#34;&gt;video&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;C++ templated

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.khronos.org/sycl/&#34;&gt;SYCL&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/kokkos/kokkos&#34;&gt;Kokkos&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://raja.readthedocs.io/en/master/&#34;&gt;Raja&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>libCEED</title>
      <link>https://cucs-hpsc.github.io/fall2019/libceed/</link>
      <pubDate>Fri, 25 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/libceed/</guid>
      <description>&lt;p&gt;Guest lecture on &lt;a href=&#34;https://github.com/ceed/libceed&#34;&gt;libCEED&lt;/a&gt; from Dr. &lt;a href=&#34;https://csel-web.cs.colorado.edu/~vaba3353/&#34;&gt;Valeria Barra&lt;/a&gt;: &lt;a href=&#34;CUCS_HPSClecture.pdf&#34;&gt;slides&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;hpsc-lab-9&#34;&gt;HPSC Lab 9&lt;/h2&gt;

&lt;p&gt;2019-10-25&lt;/p&gt;

&lt;p&gt;We are going to run some PETSc examples and consider them as &amp;quot;baseline&amp;quot; for the libCEED examples that will follow.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

# You may need to change these for your machine
PETSC_DIR=$HOME/petsc-3.12.0 PETSC_ARCH=mpich-dbg

# Build the examples
make -C $PETSC_DIR -f gmakefile $PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex34
make -C $PETSC_DIR -f gmakefile $PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex45

# Link them from the current directory to make it easy to run below
cp -sf $PETSC_DIR/$PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex34 .
cp -sf $PETSC_DIR/$PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex45 .

./ex34 -pc_type none -da_grid_x 50 -da_grid_y 50 -da_grid_z 50 -ksp_monitor
#run with -ksp_view if you want to see details about the solver [preconditioning]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: Entering directory &#39;/home/jovyan/petsc-3.12.0&#39;
make: &#39;mpich-dbg/tests/ksp/ksp/examples/tutorials/ex34&#39; is up to date.
make: Leaving directory &#39;/home/jovyan/petsc-3.12.0&#39;
make: Entering directory &#39;/home/jovyan/petsc-3.12.0&#39;
make: &#39;mpich-dbg/tests/ksp/ksp/examples/tutorials/ex45&#39; is up to date.
make: Leaving directory &#39;/home/jovyan/petsc-3.12.0&#39;
  0 KSP Residual norm 1.184352528131e-01 
  1 KSP Residual norm 4.514009350561e-15 
Residual norm 4.63793e-15
Error norm 0.00130921
Error norm 0.000338459
Error norm 1.31699e-06
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Another variant with blocked jacobi as smoother:

! ./ex34 -da_grid_x 50 -da_grid_y 50 -da_grid_z 50 -pc_type ksp -ksp_ksp_type cg -ksp_pc_type bjacobi -ksp_monitor 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 1.251646233668e+02 
  1 KSP Residual norm 1.480869591053e-03 
  2 KSP Residual norm 5.120833590957e-09 
Residual norm 1.91909e-08
Error norm 0.00130992
Error norm 0.000338481
Error norm 1.31699e-06
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Another variant full multigrid preconditioning

! ./ex34 -pc_type mg -pc_mg_type full -ksp_type fgmres -ksp_monitor_short -pc_mg_levels 3 -mg_coarse_pc_factor_shift_type nonzero
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 1.00731 
  1 KSP Residual norm 0.0510812 
  2 KSP Residual norm 0.00248709 
  3 KSP Residual norm 0.000165921 
  4 KSP Residual norm 1.1586e-05 
  5 KSP Residual norm 8.71845e-07 
Residual norm 8.71845e-07
Error norm 0.0208751
Error norm 0.00618516
Error norm 0.000197005
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# For ex45, compare the number of iterations without precoditioning:

! ./ex45 -pc_type none -da_grid_x 21 -da_grid_y 21 -da_grid_z 21 -ksp_monitor
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 1.470306455035e+01 
  1 KSP Residual norm 2.526523006237e+00 
  2 KSP Residual norm 1.199024543393e+00 
  3 KSP Residual norm 8.017624157084e-01 
  4 KSP Residual norm 5.850738300493e-01 
  5 KSP Residual norm 4.643372450285e-01 
  6 KSP Residual norm 3.794775861442e-01 
  7 KSP Residual norm 3.182229782482e-01 
  8 KSP Residual norm 2.707869730107e-01 
  9 KSP Residual norm 2.342221169435e-01 
 10 KSP Residual norm 2.044268946887e-01 
 11 KSP Residual norm 1.799290014681e-01 
 12 KSP Residual norm 1.597128452355e-01 
 13 KSP Residual norm 1.424463131478e-01 
 14 KSP Residual norm 1.286048456000e-01 
 15 KSP Residual norm 1.180539437186e-01 
 16 KSP Residual norm 1.097826197330e-01 
 17 KSP Residual norm 1.006546027975e-01 
 18 KSP Residual norm 8.528703754785e-02 
 19 KSP Residual norm 6.502594142087e-02 
 20 KSP Residual norm 5.023918850795e-02 
 21 KSP Residual norm 4.014387264317e-02 
 22 KSP Residual norm 2.976949998851e-02 
 23 KSP Residual norm 2.038487027792e-02 
 24 KSP Residual norm 1.483308034344e-02 
 25 KSP Residual norm 1.094830085637e-02 
 26 KSP Residual norm 7.449788171631e-03 
 27 KSP Residual norm 5.269131329764e-03 
 28 KSP Residual norm 3.594369080540e-03 
 29 KSP Residual norm 2.262888004918e-03 
 30 KSP Residual norm 1.493039224295e-03 
 31 KSP Residual norm 1.107124599084e-03 
 32 KSP Residual norm 7.286598548293e-04 
 33 KSP Residual norm 4.716912759260e-04 
 34 KSP Residual norm 3.214892159593e-04 
 35 KSP Residual norm 2.214075669479e-04 
 36 KSP Residual norm 1.645224575275e-04 
 37 KSP Residual norm 1.190806015370e-04 
Residual norm 0.000119081
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# With the ones with preconditioning:

!./ex45 -da_grid_x 21 -da_grid_y 21 -da_grid_z 21 -pc_type mg -pc_mg_levels 3 -mg_levels_ksp_type richardson -mg_levels_ksp_max_it 1 -mg_levels_pc_type bjacobi -ksp_monitor
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 9.713869141172e+01 
  1 KSP Residual norm 1.457128977402e+00 
  2 KSP Residual norm 7.197915243881e-02 
  3 KSP Residual norm 6.946697263348e-04 
Residual norm 6.67463e-05
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;introduction-to-libceed&#34;&gt;Introduction to libCEED&lt;/h2&gt;

&lt;p&gt;libCEED is a low-level API library for the efficient
high-order discretization methods developed by the ECP co-design &lt;a href=&#34;http://ceed.exascaleproject.org&#34;&gt;Center for
Efficient Exascale Discretizations (CEED)&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;While our focus is on high-order finite elements, the approach is mostly
algebraic and thus applicable to other discretizations in factored form, as
explained in the API documentation portion of the &lt;a href=&#34;https://codedocs.xyz/CEED/libCEED/md_doc_libCEEDapi.html&#34;&gt;Doxygen documentation&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Clone or download libCEED by running&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! git clone https://github.com/CEED/libCEED.git
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# then compile it by running

! make -C libCEED -B


&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: Entering directory &#39;/home/jovyan/libCEED&#39;
make: &#39;lib&#39; with optional backends: /cpu/self/ref/memcheck /cpu/self/avx/serial /cpu/self/avx/blocked
          CC [38;5;177;1mbuild/interface[m/ceed-fortran.o
          CC [38;5;177;1mbuild/interface[m/ceed-basis.o
          CC [38;5;177;1mbuild/interface[m/ceed-elemrestriction.o
          CC [38;5;177;1mbuild/interface[m/ceed-operator.o
          CC [38;5;177;1mbuild/interface[m/ceed-vec.o
          CC [38;5;177;1mbuild/interface[m/ceed.o
          CC [38;5;177;1mbuild/interface[m/ceed-tensor.o
          CC [38;5;177;1mbuild/interface[m/ceed-qfunction.o
          CC [38;5;85;1mbuild/gallery/identity[m/ceed-identity.o
          CC [38;5;93;1mbuild/gallery/poisson3d[m/ceed-poisson3dapply.o
          CC [38;5;93;1mbuild/gallery/poisson3d[m/ceed-poisson3dbuild.o
          CC [38;5;155;1mbuild/gallery/mass1d[m/ceed-massapply.o
          CC [38;5;155;1mbuild/gallery/mass1d[m/ceed-mass1dbuild.o
          CC [38;5;41;1mbuild/gallery/mass2d[m/ceed-mass2dbuild.o
          CC [38;5;47;1mbuild/gallery/poisson1d[m/ceed-poisson1dapply.o
          CC [38;5;47;1mbuild/gallery/poisson1d[m/ceed-poisson1dbuild.o
          CC [38;5;67;1mbuild/gallery/mass3d[m/ceed-mass3dbuild.o
          CC [38;5;211;1mbuild/gallery/poisson2d[m/ceed-poisson2dapply.o
          CC [38;5;211;1mbuild/gallery/poisson2d[m/ceed-poisson2dbuild.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-basis.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-operator.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-qfunction.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-restriction.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-tensor.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref-vec.o
          CC [38;5;39;1mbuild/backends/ref[m/ceed-ref.o
          CC [38;5;63;1mbuild/backends/blocked[m/ceed-blocked-operator.o
          CC [38;5;63;1mbuild/backends/blocked[m/ceed-blocked.o
          CC [38;5;93;1mbuild/backends/opt[m/ceed-opt-blocked.o
          CC [38;5;93;1mbuild/backends/opt[m/ceed-opt-operator.o
          CC [38;5;93;1mbuild/backends/opt[m/ceed-opt-serial.o
          CC [38;5;55;1mbuild/backends/memcheck[m/ceed-memcheck-qfunction.o
          CC [38;5;55;1mbuild/backends/memcheck[m/ceed-memcheck.o
          CC [38;5;89;1mbuild/backends/avx[m/ceed-avx-blocked.o
          CC [38;5;89;1mbuild/backends/avx[m/ceed-avx-serial.o
          CC [38;5;89;1mbuild/backends/avx[m/ceed-avx-tensor.o
        LINK [38;5;97;1mlib[m/libceed.so
make: Leaving directory &#39;/home/jovyan/libCEED&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We are going to look at some libCEED&#39;s examples that use some PETSc&#39;s capabilities
(e.g., process partitioning and geometry handling).&lt;/p&gt;

&lt;p&gt;Check out my branch for the demo where I made a couple of changes to print more info for the tutorial.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash
cd libCEED

# checkout my branch for the demo
git checkout valeria/CUHPSC-demo

cd ~/

# And compile the examples by running
make -C libCEED/examples/petsc PETSC_DIR=$HOME/petsc-3.12.0 PETSC_ARCH=mpich-dbg -B

# Link them from the current directory to make it easy to run below
cp -sf libCEED/examples/petsc/bpsraw .
cp -sf libCEED/examples/petsc/multigrid .
&lt;/code&gt;&lt;/pre&gt;

&lt;hr&gt;

&lt;p&gt;To run the example solving the Poisson&#39;s equation on a structured grid, use&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./bpsraw -ceed /cpu/self/ref/serial -problem bp3 -degree 1 -local 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 2
    Number of 1D Quadrature Points (q) : 3
    Global nodes                       : 11466
    Process Decomposition              : 1 1 1
    Local Elements                     : 10000 = 20 20 25
    Owned nodes                        : 11466 = 21 21 26
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 2
    Final rnorm                        : 9.710169e-15
  Performance:
    CG Solve Time                      : 0.144075  sec
    DoFs/Sec in CG                     : 0.159167  million
    Pointwise Error (max)              : 2.079708e-02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;See what happens when you run this in parallel, let&#39;s say with 2 processes&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./bpsraw -ceed /cpu/self/ref/serial -problem bp3 -degree 1 -local 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 2
    Number of 1D Quadrature Points (q) : 3
    Global nodes                       : 22386
    Process Decomposition              : 2 1 1
    Local Elements                     : 10000 = 20 20 25
    Owned nodes                        : 10920 = 20 21 26
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 2
    Final rnorm                        : 1.327753e-14
  Performance:
    CG Solve Time                      : 0.229866  sec
    DoFs/Sec in CG                     : 0.194774  million
    Pointwise Error (max)              : 1.999130e-02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Instead, you can keep the total amount of work roughly constant, when you request more processes,
but divide the local size of the problem so that each process works roughly the same. For instance, compare&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./bpsraw -ceed /cpu/self/ref/serial -problem bp3 -degree 1 -local 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 2
    Number of 1D Quadrature Points (q) : 3
    Global nodes                       : 11466
    Process Decomposition              : 1 1 1
    Local Elements                     : 10000 = 20 20 25
    Owned nodes                        : 11466 = 21 21 26
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 2
    Final rnorm                        : 9.710169e-15
  Performance:
    CG Solve Time                      : 0.148991  sec
    DoFs/Sec in CG                     : 0.153915  million
    Pointwise Error (max)              : 2.079708e-02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;with&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 4 ./bpsraw -ceed /cpu/self/ref/serial -problem bp3 -degree 1 -local 2500
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 2
    Number of 1D Quadrature Points (q) : 3
    Global nodes                       : 11500
    Process Decomposition              : 2 2 1
    Local Elements                     : 2508 = 11 12 19
    Owned nodes                        : 2640 = 11 12 20
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 2
    Final rnorm                        : 9.925692e-15
  Performance:
    CG Solve Time                      : 0.041265  sec
    DoFs/Sec in CG                     : 0.557373  million
    Pointwise Error (max)              : 2.854310e-02
&lt;/code&gt;&lt;/pre&gt;

&lt;hr&gt;

&lt;h3 id=&#34;the-multigrid-example&#34;&gt;The multigrid example&lt;/h3&gt;

&lt;p&gt;This example solves the same problem, but by using a preconditioning strategy. We use Chebchev as the smoother (solver)
with Jacobi as the preconditioner for the smoother.&lt;/p&gt;

&lt;p&gt;Run&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./multigrid -ceed /cpu/self/ref/serial -problem bp3  -cells 1000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc + PCMG --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 3
    Number of 1D Quadrature Points (q) : 4
    Global Nodes                       : 49975
    Owned Nodes                        : 49975
  Multigrid:
    Number of Levels                   : 2
    Level 0 (coarse):
      Number of 1D Basis Nodes (p)     : 2
      Global Nodes                     : 3996
      Owned Nodes                      : 3996
    Level 1 (fine):
      Number of 1D Basis Nodes (p)     : 3
      Global Nodes                     : 49975
      Owned Nodes                      : 49975
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 26
    Final rnorm                        : 3.394703e-12
  PCMG:
    PCMG Type                          : MULTIPLICATIVE
    PCMG Cycle Type                    : v
  Performance:
    Pointwise Error (max)              : 4.270543e-02
    CG Solve Time                      : 19.3821 sec
    DoFs/Sec in CG                     : 0.0670388 million
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 4 ./multigrid -ceed /cpu/self/ref/serial -problem bp3  -cells 1000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc + PCMG --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 3
    Number of 1D Quadrature Points (q) : 4
    Global Nodes                       : 49975
    Owned Nodes                        : 6995
  Multigrid:
    Number of Levels                   : 2
    Level 0 (coarse):
      Number of 1D Basis Nodes (p)     : 2
      Global Nodes                     : 3996
      Owned Nodes                      : 0
    Level 1 (fine):
      Number of 1D Basis Nodes (p)     : 3
      Global Nodes                     : 49975
      Owned Nodes                      : 6995
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 26
    Final rnorm                        : 3.387644e-12
  PCMG:
    PCMG Type                          : MULTIPLICATIVE
    PCMG Cycle Type                    : v
  Performance:
    Pointwise Error (max)              : 4.270543e-02
    CG Solve Time                      : 33.2205 sec
    DoFs/Sec in CG                     : 0.0391129 million
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What do you see?&lt;/p&gt;

&lt;p&gt;Now let&#39;s raise the degree (accuracy of solution).
This will also increase the number of neighboring points we need information from, i.e., the number of nodes.&lt;/p&gt;

&lt;p&gt;Compare&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./multigrid -ceed /cpu/self/ref/serial -problem bp3 -degree 8 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc + PCMG --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 9
    Number of 1D Quadrature Points (q) : 10
    Global Nodes                       : 12167
    Owned Nodes                        : 12167
  Multigrid:
    Number of Levels                   : 8
    Level 0 (coarse):
      Number of 1D Basis Nodes (p)     : 2
      Global Nodes                     : 8
      Owned Nodes                      : 8
    Level 7 (fine):
      Number of 1D Basis Nodes (p)     : 9
      Global Nodes                     : 12167
      Owned Nodes                      : 12167
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 6
    Final rnorm                        : 3.132892e-11
  PCMG:
    PCMG Type                          : MULTIPLICATIVE
    PCMG Cycle Type                    : v
  Performance:
    Pointwise Error (max)              : 4.525195e-08
    CG Solve Time                      : 1.60019 sec
    DoFs/Sec in CG                     : 0.0456207 million
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;With&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./multigrid -ceed /cpu/self/ref/serial -problem bp3 -degree 8 -coarsen logarithmic
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;-- CEED Benchmark Problem 3 -- libCEED + PETSc + PCMG --
  libCEED:
    libCEED Backend                    : /cpu/self/ref/serial
  Mesh:
    Number of 1D Basis Nodes (p)       : 9
    Number of 1D Quadrature Points (q) : 10
    Global Nodes                       : 12167
    Owned Nodes                        : 12167
  Multigrid:
    Number of Levels                   : 4
    Level 0 (coarse):
      Number of 1D Basis Nodes (p)     : 2
      Global Nodes                     : 8
      Owned Nodes                      : 8
    Level 3 (fine):
      Number of 1D Basis Nodes (p)     : 9
      Global Nodes                     : 12167
      Owned Nodes                      : 12167
  KSP:
    KSP Type                           : cg
    KSP Convergence                    : CONVERGED_RTOL
    Total KSP Iterations               : 7
    Final rnorm                        : 1.970523e-11
  PCMG:
    PCMG Type                          : MULTIPLICATIVE
    PCMG Cycle Type                    : v
  Performance:
    Pointwise Error (max)              : 4.525156e-08
    CG Solve Time                      : 0.912013 sec
    DoFs/Sec in CG                     : 0.0933857 million
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Without specifying a coarsening strategy, it defaults to &lt;code&gt;-coarsen uniform&lt;/code&gt;.
This way, the domain is partitioned from finest grid to coarsest grid in a linear fashion, i.e.,
for &lt;code&gt;-degree 8&lt;/code&gt;, we run all intermediate levels given by&lt;/p&gt;

&lt;p&gt;8-&amp;gt;7-&amp;gt;6-&amp;gt;5-&amp;gt;...-&amp;gt;2-&amp;gt;1&lt;/p&gt;

&lt;p&gt;Instead, when we use &lt;code&gt;-coarsen logarithmic&lt;/code&gt; we have fewer subdivisions, using only powers of 2 as intermediate levels&lt;/p&gt;

&lt;p&gt;8-&amp;gt;4-&amp;gt;2-&amp;gt;1&lt;/p&gt;

&lt;hr&gt;

&lt;p&gt;Collect your experiments data and try to plot the accuracy gained
(given by the error, when the actual solution is available, otherwise by the digits of precision gained) vs time to solve&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Transient Problems</title>
      <link>https://cucs-hpsc.github.io/fall2019/transient/</link>
      <pubDate>Wed, 23 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/transient/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
import numpy as np
plt.style.use(&#39;ggplot&#39;)
plt.rc(&#39;figure&#39;, figsize=(12,8))
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;recap-nonlinear-solver-costs&#34;&gt;Recap: Nonlinear solver costs&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;for each nonlinear iteration

&lt;ul&gt;
&lt;li&gt;compute residual $F(u)$&lt;/li&gt;
&lt;li&gt;assemble matrix $J(u) = F&#39;(u)$&lt;/li&gt;
&lt;li&gt;setup preconditioner $M^{-1}(J, \dotsc)$&lt;/li&gt;
&lt;li&gt;for each linear iteration&lt;/li&gt;
&lt;li&gt;apply preconditioner $M^{-1} v$&lt;/li&gt;
&lt;li&gt;apply Jacobian $J v$&lt;/li&gt;
&lt;li&gt;Krylov vector work/inner products&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;shifting-costs&#34;&gt;Shifting costs&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Approximate Jacobian&lt;/li&gt;
&lt;li&gt;Less expensive preconditioner &lt;code&gt;-pc_type jacobi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Lag the preconditioner &lt;code&gt;-snes_lag_preconditioner&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Lag the Jacobian &lt;code&gt;-snes_lag_jacobian&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Matrix-free finite differencing to skip assembly of Jacobian &lt;code&gt;-snes_mf&lt;/code&gt; or &lt;code&gt;-snes_mf_operator&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A good PETSc example to test with: &lt;code&gt;src/snes/examples/tutorials/ex15.c&lt;/code&gt;&lt;/p&gt;

&lt;h2 id=&#34;transient-problems&#34;&gt;Transient problems&lt;/h2&gt;

&lt;p&gt;When solving time-dependent problems such as&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \dot u := \frac{\partial u(x,t)}{\partial t} = f\big(u(x,t), t\big) \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;we have a choice between explicit methods and implicit methods.  Explicit methods only require that we evaluate $f(u,t)$ on each time step while implicit methods require solves (linear or nonlinear).  To get a handle on this choice, we have to understand &lt;strong&gt;stability&lt;/strong&gt; and &lt;strong&gt;stiffness&lt;/strong&gt;.  First, we consider an explicit method for a scalar model problem,&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \dot u = -k (u - \cos t) \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;where $k$ is a parameter controlling the rate at which the solution $u(t)$ is pulled toward the curve $\cos t$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def ode_euler(f, u0, tfinal=1, h=0.1):
    u = np.array(u0)
    t = 0
    thist = [t]
    uhist = [u0]
    while t &amp;lt; tfinal:
        h = min(h, tfinal - t)
        u += h * f(t, u)
        t += h
        thist.append(t)
        uhist.append(u.copy())
    return np.array(thist), np.array(uhist)

tests = []

class fcos:
    def __init__(self, k=5):
        self.k = k
    def __repr__(self):
        return &#39;fcos(k={:d})&#39;.format(self.k)
    def f(self, t, u):
        return -self.k * (u - np.cos(t))
    def u(self, t, u0):
        k2p1 = self.k**2+1
        return (u0 - self.k**2/k2p1) * np.exp(np.array(-self.k*t)) + self.k*(np.sin(t) + self.k*np.cos(t))/k2p1

tests.append(fcos(k=2))
tests.append(fcos(k=20))

u0 = np.array([.2])
for test in tests:
    thist, uhist = ode_euler(test.f, u0, h=.021, tfinal=6)
    plt.plot(thist, uhist, &#39;.&#39;, label=repr(test)+&#39; Forward Euler&#39;)
    plt.plot(thist, test.u(thist, u0), label=repr(test)+&#39; exact&#39;)
plt.plot(thist, np.cos(thist), label=&#39;cos&#39;)
plt.legend(loc=&#39;upper right&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_3_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;As we increase the parameter $k$, we observe a greater separation of scales between the fast relaxation (characteristic time $1/k$) and the slow dynamics dictated by &lt;code&gt;cos(t)&lt;/code&gt;, which has characteristic time 1.  After the initial transient, we could approximate the solution accurately with large time steps, but the Forward Euler method that we&#39;re using here is unstable.  We&#39;ll now investigate why.&lt;/p&gt;

&lt;h3 id=&#34;linear-stability-analysis&#34;&gt;Linear Stability Analysis&lt;/h3&gt;

&lt;p&gt;Why did forward Euler diverge and how can we characterize methods that enable long time steps?  We can answer this by considering the test equation
&lt;span  class=&#34;math&#34;&gt;\( \dot u = \lambda u \)&lt;/span&gt;
and applying each method to construct
&lt;span  class=&#34;math&#34;&gt;\( \tilde u(h) = R(h\lambda) u(0) \)&lt;/span&gt;
where $R(z)$ is called the &lt;strong&gt;stability function&lt;/strong&gt;.&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[\begin{align} \tilde u(h) &amp;= u(0) + h \lambda u(0) &amp; R(z) &amp;= 1+z &amp; \text{Forward Euler} \\
 \tilde u(h) &amp;= u(0) + h \lambda \tilde u(h) &amp; R(z) &amp;= \frac{1}{1-z} &amp; \text{Backward Euler} \\
 \tilde u(h) &amp;= u(0) + h \lambda \frac{u(0) + \tilde u(h)}{2} &amp; R(z) &amp;= \frac{1+z/2}{1-z/2} &amp; \text{Midpoint}
\end{align}\]&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We can take $n$ steps via&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[\tilde u(hn) = \big( R(h \lambda) \big)^n u(0) \]&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Under what condition does this cause the solution to blow up?&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plot_stability(x, y, Rz, label):
    plt.figure()
    C = plt.contourf(xx, yy, np.abs(Rz), np.arange(0,2,.1), cmap=plt.cm.coolwarm)
    plt.colorbar(C, ticks=np.linspace(0, 2, 5))
    plt.axvline(x=0, linewidth=1, color=&#39;grey&#39;)
    plt.axhline(y=0, linewidth=1, color=&#39;grey&#39;)
    plt.contour(xx, yy, np.abs(Rz), np.arange(0,2,.5), colors=&#39;k&#39;)
    plt.title(label)

x = np.linspace(-2,2)
xx, yy = np.meshgrid(x, x)
zz = xx + 1j*yy
Rlist = [(&#39;Forward Euler&#39;, 1+zz),
        (&#39;Backward Euler&#39;, 1/(1-zz)),
        (&#39;Midpoint&#39;, (1+zz/2)/(1-zz/2))]
for Rlabel, R in Rlist:
    plot_stability(xx, yy, R, Rlabel)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_5_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_5_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_5_2.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;We can capture all of these methods in a family known as the $\theta$ method.&lt;/p&gt;

&lt;p&gt;We&#39;ll model our cosine decay equation as&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \dot u = \underbrace{A}_{-k} u + \underbrace{s(t)}_{k \cos t} \]&lt;/span&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def ode_theta_linear(A, u0, source, bcs=[], tfinal=1, h=0.1, theta=.5):
    u = u0.copy()
    t = 0.
    thist = [t]
    uhist = [u0]
    A = np.array(A, ndmin=2)
    I = np.eye(*A.shape)
    while t &amp;lt; tfinal:
        if tfinal - t &amp;lt; 1.01*h:
            h = tfinal - t
            tnext = tfinal
        else:
            tnext = t + h
        h = min(h, tfinal - t)
        rhs = (I + (1-theta)*h*A) @ u + h*source(t+theta*h)
        for i, f in bcs:
            rhs[i] = theta*h*f(t+theta*h, x[i])
        u = np.linalg.solve(I - theta*h*A, rhs)
        t = tnext
        thist.append(t)
        uhist.append(u.copy())
    return np.array(thist), np.array(uhist)

test = fcos(k=5000)
u0 = np.array([.2])
hist = ode_theta_linear(-test.k, u0,
                        lambda t: test.k*np.cos(t),
                        h=.1, tfinal=6, theta=.5)
plt.plot(hist[0], hist[1], &#39;o&#39;)
tt = np.linspace(0, 6, 200)
plt.plot(tt, test.u(tt,u0));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_7_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;observations&#34;&gt;Observations&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;$\theta=1$ is robust&lt;/li&gt;
&lt;li&gt;$\theta=1/2$ gets correct long-term behavior, but has oscillations at early times&lt;/li&gt;
&lt;li&gt;$\theta &amp;lt; 1/2$ allows oscillations to grow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;We say that a problem is &lt;strong&gt;stiff&lt;/strong&gt; when it has multiple time scales and the slower time scales can be approximated using larger steps than would be needed to resolve the fast scales.  This usually means that explicit methods are limited by stability rather than accuracy, and we should choose implicit methods to efficiently approximate the slow/long-term dynamics.  Examples of stiff problems:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Diffusion&lt;/li&gt;
&lt;li&gt;Elastic waves in quasi-static simulation&lt;/li&gt;
&lt;li&gt;Chemical reactions&lt;/li&gt;
&lt;li&gt;Low-Mach flows*&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;class flinear:
    def __init__(self, A):
        self.A = A.copy()
    def f(self, t, u):
        return self.A @ u
    def u(self, t, u0):
        from scipy.linalg import expm
        return expm(self.A*t) @ u0

def mms_error(h, theta):
    test = flinear(np.array([[0, 5], [-5, 0]]))
    u0 = np.array([1, 0])
    thist, uhist = ode_theta_linear(test.A, u0,
                                    lambda t: 0*u0, h=h, tfinal=3,
                                    theta=theta)
    return np.linalg.norm(uhist[-1] - test.u(thist[-1], u0), np.inf)

hs = np.geomspace(.002, 1, 20)
for theta in [0, .5, 0.6, 1]:
    errors = [mms_error(h, theta) for h in hs]
    plt.loglog(hs, errors, &#39;o&#39;, label=f&#39;numerical $\\theta = {theta}$&#39;)
for p in range(1,4):
    plt.loglog(hs, hs**p, label=&#39;$h^{%d}$&#39;%p)
plt.loglog(hs, 0*hs+1, &#39;k&#39;)
plt.xlabel(&#39;h&#39;)
plt.ylabel(&#39;error&#39;)
plt.legend(loc=&#39;lower right&#39;)
plt.ylim(top=10);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_9_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Only $\theta = 0.5$ converges at second order (slope matches the $h^2$ line).&lt;/li&gt;
&lt;li&gt;$\theta=0$ becomes unstable at a step size where $\theta=1$ already has very poor accuracy, but $\theta=0.5$ is less than 10% error.&lt;/li&gt;
&lt;li&gt;All stable methods have $O(1)$ error for sufficiently large steps.&lt;/li&gt;
&lt;li&gt;High order explicit methods (beyond the scope of this class, but widely available) could be much more accurate for sufficiently small steps, but would still not be stable with arbitrarily large time steps.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;automatic-step-size-control&#34;&gt;Automatic step size control&lt;/h3&gt;

&lt;p&gt;Some dynamical systems have rapid transitions that need short time steps, but long periods of slow dynamics in which large steps are possible.  Adaptive controllers can automatically choose step sizes for efficiency gains.  An example from chemical kinetics, using petsc4py:&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;oregonator.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;evaluating-accuracy-and-performance&#34;&gt;Evaluating accuracy and performance&lt;/h3&gt;

&lt;p&gt;Each method has an order of accuracy&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;error is $O(h^p)$

&lt;ul&gt;
&lt;li&gt;larger $p$ is important if you need lots of accuracy&lt;/li&gt;
&lt;li&gt;you might not need extreme accuracy&lt;/li&gt;
&lt;li&gt;accuracy might be limited by other approximations (collisions, spatial discretization, ...)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;multi-stage vs multi-step

&lt;ul&gt;
&lt;li&gt;Runge-Kutta methods take larger steps, but need to do work on each &amp;quot;stage&amp;quot;&lt;/li&gt;
&lt;li&gt;Rosenbrock methods can amortize costs over the stages&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Newton and Krylov methods might not converge (or converge more slowly) when taking steps that are too long

&lt;ul&gt;
&lt;li&gt;maybe need better preconditioners, multigrid, etc.&lt;/li&gt;
&lt;li&gt;or choose smaller time steps&lt;/li&gt;
&lt;li&gt;revisit formulation&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;adaptive error control

&lt;ul&gt;
&lt;li&gt;mostly heuristic, assuming asymptotic range&lt;/li&gt;
&lt;li&gt;controller stability&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;HairerWanner-WorkPrecision.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;further-reading&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Hairer, NÃ¸rsett, &lt;a href=&#34;https://link.springer.com/book/10.1007%2F978-3-540-78862-1&#34;&gt;&lt;strong&gt;Solving Ordinary Differential Equations I: Nonstiff Problems&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hairer and Wanner, &lt;a href=&#34;https://link.springer.com/book/10.1007%2F978-3-642-05221-7&#34;&gt;&lt;strong&gt;Solving Ordinary Differential Equations II: Stiff and Differential-Algebraic Problems&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Nonlinear Solvers</title>
      <link>https://cucs-hpsc.github.io/fall2019/nonlinear/</link>
      <pubDate>Mon, 21 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/nonlinear/</guid>
      <description>&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
import numpy as np
plt.style.use(&#39;ggplot&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;nonlinear-problems&#34;&gt;Nonlinear problems&lt;/h2&gt;

&lt;p&gt;Up to now, we have been solving linear problems.  The preferred way to leverage fast linear solves for (potentially ill-conditioned) nonlinear problems is via defect correction, usually Newton methods.&lt;/p&gt;

&lt;h3 id=&#34;the-newtonraphson-method-for-scalar-problems&#34;&gt;The Newton-Raphson method for scalar problems&lt;/h3&gt;

&lt;p&gt;Much of numerical analysis reduces to &lt;a href=&#34;https://en.wikipedia.org/wiki/Taylor_series&#34;&gt;Taylor series&lt;/a&gt;, the approximation
&lt;span  class=&#34;math&#34;&gt;\( f(x) = f(x_0) + f&#39;(x_0) (x-x_0) + \underbrace{f&#39;&#39;(x_0) (x - x_0)^2 / 2 + \dotsb}_{O((x-x_0)^2)} \)&lt;/span&gt;
centered on some reference point $x_0$.&lt;/p&gt;

&lt;p&gt;In numerical computation, it is exceedingly rare to look beyond the first-order approximation
&lt;span  class=&#34;math&#34;&gt;\( \tilde f_{x_0}(x) = f(x_0) + f&#39;(x_0)(x - x_0) . \)&lt;/span&gt;
Since $\tilde f_{x&lt;em&gt;0}(x)$ is a linear function, we can explicitly compute the unique solution of $\tilde f&lt;/em&gt;{x_0}(x) = 0$ as
&lt;span  class=&#34;math&#34;&gt;\( x = x_0 - f(x_0) / f&#39;(x_0) . \)&lt;/span&gt;
This is Newton&#39;s Method (aka Newton-Raphson or Newton-Raphson-Simpson) for finding the roots of differentiable functions.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def newton(func, x, verbose=False):
    &amp;quot;&amp;quot;&amp;quot;Solve f(x) = 0 using initial guess x.
    
    The provided function func must return a pair of values,
    f(x) and its derivative f&#39;(x).  For example, to solve
    the equation x^2 - 3 starting from initial guess x=1,
    one would write
    
    def func(x):
        return x**2 - 3, 2*x
        
    newton(func, 1)
    &amp;quot;&amp;quot;&amp;quot;
    for i in range(100):
        fx, dfx = func(x)
        if verbose:
            print(func.__name__, i, x, fx)
        if np.abs(fx) &amp;lt; 1e-12:
            return x, fx, i
        try:
            x -= fx / dfx
        except ZeroDivisionError:
            return x, np.NaN, i
        
def test_func(x):
    f = np.exp(x) - np.cos(x) - 1
    dfdx = np.exp(x) + np.sin(x)
    return f, dfdx

x0 = -2
root, _, _ = newton(test_func, x0, verbose=1)
x = np.linspace(min(x0,root)-1, max(x0,root+1))
plt.plot(x, test_func(x)[0])
plt.plot([x0,root], test_func([x0,root])[0], &#39;ok&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;test_func 0 -2 -0.44851788021624484
test_func 1 -2.579508809224632 -0.07804240445653787
test_func 2 -2.7502278755485423 -0.01169737888867406
test_func 3 -2.787065713793899 -0.0005874789197288788
test_func 4 -2.7891231086081634 -1.8550336560174685e-06
test_func 5 -2.7891296463678903 -1.874356225783913e-11
test_func 6 -2.7891296464339503 0.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_2_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;We say this method converges &lt;strong&gt;quadratically&lt;/strong&gt; since the number of correct digits doubles each iteration.&lt;/li&gt;
&lt;li&gt;The initial guess matters; a bad initial guess can take us to the wrong solution or cause divergence.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;systems-of-equations&#34;&gt;Systems of equations&lt;/h3&gt;

&lt;p&gt;We&#39;ve been solving linear systems, such as those resulting from discretizing linear PDE.  To address nonlinear problems (be they from PDE or otherwise), we&#39;ll express our problem as
&lt;span  class=&#34;math&#34;&gt;\( F(u) = 0 \)&lt;/span&gt;
where $u$ is a vector of state variables and $F(u)$ is a vector of residuals of the same length.
Note that linear problems can be written in this form, $F(u) = A u - b$.
We will primarily be interested in defect correction methods of the form
\begin{gather} A \delta u = - F(u) &lt;br&gt;
u \gets u + \gamma \delta u
\end{gather}
where $A$ is a matrix and $\gamma$ is a scalar parameter that may need to be found using an iteration.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;If $A = I$, this is a Richardson iteration, which is related to gradient descent.  Such methods are usually quite slow unless $F(u)$ is especially &amp;quot;nice&amp;quot;.&lt;/li&gt;
&lt;li&gt;If $A = \partial F/\partial u$, this is a Newton method and $\gamma=1$ can often be used.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;newtonraphson-methods-for-systems&#34;&gt;Newton-Raphson methods for systems&lt;/h2&gt;

&lt;p&gt;The &lt;strong&gt;Jacobian&lt;/strong&gt; of $F$ is
&lt;span  class=&#34;math&#34;&gt;\( J(u) = \frac{\partial F}{\partial u}(u) =
\begin{bmatrix} \frac{\partial F_0}{\partial u_0} &amp; \frac{\partial F_0}{\partial u_1} &amp; \dotsb \\
 \frac{\partial F_1}{\partial u_0} &amp; \frac{\partial F_1}{\partial u_1} &amp;  \\
 \vdots &amp; &amp; \ddots
 \end{bmatrix}(u) . \)&lt;/span&gt;
The method can be derived by taking the Taylor expansion of $F(u)$ at $u$,
&lt;span  class=&#34;math&#34;&gt;\( F(u + \delta u) = F(u) + \frac{\partial F}{\partial u}(u) (\delta u) + \frac{\partial^2 F}{\partial u^2}(u) (\delta u \otimes \delta u) / 2 + \dotsb \)&lt;/span&gt;
Note that each higher term is a higher rank tensor, thus computationally unweildy.  If we truncate the series with the linear term and set equal to zero, we have a linear equation for $\delta u$
&lt;span  class=&#34;math&#34;&gt;\( \frac{\partial F}{\partial u}(u) \delta u = - F(u) \)&lt;/span&gt;
which will hopefully make $F(u + \partial u) \approx 0$.  This is Newton&#39;s method.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Each iteration requires evaluating $F(u)$ -- almost any method will have this property.&lt;/li&gt;
&lt;li&gt;Each iteration requires evaluating the Jacobian matrix $J(u)$ -- this either requires custom code, algorithmic differentiation, or a finite difference approximation (we&#39;ll revisit this later).&lt;/li&gt;
&lt;li&gt;Each iteration requires solving a linear system with the matrix $J(u)$.  This may be expensive.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def fsolve_newton(F, J, u0, rtol=1e-10, maxit=50, verbose=False):
    u = u0.copy()
    Fu = F(u)
    norm0 = np.linalg.norm(Fu)
    enorm_last = np.linalg.norm(u - np.array([1,1]))
    for i in range(maxit):
        du = -np.linalg.solve(J(u), Fu)
        u += du
        Fu = F(u)
        norm = np.linalg.norm(Fu)
        if verbose:
            enorm = np.linalg.norm(u - np.array([1,1]))
            print(&#39;Newton {:d} anorm {:6.2e} rnorm {:6.2e} eratio {:6.2f}&#39;.
                  format(i+1, norm, norm/norm0, enorm/enorm_last**2))
            enorm_last = enorm
        if norm &amp;lt; rtol * norm0:
            break
    return u, i

def rostest(a,b):
    def F(u):
        x = u[0]; y = u[1]
        return np.array([-2*(a-x) + 4*b*x**3 - 4*b*x*y,
                         2*b*(y-x**2)])
    def J(u):
        x = u[0]; y = u[1]
        return np.array([[2 + 12*b*x**2 - 4*b*y, -4*b*x],
                         [-4*b*x, 2*b]])
    return F, J

F, J = rostest(1,3)
fsolve_newton(F, J, np.array([0, 1.]), verbose=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Newton 1 anorm 2.51e+00 rnorm 3.96e-01 eratio   1.56
Newton 2 anorm 9.91e+00 rnorm 1.57e+00 eratio   0.56
Newton 3 anorm 3.83e-01 rnorm 6.05e-02 eratio   0.22
Newton 4 anorm 5.11e-01 rnorm 8.08e-02 eratio   0.25
Newton 5 anorm 5.24e-04 rnorm 8.28e-05 eratio   0.36
Newton 6 anorm 9.76e-07 rnorm 1.54e-07 eratio   0.21
Newton 7 anorm 3.61e-15 rnorm 5.72e-16 eratio   0.31





(array([1., 1.]), 6)
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can the iteration break down?  How?&lt;/li&gt;
&lt;li&gt;How does the method depend on the initial guess?&lt;/li&gt;
&lt;li&gt;It turns out that Newton&#39;s method has &lt;em&gt;locally quadratic&lt;/em&gt; convergence to simple roots, &lt;span  class=&#34;math&#34;&gt;\(\lim_{i \to \infty} |e_{i+1}|/|e_i^2| &lt; \infty .\)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&amp;quot;The number of correct digits doubles each iteration.&amp;quot;&lt;/li&gt;
&lt;li&gt;Now that we know how to make a good guess accurate, the effort lies in getting a good guess.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;matrixfree-jacobian-via-finite-differencing&#34;&gt;Matrix-free Jacobian via finite differencing&lt;/h2&gt;

&lt;p&gt;It can be error-prone and complicated to implement the Jacobian function &lt;code&gt;J(u)&lt;/code&gt;.  In such cases, we can use the approximation&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ J(u) v \approx \frac{F(u+\epsilon v) - F(u)}{\epsilon} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;where $\epsilon$ is some &amp;quot;small&amp;quot; number.  Now can&#39;t access individual entries of $J$, but we can apply its action to an arbitrary vector $u$.&lt;/p&gt;

&lt;p&gt;We know that this approximation is first order accurate in $\epsilon$,
&lt;span  class=&#34;math&#34;&gt;\( \left\lVert J(u) v - \frac{F(u+\epsilon v) - F(u)}{\epsilon} \right\rVert \in O(\epsilon) . \)&lt;/span&gt;
But if $\epsilon$ is too small, we will lose accuracy due to rounding error.  If $F$ has been scaled such that its norm is of order 1, then $\epsilon = \sqrt{\epsilon_{\text{machine}}}$ is a good default choice.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import scipy.sparse.linalg as splinalg

def fsolve_newtonkrylov(F, u0, epsilon=1e-8, rtol=1e-10, maxit=50, verbose=False):
    u = u0.copy()
    Fu = F(u)
    norm0 = np.linalg.norm(Fu)
    for i in range(maxit):
        def Ju_fd(v):
            return (F(u + epsilon*v) - Fu) / epsilon
        Ju = splinalg.LinearOperator((len(Fu),len(u)), matvec=Ju_fd)
        du, info = splinalg.gmres(Ju, Fu, atol=1.e-6)
        if info != 0:
            print(np.linalg.norm(Ju @ du - Fu), norm)
            raise RuntimeError(&#39;GMRES failed to converge: {:d}&#39;.format(info))
        u -= du
        Fu = F(u)
        norm = np.linalg.norm(Fu)
        if verbose:
            print(&#39;Newton {:d} anorm {:6.2e} rnorm {:6.2e}&#39;
                  .format(i, norm, norm/norm0))
        if norm &amp;lt; rtol * norm0:
            break
    return u, i

fsolve_newtonkrylov(F, np.array([0.,1]), rtol=1e-6, verbose=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Newton 0 anorm 2.51e+00 rnorm 3.96e-01
Newton 1 anorm 9.91e+00 rnorm 1.57e+00
Newton 2 anorm 3.83e-01 rnorm 6.05e-02
Newton 3 anorm 5.11e-01 rnorm 8.08e-02
Newton 4 anorm 5.24e-04 rnorm 8.28e-05
Newton 5 anorm 9.76e-07 rnorm 1.54e-07





(array([1.        , 0.99999992]), 5)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;jacobianfree-newton-krylov-jfnk-and-preconditioning&#34;&gt;Jacobian-Free Newton Krylov (JFNK) and Preconditioning&lt;/h3&gt;

&lt;p&gt;While matrix-free finite differencing can save us the need to assemble the Jacobian (and write code to do that), there is no free lunch: Krylov convergence will be slow unless we have a good preconditioner.  But sometimes there are short-cuts: we can assemble a cheaper approximation for preconditioning, or develop multigrid methods that don&#39;t involve any assembled matrices.&lt;/p&gt;

&lt;h4 id=&#34;further-reading&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Knoll and Keyes (2004) &lt;a href=&#34;https://www.cs.odu.edu/~keyes/papers/jfnk.pdf&#34;&gt;&lt;strong&gt;Jacobian-free Newtonâ€“Krylov methods: a survey of approaches and applications&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;case-study-newtonkrylov-multigrid-methods-for-hydrostatic-ice-flow&#34;&gt;Case study: Newton-Krylov Multigrid methods for hydrostatic ice flow&lt;/h2&gt;

&lt;p&gt;This is a strongly nonlinear problem for which convergence of a high-resolution model stagnates if the initial guess isn&#39;t good.  It is, however, amenable to a method called grid sequencing where we solve coarse problems to generate initial guesses on the fine grid. At each grid level, we solve nonlinear problems using Newton-Krylov methods preconditioned by multigrid.&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;tme-ice-nk.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;tme-ice-its.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;tme-ice-breakdown.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h2 id=&#34;further-reading-1&#34;&gt;Further reading&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Brown, Smith, and Ahmadia (2013) &lt;a href=&#34;https://doi.org/10.1137/110834512&#34;&gt;&lt;strong&gt;Textbook multigrid efficiency for hydrostatic ice flow&lt;/strong&gt;&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Configuring an efficient nonlinear solver (see &lt;code&gt;snes/examples/tutorials/ex48.c&lt;/code&gt; in PETSc repository)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;costs&#34;&gt;Costs&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Residual evaluation $F(u)$&lt;/li&gt;
&lt;li&gt;Jacobian assembly $J(u) = F&#39;(u)$&lt;/li&gt;
&lt;li&gt;Preconditioner setup $M^{-1}$&lt;/li&gt;
&lt;li&gt;Jacobian application $J(u) v$&lt;/li&gt;
&lt;li&gt;Preconditioner application $M^{-1} v$&lt;/li&gt;
&lt;li&gt;Krylov vector work: inner products and vector axpy&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;shifting-costs&#34;&gt;Shifting costs&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Approximate Jacobian&lt;/li&gt;
&lt;li&gt;Less expensive preconditioner &lt;code&gt;-pc_type jacobi&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Lag the preconditioner &lt;code&gt;-snes_lag_preconditioner&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Lag the Jacobian &lt;code&gt;-snes_lag_jacobian&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Matrix-free finite differencing to skip assembly of Jacobian &lt;code&gt;-snes_mf&lt;/code&gt; or &lt;code&gt;-snes_mf_operator&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A good PETSc example to test with: &lt;code&gt;src/snes/examples/tutorials/ex15.c&lt;/code&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Multilevel Preconditioning</title>
      <link>https://cucs-hpsc.github.io/fall2019/mg-preconditioning/</link>
      <pubDate>Fri, 18 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/mg-preconditioning/</guid>
      <description>&lt;h2 id=&#34;recap-domain-decomposition-convergence-theory&#34;&gt;Recap: Domain Decomposition convergence theory&lt;/h2&gt;

&lt;p&gt;The formal convergence is beyond the scope of this course, but the following estimates are useful.  We let $h$ be the element diameter, $H$ be the subdomain diameter, and $\delta$ be the overlap, each normalized such that the global domain diameter is 1.  We express the convergence in terms of the condition number $\kappa$ for the preconditioned operator.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(Block) Jacobi: $\delta=0$, $\kappa \sim H^{-2} H/h = (Hh)^{-1}$&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz: $\kappa \sim H^{-2} H/\delta = (H \delta)^{-1}$&lt;/li&gt;
&lt;li&gt;2-level overlapping Schwarz: $\kappa \sim H/\delta$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;handson-with-petsc-demonstrate-these-estimates&#34;&gt;Hands-on with PETSc: demonstrate these estimates&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Linear Poisson with geometric multigrid: &lt;code&gt;src/ksp/ksp/examples/tutorials/ex29.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonlinear problems

&lt;ul&gt;
&lt;li&gt;Symmetric scalar problem: &lt;code&gt;src/snes/examples/tutorials/ex5.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonsymmetric system (lid/thermal-driven cavity): &lt;code&gt;src/snes/examples/tutorials/ex19.c&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Compare preconditioned versus unpreconditioned norms.&lt;/li&gt;
&lt;li&gt;Compare BiCG versus GMRES&lt;/li&gt;
&lt;li&gt;Compare domain decomposition and multigrid preconditioning

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-pc_type asm&lt;/code&gt; (Additive Schwarz)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_type basic&lt;/code&gt; (symmetric, versus &lt;code&gt;restrict&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_overlap 2&lt;/code&gt; (increase overlap)&lt;/li&gt;
&lt;li&gt;Effect of direct subdomain solver: &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_type mg&lt;/code&gt; (Geometric Multigrid)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Use monitors:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_true_residual&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_converged_reason&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Explain methods: &lt;code&gt;-snes_view&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Performance info: &lt;code&gt;-log_view&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;example-inhomogeneous-poisson&#34;&gt;Example: Inhomogeneous Poisson&lt;/h4&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ -\nabla\cdot \Big( \rho(x,y) \nabla u(x,y) \Big) = e^{-10 (x^2 + y^2)} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;in $\Omega = [0,1]^2$ with variable conductivity&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[
\rho(x,y) = \begin{cases}
\rho_0 &amp; (x,y) \in [1/3, 2/3]^2 \\
1 &amp; \text{otherwise}
\end{cases}
\]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;where $\rho_0 &amp;gt; 0$ is a parameter (with default $\rho_0 = 1$).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

# You may need to change these for your machine
PETSC_DIR=$HOME/petsc PETSC_ARCH=ompi-optg

# Build the example
make -C $PETSC_DIR -f gmakefile $PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex29

# Link it from the current directory to make it easy to run below
cp -sf $PETSC_DIR/$PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex29 .
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: Entering directory &#39;/home/jed/petsc&#39;
make: &#39;ompi-optg/tests/ksp/ksp/examples/tutorials/ex29&#39; is up to date.
make: Leaving directory &#39;/home/jed/petsc&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Prints solution DM and then a coordinate DM
! mpiexec -n 2 ./ex29 -da_refine 2 -dm_view
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DM Object: 2 MPI processes
  type: da
Processor [0] M 9 N 9 m 1 n 2 w 1 s 1
X range of indices: 0 9, Y range of indices: 0 5
Processor [1] M 9 N 9 m 1 n 2 w 1 s 1
X range of indices: 0 9, Y range of indices: 5 9
DM Object: 2 MPI processes
  type: da
Processor [0] M 9 N 9 m 1 n 2 w 2 s 1
X range of indices: 0 9, Y range of indices: 0 5
Processor [1] M 9 N 9 m 1 n 2 w 2 s 1
X range of indices: 0 9, Y range of indices: 5 9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_view_solution draw -draw_pause 5 -draw_cmap plasma
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This problem is nonsymmetric due to boundary conditions, though symmetric solvers like CG and MINRES may still converge&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_monitor_true_residual -ksp_view -ksp_type gmres
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP preconditioned resid norm 1.338744788815e-02 true resid norm 1.433852280437e-02 ||r(i)||/||b|| 1.000000000000e+00
  1 KSP preconditioned resid norm 6.105013156491e-03 true resid norm 8.819020609674e-03 ||r(i)||/||b|| 6.150578222039e-01
  2 KSP preconditioned resid norm 3.380566739974e-03 true resid norm 3.966597605983e-03 ||r(i)||/||b|| 2.766392089410e-01
  3 KSP preconditioned resid norm 2.248884854426e-03 true resid norm 1.950654466953e-03 ||r(i)||/||b|| 1.360429169426e-01
  4 KSP preconditioned resid norm 1.603958727893e-03 true resid norm 1.729343487982e-03 ||r(i)||/||b|| 1.206082043163e-01
  5 KSP preconditioned resid norm 1.017005335066e-03 true resid norm 1.108652090238e-03 ||r(i)||/||b|| 7.731982613301e-02
  6 KSP preconditioned resid norm 5.817999897588e-04 true resid norm 7.954596575686e-04 ||r(i)||/||b|| 5.547709958842e-02
  7 KSP preconditioned resid norm 3.102671011646e-04 true resid norm 4.651546500795e-04 ||r(i)||/||b|| 3.244090457755e-02
  8 KSP preconditioned resid norm 1.547863442961e-04 true resid norm 2.154582266646e-04 ||r(i)||/||b|| 1.502652885547e-02
  9 KSP preconditioned resid norm 7.772941255716e-05 true resid norm 1.166482147907e-04 ||r(i)||/||b|| 8.135302107631e-03
 10 KSP preconditioned resid norm 3.800559054824e-05 true resid norm 5.777187067722e-05 ||r(i)||/||b|| 4.029136854992e-03
 11 KSP preconditioned resid norm 1.694315416916e-05 true resid norm 3.229096611633e-05 ||r(i)||/||b|| 2.252042735288e-03
 12 KSP preconditioned resid norm 6.705763692270e-06 true resid norm 1.252406213904e-05 ||r(i)||/||b|| 8.734555372208e-04
 13 KSP preconditioned resid norm 2.308568861148e-06 true resid norm 4.636253434420e-06 ||r(i)||/||b|| 3.233424738152e-04
 14 KSP preconditioned resid norm 8.946501825242e-07 true resid norm 1.703002880989e-06 ||r(i)||/||b|| 1.187711526650e-04
 15 KSP preconditioned resid norm 2.744515348301e-07 true resid norm 5.751960627589e-07 ||r(i)||/||b|| 4.011543382863e-05
 16 KSP preconditioned resid norm 1.137618031844e-07 true resid norm 2.081989399152e-07 ||r(i)||/||b|| 1.452025029048e-05
KSP Object: 2 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 2 MPI processes
  type: bjacobi
    number of blocks = 2
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqaij
            rows=153, cols=153
            package used to perform factorization: petsc
            total: nonzeros=713, allocated nonzeros=713
            total number of mallocs used during MatSetValues calls =0
              not using I-node routines
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqaij
      rows=153, cols=153
      total: nonzeros=713, allocated nonzeros=713
      total number of mallocs used during MatSetValues calls =0
        not using I-node routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=289, cols=289
    total: nonzeros=1377, allocated nonzeros=1377
    total number of mallocs used during MatSetValues calls =0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;default-parallel-solver&#34;&gt;Default parallel solver&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Krylov method: GMRES

&lt;ul&gt;
&lt;li&gt;restart length of 30 to bound memory requirement and orthogonalization cost&lt;/li&gt;
&lt;li&gt;classical Gram-Schmidt (compare &lt;code&gt;-ksp_gmres_modifiedgramschmidt&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;left preconditioning, uses preconditioned norm
&lt;span  class=&#34;math&#34;&gt;\( P^{-1} A x = P^{-1} b \)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_norm_type unpreconditioned&lt;/code&gt;
&lt;span  class=&#34;math&#34;&gt;\( A P^{-1} (P x) = b \)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Can estimate condition number using Hessenberg matrix&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_view_singularvalues&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Contaminated by restarts, so turn off restart &lt;code&gt;-ksp_gmres_restart 1000&lt;/code&gt; for accurate results&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Preconditioner: block Jacobi

&lt;ul&gt;
&lt;li&gt;Expect condition number to scale with $1/(H h)$ where $H$ is the subdomain diameter and $h$ is the element size&lt;/li&gt;
&lt;li&gt;One block per MPI process&lt;/li&gt;
&lt;li&gt;No extra memory to create subdomain problems&lt;/li&gt;
&lt;li&gt;Create two blocks per process: &lt;code&gt;-pc_bjacobi_local_blocks 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Each subdomain solver can be configured/monitored using the &lt;code&gt;-sub_&lt;/code&gt; prefix&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-sub_ksp_type preonly&lt;/code&gt; (default) means just apply the preconditioner&lt;/li&gt;
&lt;li&gt;Incomplete LU factorization with zero fill&lt;/li&gt;
&lt;li&gt;$O(n)$ cost to compute and apply; same memory as matrix $A$&lt;/li&gt;
&lt;li&gt;gets weaker as $n$ increases&lt;/li&gt;
&lt;li&gt;can fail unpredictably at the worst possible time&lt;/li&gt;
&lt;li&gt;Allow &amp;quot;levels&amp;quot; of fill: &lt;code&gt;-sub_pc_factor_levels 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Try &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_monitor -ksp_view -sub_pc_factor_levels 3
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 3.321621226957e-02 
  1 KSP Residual norm 6.488371997792e-03 
  2 KSP Residual norm 3.872608843511e-03 
  3 KSP Residual norm 2.258796172567e-03 
  4 KSP Residual norm 6.146527388370e-04 
  5 KSP Residual norm 4.540373464970e-04 
  6 KSP Residual norm 1.994013489521e-04 
  7 KSP Residual norm 2.170446909144e-05 
  8 KSP Residual norm 7.079429242940e-06 
  9 KSP Residual norm 2.372198219605e-06 
 10 KSP Residual norm 9.203675161062e-07 
 11 KSP Residual norm 2.924907588760e-07 
KSP Object: 2 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 2 MPI processes
  type: bjacobi
    number of blocks = 2
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      3 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 2.34642
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqaij
            rows=153, cols=153
            package used to perform factorization: petsc
            total: nonzeros=1673, allocated nonzeros=1673
            total number of mallocs used during MatSetValues calls =0
              not using I-node routines
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqaij
      rows=153, cols=153
      total: nonzeros=713, allocated nonzeros=713
      total number of mallocs used during MatSetValues calls =0
        not using I-node routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=289, cols=289
    total: nonzeros=1377, allocated nonzeros=1377
    total number of mallocs used during MatSetValues calls =0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scaling-estimates&#34;&gt;Scaling estimates&lt;/h3&gt;

&lt;h4 id=&#34;dependence-on-h&#34;&gt;Dependence on $h$&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 16 --oversubscribe ./ex29 -da_refine 3 -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 20
Iteratively computed extreme singular values: max 1.9384 min 0.0694711 max/min 27.9023
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

for refine in {4..8}; do
  mpiexec -n 16 --oversubscribe ./ex29 -da_refine $refine -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 27
Iteratively computed extreme singular values: max 1.98356 min 0.0338842 max/min 58.5395
Linear solve converged due to CONVERGED_RTOL iterations 36
Iteratively computed extreme singular values: max 2.04703 min 0.0167502 max/min 122.209
Linear solve converged due to CONVERGED_RTOL iterations 47
Iteratively computed extreme singular values: max 2.12834 min 0.00830794 max/min 256.182
Linear solve converged due to CONVERGED_RTOL iterations 62
Iteratively computed extreme singular values: max 2.1865 min 0.00412757 max/min 529.731
Linear solve converged due to CONVERGED_RTOL iterations 82
Iteratively computed extreme singular values: max 2.22724 min 0.00206119 max/min 1080.56
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

for refine in {3..8}; do
  mpiexec -n 16 --oversubscribe ./ex29 -da_refine $refine -pc_type asm -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 12
Iteratively computed extreme singular values: max 1.39648 min 0.183011 max/min 7.63057
Linear solve converged due to CONVERGED_RTOL iterations 16
Iteratively computed extreme singular values: max 1.68852 min 0.0984075 max/min 17.1584
Linear solve converged due to CONVERGED_RTOL iterations 23
Iteratively computed extreme singular values: max 1.8569 min 0.0494302 max/min 37.5661
Linear solve converged due to CONVERGED_RTOL iterations 31
Iteratively computed extreme singular values: max 1.9503 min 0.0247646 max/min 78.7537
Linear solve converged due to CONVERGED_RTOL iterations 41
Iteratively computed extreme singular values: max 2.03979 min 0.0123563 max/min 165.081
Linear solve converged due to CONVERGED_RTOL iterations 54
Iteratively computed extreme singular values: max 2.12275 min 0.00615712 max/min 344.764
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash
cat &amp;gt; results.csv &amp;lt;&amp;lt;EOF
method,refine,its,cond
bjacobi,3,20,27.90
bjacobi,4,27,58.54
bjacobi,5,36,122.2
bjacobi,6,47,256.2
bjacobi,7,62,529.7
bjacobi,8,82,1080.6
asm,3,12,7.63
asm,4,16,17.15
asm,5,23,37.57
asm,6,31,78.75
asm,7,41,165.1
asm,8,54,344.8
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)

df = pandas.read_csv(&#39;results.csv&#39;)
n1 = 2**(df.refine + 1) # number of points per dimension
df[&#39;P&#39;] = 16      # number of processes
df[&#39;N&#39;] = n1**2    # number of dofs in global problem
df[&#39;h&#39;] = 1/n1
df[&#39;H&#39;] = 0.25 # 16 procs = 4x4 process grid
df[&#39;1/Hh&#39;] = 1/(df.H * df.h)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;seaborn.lmplot(x=&#39;1/Hh&#39;, y=&#39;cond&#39;, hue=&#39;method&#39;, data=df)
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;refine&lt;/th&gt;
      &lt;th&gt;its&lt;/th&gt;
      &lt;th&gt;cond&lt;/th&gt;
      &lt;th&gt;P&lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;h&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;1/Hh&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;27.90&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;0.062500&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;58.54&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;0.031250&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;128.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;122.20&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;4096&lt;/td&gt;
      &lt;td&gt;0.015625&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;256.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;256.20&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;16384&lt;/td&gt;
      &lt;td&gt;0.007812&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;512.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;529.70&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;65536&lt;/td&gt;
      &lt;td&gt;0.003906&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;1024.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;1080.60&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;262144&lt;/td&gt;
      &lt;td&gt;0.001953&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;2048.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;7.63&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;0.062500&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;17.15&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;0.031250&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;128.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;37.57&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;4096&lt;/td&gt;
      &lt;td&gt;0.015625&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;256.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;78.75&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;16384&lt;/td&gt;
      &lt;td&gt;0.007812&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;512.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;165.10&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;65536&lt;/td&gt;
      &lt;td&gt;0.003906&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;1024.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;344.80&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;262144&lt;/td&gt;
      &lt;td&gt;0.001953&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;2048.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_15_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
df[&#39;1/sqrt(Hh)&#39;] = np.sqrt(df[&#39;1/Hh&#39;])
plt.rc(&#39;figure&#39;, figsize=(16, 9))
g = seaborn.lmplot(x=&#39;1/sqrt(Hh)&#39;, y=&#39;its&#39;, hue=&#39;method&#39;, data=df);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_16_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.stats import linregress

bjacobi = df[df.method == &#39;bjacobi&#39;]
asm = df[df.method == &#39;asm&#39;]
bjacobi_its = linregress(bjacobi[&#39;1/sqrt(Hh)&#39;], bjacobi[&#39;its&#39;])
asm_its = linregress(asm[&#39;1/sqrt(Hh)&#39;], asm[&#39;its&#39;])
bjacobi_its, asm_its
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(LinregressResult(slope=1.649535193425483, intercept=8.498251134591065, rvalue=0.998633733566655, pvalue=2.7987507565052237e-06, stderr=0.043157836341681514),
 LinregressResult(slope=1.130138246216531, intercept=4.034979240523391, rvalue=0.9973956316037952, pvalue=1.0165269744723222e-05, stderr=0.04086178847687418))
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;cost&#34;&gt;Cost&lt;/h4&gt;

&lt;p&gt;Let $n = N/P$ be the subdomain size and suppose $k$ iterations are needed.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Matrix assembly scales like $O(n)$ (perfect parallelism)&lt;/li&gt;
&lt;li&gt;2D factorization in each subdomain scales as $O(n^{3/2})$&lt;/li&gt;
&lt;li&gt;Preconditioner application scales like $O(n \log n)$&lt;/li&gt;
&lt;li&gt;Matrix multiplication scales like $O(n)$&lt;/li&gt;
&lt;li&gt;GMRES scales like $O(k^2 n) + O(k^2 \log P)$

&lt;ul&gt;
&lt;li&gt;With restart length $r \ll k$, GMRES scales with $O(krn) + O(kr\log P)$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 --oversubscribe ./ex29 -da_refine 8 -pc_type asm -sub_pc_type lu -ksp_converged_reason -log_view
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 25
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use &#39;enscript -r -fCourier9&#39; to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./ex29 on a ompi-optg named joule.int.colorado.edu with 2 processors, by jed Wed Oct 16 10:57:30 2019
Using Petsc Development GIT revision: v3.12-32-g78b8d9f084  GIT Date: 2019-10-03 10:45:44 -0500

                         Max       Max/Min     Avg       Total 
Time (sec):           1.484e+00     1.000   1.484e+00
Objects:              1.040e+02     1.000   1.040e+02
Flop:                 1.432e+09     1.004   1.429e+09  2.857e+09
Flop/sec:             9.647e+08     1.004   9.628e+08  1.926e+09
MPI Messages:         6.200e+01     1.000   6.200e+01  1.240e+02
MPI Message Lengths:  2.524e+05     1.000   4.071e+03  5.048e+05
MPI Reductions:       1.710e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --&amp;gt; 2N flop
                            and VecAXPY() for complex vectors of length N --&amp;gt; 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total 
 0:      Main Stage: 1.4839e+00 100.0%  2.8574e+09 100.0%  1.240e+02 100.0%  4.071e+03      100.0%  1.630e+02  95.3% 

------------------------------------------------------------------------------------------------------------------------
See the &#39;Profiling&#39; chapter of the users&#39; manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          5 1.0 1.5282e-02 1.7 0.00e+00 0.0 4.0e+00 4.0e+00 0.0e+00  1  0  3  0  0   1  0  3  0  0     0
BuildTwoSidedF         4 1.0 1.1949e-0217.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult               25 1.0 2.8539e-02 1.0 2.96e+07 1.0 5.0e+01 4.1e+03 0.0e+00  2  2 40 41  0   2  2 40 41  0  2071
MatSolve              26 1.0 2.9259e-01 1.0 3.50e+08 1.0 0.0e+00 0.0e+00 0.0e+00 20 25  0  0  0  20 25  0  0  0  2393
MatLUFactorSym         1 1.0 1.5648e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 10  0  0  0  0  10  0  0  0  0     0
MatLUFactorNum         1 1.0 5.9458e-01 1.1 8.64e+08 1.0 0.0e+00 0.0e+00 0.0e+00 39 60  0  0  0  39 60  0  0  0  2896
MatAssemblyBegin       3 1.0 1.0730e-0282.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         3 1.0 9.8794e-03 1.1 0.00e+00 0.0 3.0e+00 1.4e+03 4.0e+00  1  0  2  1  2   1  0  2  1  2     0
MatGetRowIJ            1 1.0 5.0642e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatCreateSubMats       1 1.0 3.9036e-02 1.2 0.00e+00 0.0 1.0e+01 7.0e+03 1.0e+00  2  0  8 14  1   2  0  8 14  1     0
MatGetOrdering         1 1.0 8.0494e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  5  0  0  0  0   5  0  0  0  0     0
MatIncreaseOvrlp       1 1.0 1.5691e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+00  1  0  0  0  1   1  0  0  0  1     0
KSPSetUp               2 1.0 2.8898e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  6   0  0  0  0  6     0
KSPSolve               1 1.0 1.2704e+00 1.0 1.43e+09 1.0 1.0e+02 4.1e+03 1.1e+02 86100 82 83 64  86100 82 83 67  2249
KSPGMRESOrthog        25 1.0 8.4230e-02 1.0 1.71e+08 1.0 0.0e+00 0.0e+00 2.5e+01  6 12  0  0 15   6 12  0  0 15  4062
DMCreateMat            1 1.0 6.0364e-02 1.0 0.00e+00 0.0 3.0e+00 1.4e+03 6.0e+00  4  0  2  1  4   4  0  2  1  4     0
SFSetGraph             5 1.0 3.0582e-04 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                5 1.0 3.2978e-02 1.5 0.00e+00 0.0 1.2e+01 1.4e+03 0.0e+00  2  0 10  3  0   2  0 10  3  0     0
SFBcastOpBegin        51 1.0 7.6917e-03 1.0 0.00e+00 0.0 1.0e+02 4.1e+03 0.0e+00  1  0 82 83  0   1  0 82 83  0     0
SFBcastOpEnd          51 1.0 1.0617e-02 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFReduceBegin         26 1.0 5.9807e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFReduceEnd           26 1.0 5.0625e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               25 1.0 4.1009e-02 1.0 8.57e+07 1.0 0.0e+00 0.0e+00 2.5e+01  3  6  0  0 15   3  6  0  0 15  4171
VecNorm               26 1.0 6.5928e-03 1.3 6.86e+06 1.0 0.0e+00 0.0e+00 2.6e+01  0  0  0  0 15   0  0  0  0 16  2076
VecScale              26 1.0 2.2696e-03 1.0 3.43e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3015
VecCopy                1 1.0 1.2067e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                85 1.0 6.4445e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 1.7286e-04 1.0 2.64e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3045
VecMAXPY              26 1.0 4.5977e-02 1.0 9.23e+07 1.0 0.0e+00 0.0e+00 0.0e+00  3  6  0  0  0   3  6  0  0  0  4007
VecAssemblyBegin       2 1.0 1.3040e-03 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         2 1.0 4.9600e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      129 1.0 2.7052e-02 1.0 0.00e+00 0.0 1.0e+02 4.1e+03 0.0e+00  2  0 82 83  0   2  0 82 83  0     0
VecScatterEnd         77 1.0 1.5437e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecNormalize          26 1.0 8.8965e-03 1.2 1.03e+07 1.0 0.0e+00 0.0e+00 2.6e+01  1  1  0  0 15   1  1  0  0 16  2307
PCSetUp                2 1.0 8.5827e-01 1.0 8.64e+08 1.0 1.3e+01 5.7e+03 7.0e+00 58 60 10 15  4  58 60 10 15  4  2006
PCSetUpOnBlocks        1 1.0 7.9431e-01 1.0 8.64e+08 1.0 0.0e+00 0.0e+00 0.0e+00 53 60  0  0  0  53 60  0  0  0  2168
PCApply               26 1.0 3.3956e-01 1.0 3.50e+08 1.0 5.2e+01 4.1e+03 0.0e+00 23 25 42 42  0  23 25 42 42  0  2062
PCApplyOnBlocks       26 1.0 2.9531e-01 1.0 3.50e+08 1.0 0.0e+00 0.0e+00 0.0e+00 20 25  0  0  0  20 25  0  0  0  2371
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants&#39; Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

       Krylov Solver     2              2        20056     0.
     DMKSP interface     1              1          664     0.
              Matrix     5              5    105275836     0.
    Distributed Mesh     3              3        15760     0.
           Index Set    17             17      5309508     0.
   IS L to G Mapping     3              3      2119704     0.
   Star Forest Graph    11             11        10648     0.
     Discrete System     3              3         2856     0.
              Vector    50             50     45457728     0.
         Vec Scatter     5              5         4008     0.
      Preconditioner     2              2         2000     0.
              Viewer     2              1          848     0.
========================================================================================================================
Average time to get PetscTime(): 3.32e-08
Average time for MPI_Barrier(): 1.404e-06
Average time for zero size MPI_Send(): 8.8545e-06
#PETSc Option Table entries:
-da_refine 8
-ksp_converged_reason
-log_view
-malloc_test
-pc_type asm
-sub_pc_type lu
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --download-ctetgen --download-exodusii --download-hypre --download-ml --download-mumps --download-netcdf --download-pnetcdf --download-scalapack --download-sundials --download-superlu --download-superlu_dist --download-triangle --with-debugging=0 --with-hdf5 --with-med --with-metis --with-mpi-dir=/home/jed/usr/ccache/ompi --with-parmetis --with-suitesparse --with-x --with-zlib COPTFLAGS=&amp;quot;-O2 -march=native -ftree-vectorize -g&amp;quot; PETSC_ARCH=ompi-optg
-----------------------------------------
Libraries compiled on 2019-10-03 21:38:02 on joule 
Machine characteristics: Linux-5.3.1-arch1-1-ARCH-x86_64-with-arch
Using PETSc directory: /home/jed/petsc
Using PETSc arch: ompi-optg
-----------------------------------------

Using C compiler: /home/jed/usr/ccache/ompi/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -O2 -march=native -ftree-vectorize -g  
Using Fortran compiler: /home/jed/usr/ccache/ompi/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O    
-----------------------------------------

Using include paths: -I/home/jed/petsc/include -I/home/jed/petsc/ompi-optg/include -I/home/jed/usr/ccache/ompi/include
-----------------------------------------

Using C linker: /home/jed/usr/ccache/ompi/bin/mpicc
Using Fortran linker: /home/jed/usr/ccache/ompi/bin/mpif90
Using libraries: -Wl,-rpath,/home/jed/petsc/ompi-optg/lib -L/home/jed/petsc/ompi-optg/lib -lpetsc -Wl,-rpath,/home/jed/petsc/ompi-optg/lib -L/home/jed/petsc/ompi-optg/lib -Wl,-rpath,/usr/lib/openmpi -L/usr/lib/openmpi -Wl,-rpath,/usr/lib/gcc/x86_64-pc-linux-gnu/9.1.0 -L/usr/lib/gcc/x86_64-pc-linux-gnu/9.1.0 -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lumfpack -lklu -lcholmod -lbtf -lccolamd -lcolamd -lcamd -lamd -lsuitesparseconfig -lsuperlu -lsuperlu_dist -lml -lsundials_cvode -lsundials_nvecserial -lsundials_nvecparallel -llapack -lblas -lexodus -lnetcdf -lpnetcdf -lmedC -lmed -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lparmetis -lmetis -ltriangle -lm -lz -lX11 -lctetgen -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lquadmath -lstdc++ -ldl
-----------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;suggested-exercises&#34;&gt;Suggested exercises&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;There is no substitute for experimentation.  Try some different methods or a different example.  How do the constants and scaling compare?&lt;/li&gt;
&lt;li&gt;Can you estimate parameters to model the leading costs for this solver?

&lt;ul&gt;
&lt;li&gt;In your model, how does degrees of freedom solved per second per process depend on discretization size $h$?&lt;/li&gt;
&lt;li&gt;What would be optimal?
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;an-approach-to-modeling&#34;&gt;An approach to modeling&lt;/h2&gt;

&lt;p&gt;We have conducted:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;a few experiments to validate the mathematical estimates for condition number and number of iterations

&lt;ul&gt;
&lt;li&gt;even when the theorem exists, we need to confirm that we&#39;re in the asymptotic regime&lt;/li&gt;
&lt;li&gt;execution time does not matter at all for this; it&#39;s checking the math/convergence rates&lt;/li&gt;
&lt;li&gt;indeed, we ran oversubscribed (more processes than cores)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;one performance experiment on representative hardware (&lt;code&gt;-log_view&lt;/code&gt;)

&lt;ul&gt;
&lt;li&gt;this was on my laptop, but could have been on a couple nodes of a cluster&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The performance experiment(s) enables us to fill in constants to estimate time.
These models could be more sophisticated, accounting for cache sizes, message sizes, and the like.
We implement this performance model in code, dropping in the timing constants from the experiment above, then run synthetic experiments to map out estimated performance in various scaling modes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def perf_model(h, P, method, regress_its):
    n1 = 1/h
    N = n1**2
    n = N / P
    H = 1/np.sqrt(P)
    its = regress_its.intercept + regress_its.slope / np.sqrt(H*h)
    nref = (2**9 + 1)**2/2 # 8 levels of refinement from a 3x3 (2x2 element) grid
    pc_setup = 8.5827e-01 / nref**1.5 * n**1.5
    pc_apply = 3.3956e-01 / 26 / (nref * np.log(nref)) * (n * np.log(n))
    matmult =  2.8539e-02 / 25 / nref * n
    gmres = 8.4230e-02 / 25 / nref * n + 30e-6
    total = pc_setup + its*(pc_apply + matmult + gmres)
    return dict(h=h, H=H, n=n, N=N, P=P, method=method, its=its,
                pc_setup=pc_setup, pc_apply=its*pc_apply, matmult=its*matmult,
                gmres=its*gmres)

mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
mdf.append(perf_model(.5**9, 2, &#39;asm&#39;, asm_its), ignore_index=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;h&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;n&lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;P&lt;/th&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;its&lt;/th&gt;
      &lt;th&gt;pc_setup&lt;/th&gt;
      &lt;th&gt;pc_apply&lt;/th&gt;
      &lt;th&gt;matmult&lt;/th&gt;
      &lt;th&gt;gmres&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.001953&lt;/td&gt;
      &lt;td&gt;0.707107&lt;/td&gt;
      &lt;td&gt;131072.0&lt;/td&gt;
      &lt;td&gt;262144.0&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;34.445514&lt;/td&gt;
      &lt;td&gt;0.853261&lt;/td&gt;
      &lt;td&gt;0.447958&lt;/td&gt;
      &lt;td&gt;0.039168&lt;/td&gt;
      &lt;td&gt;0.116635&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;h3 id=&#34;weak-scaling-study-fixed-subdomain-size&#34;&gt;Weak scaling study: fixed subdomain size&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def make_stats(df):
    df[&#39;total&#39;] = df.pc_setup + df.pc_apply + df.matmult + df.gmres
    df[&#39;cost&#39;] = df.total * df.P
    df[&#39;efficiency&#39;] = df.N / df.cost
    df[&#39;digits_accuracy&#39;] = -np.log10(100*df.h**2)
    df[&#39;log10_time&#39;] = np.log10(df.total)
    df[&#39;log10_cost&#39;] = np.log10(df.cost)

mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
for h in [.002]:
    for scale in np.geomspace(2, 1e3, 10):
        for method, its in [(&#39;asm&#39;, asm_its), (&#39;bjacobi&#39;, bjacobi_its)]:
            mdf = mdf.append(perf_model(h/scale, scale**2, method, its), ignore_index=True)
make_stats(mdf)

plt.rc(&#39;figure&#39;, figsize=(16,9))
grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;total&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(2, 2e6), yscale=&#39;log&#39;, ylim=(1, 2e3))
mdf
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;h&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;n&lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;P&lt;/th&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;its&lt;/th&gt;
      &lt;th&gt;pc_setup&lt;/th&gt;
      &lt;th&gt;pc_apply&lt;/th&gt;
      &lt;th&gt;matmult&lt;/th&gt;
      &lt;th&gt;gmres&lt;/th&gt;
      &lt;th&gt;total&lt;/th&gt;
      &lt;th&gt;cost&lt;/th&gt;
      &lt;th&gt;efficiency&lt;/th&gt;
      &lt;th&gt;digits_accuracy&lt;/th&gt;
      &lt;th&gt;log10_time&lt;/th&gt;
      &lt;th&gt;log10_cost&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;0.001000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.000000e+06&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;54.576298&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;1.427934&lt;/td&gt;
      &lt;td&gt;0.118369&lt;/td&gt;
      &lt;td&gt;0.350992&lt;/td&gt;
      &lt;td&gt;4.144935&lt;/td&gt;
      &lt;td&gt;1.657974e+01&lt;/td&gt;
      &lt;td&gt;60314.577430&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;0.617518&lt;/td&gt;
      &lt;td&gt;1.219578&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;0.001000&lt;/td&gt;
      &lt;td&gt;0.500000&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.000000e+06&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;82.267708&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;2.152452&lt;/td&gt;
      &lt;td&gt;0.178428&lt;/td&gt;
      &lt;td&gt;0.529081&lt;/td&gt;
      &lt;td&gt;5.107601&lt;/td&gt;
      &lt;td&gt;2.043040e+01&lt;/td&gt;
      &lt;td&gt;48946.656533&lt;/td&gt;
      &lt;td&gt;4.000000&lt;/td&gt;
      &lt;td&gt;0.708217&lt;/td&gt;
      &lt;td&gt;1.310277&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.000501&lt;/td&gt;
      &lt;td&gt;0.250660&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;3.978974e+06&lt;/td&gt;
      &lt;td&gt;15.915896&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;104.851598&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;2.743336&lt;/td&gt;
      &lt;td&gt;0.227410&lt;/td&gt;
      &lt;td&gt;0.674323&lt;/td&gt;
      &lt;td&gt;5.892709&lt;/td&gt;
      &lt;td&gt;9.378775e+01&lt;/td&gt;
      &lt;td&gt;42425.307545&lt;/td&gt;
      &lt;td&gt;4.599771&lt;/td&gt;
      &lt;td&gt;0.770315&lt;/td&gt;
      &lt;td&gt;1.972146&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;0.000501&lt;/td&gt;
      &lt;td&gt;0.250660&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;3.978974e+06&lt;/td&gt;
      &lt;td&gt;15.915896&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;155.648886&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;4.072396&lt;/td&gt;
      &lt;td&gt;0.337583&lt;/td&gt;
      &lt;td&gt;1.001011&lt;/td&gt;
      &lt;td&gt;7.658630&lt;/td&gt;
      &lt;td&gt;1.218940e+02&lt;/td&gt;
      &lt;td&gt;32642.914395&lt;/td&gt;
      &lt;td&gt;4.599771&lt;/td&gt;
      &lt;td&gt;0.884151&lt;/td&gt;
      &lt;td&gt;2.085982&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;0.000251&lt;/td&gt;
      &lt;td&gt;0.125661&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.583223e+07&lt;/td&gt;
      &lt;td&gt;63.328940&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;205.137578&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;5.367218&lt;/td&gt;
      &lt;td&gt;0.444917&lt;/td&gt;
      &lt;td&gt;1.319283&lt;/td&gt;
      &lt;td&gt;9.379058&lt;/td&gt;
      &lt;td&gt;5.939658e+02&lt;/td&gt;
      &lt;td&gt;26655.127609&lt;/td&gt;
      &lt;td&gt;5.199542&lt;/td&gt;
      &lt;td&gt;0.972159&lt;/td&gt;
      &lt;td&gt;2.773761&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;0.000251&lt;/td&gt;
      &lt;td&gt;0.125661&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.583223e+07&lt;/td&gt;
      &lt;td&gt;63.328940&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;302.025008&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;7.902180&lt;/td&gt;
      &lt;td&gt;0.655054&lt;/td&gt;
      &lt;td&gt;1.942386&lt;/td&gt;
      &lt;td&gt;12.747260&lt;/td&gt;
      &lt;td&gt;8.072705e+02&lt;/td&gt;
      &lt;td&gt;19612.057407&lt;/td&gt;
      &lt;td&gt;5.199542&lt;/td&gt;
      &lt;td&gt;1.105417&lt;/td&gt;
      &lt;td&gt;2.907019&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;0.000126&lt;/td&gt;
      &lt;td&gt;0.062996&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;6.299605e+07&lt;/td&gt;
      &lt;td&gt;251.984210&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;405.181693&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;10.601171&lt;/td&gt;
      &lt;td&gt;0.878787&lt;/td&gt;
      &lt;td&gt;2.605809&lt;/td&gt;
      &lt;td&gt;16.333407&lt;/td&gt;
      &lt;td&gt;4.115761e+03&lt;/td&gt;
      &lt;td&gt;15306.053492&lt;/td&gt;
      &lt;td&gt;5.799313&lt;/td&gt;
      &lt;td&gt;1.213077&lt;/td&gt;
      &lt;td&gt;3.614450&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;0.000126&lt;/td&gt;
      &lt;td&gt;0.062996&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;6.299605e+07&lt;/td&gt;
      &lt;td&gt;251.984210&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;594.006815&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;15.541589&lt;/td&gt;
      &lt;td&gt;1.288325&lt;/td&gt;
      &lt;td&gt;3.820182&lt;/td&gt;
      &lt;td&gt;22.897737&lt;/td&gt;
      &lt;td&gt;5.769868e+03&lt;/td&gt;
      &lt;td&gt;10918.109272&lt;/td&gt;
      &lt;td&gt;5.799313&lt;/td&gt;
      &lt;td&gt;1.359793&lt;/td&gt;
      &lt;td&gt;3.761166&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;0.000063&lt;/td&gt;
      &lt;td&gt;0.031581&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;2.506597e+08&lt;/td&gt;
      &lt;td&gt;1002.638645&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;804.217010&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;21.041527&lt;/td&gt;
      &lt;td&gt;1.744244&lt;/td&gt;
      &lt;td&gt;5.172088&lt;/td&gt;
      &lt;td&gt;30.205500&lt;/td&gt;
      &lt;td&gt;3.028520e+04&lt;/td&gt;
      &lt;td&gt;8276.638274&lt;/td&gt;
      &lt;td&gt;6.399084&lt;/td&gt;
      &lt;td&gt;1.480086&lt;/td&gt;
      &lt;td&gt;4.481230&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;0.000063&lt;/td&gt;
      &lt;td&gt;0.031581&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;2.506597e+08&lt;/td&gt;
      &lt;td&gt;1002.638645&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;1176.433613&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;30.780200&lt;/td&gt;
      &lt;td&gt;2.551534&lt;/td&gt;
      &lt;td&gt;7.565891&lt;/td&gt;
      &lt;td&gt;43.145266&lt;/td&gt;
      &lt;td&gt;4.325911e+04&lt;/td&gt;
      &lt;td&gt;5794.378472&lt;/td&gt;
      &lt;td&gt;6.399084&lt;/td&gt;
      &lt;td&gt;1.634933&lt;/td&gt;
      &lt;td&gt;4.636078&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;0.000032&lt;/td&gt;
      &lt;td&gt;0.015832&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;9.973683e+08&lt;/td&gt;
      &lt;td&gt;3989.473198&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;1600.187362&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;41.867289&lt;/td&gt;
      &lt;td&gt;3.470602&lt;/td&gt;
      &lt;td&gt;10.291141&lt;/td&gt;
      &lt;td&gt;57.876673&lt;/td&gt;
      &lt;td&gt;2.308974e+05&lt;/td&gt;
      &lt;td&gt;4319.529584&lt;/td&gt;
      &lt;td&gt;6.998856&lt;/td&gt;
      &lt;td&gt;1.762504&lt;/td&gt;
      &lt;td&gt;5.363419&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;0.000032&lt;/td&gt;
      &lt;td&gt;0.015832&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;9.973683e+08&lt;/td&gt;
      &lt;td&gt;3989.473198&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;2338.221662&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;61.177213&lt;/td&gt;
      &lt;td&gt;5.071305&lt;/td&gt;
      &lt;td&gt;15.037594&lt;/td&gt;
      &lt;td&gt;83.533752&lt;/td&gt;
      &lt;td&gt;3.332557e+05&lt;/td&gt;
      &lt;td&gt;2992.802242&lt;/td&gt;
      &lt;td&gt;6.998856&lt;/td&gt;
      &lt;td&gt;1.921862&lt;/td&gt;
      &lt;td&gt;5.522778&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;0.000016&lt;/td&gt;
      &lt;td&gt;0.007937&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;3.968503e+09&lt;/td&gt;
      &lt;td&gt;15874.010520&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;3187.938555&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;83.409198&lt;/td&gt;
      &lt;td&gt;6.914232&lt;/td&gt;
      &lt;td&gt;20.502302&lt;/td&gt;
      &lt;td&gt;113.073373&lt;/td&gt;
      &lt;td&gt;1.794928e+06&lt;/td&gt;
      &lt;td&gt;2210.953766&lt;/td&gt;
      &lt;td&gt;7.598627&lt;/td&gt;
      &lt;td&gt;2.053360&lt;/td&gt;
      &lt;td&gt;6.254047&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;13&lt;/td&gt;
      &lt;td&gt;0.000016&lt;/td&gt;
      &lt;td&gt;0.007937&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;3.968503e+09&lt;/td&gt;
      &lt;td&gt;15874.010520&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;4655.682804&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;121.811247&lt;/td&gt;
      &lt;td&gt;10.097582&lt;/td&gt;
      &lt;td&gt;29.941673&lt;/td&gt;
      &lt;td&gt;164.098143&lt;/td&gt;
      &lt;td&gt;2.604896e+06&lt;/td&gt;
      &lt;td&gt;1523.478544&lt;/td&gt;
      &lt;td&gt;7.598627&lt;/td&gt;
      &lt;td&gt;2.215104&lt;/td&gt;
      &lt;td&gt;6.415790&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;14&lt;/td&gt;
      &lt;td&gt;0.000008&lt;/td&gt;
      &lt;td&gt;0.003979&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.579057e+10&lt;/td&gt;
      &lt;td&gt;63162.276697&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;6355.083968&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;166.274365&lt;/td&gt;
      &lt;td&gt;13.783367&lt;/td&gt;
      &lt;td&gt;40.870879&lt;/td&gt;
      &lt;td&gt;223.176251&lt;/td&gt;
      &lt;td&gt;1.409632e+07&lt;/td&gt;
      &lt;td&gt;1120.190874&lt;/td&gt;
      &lt;td&gt;8.198398&lt;/td&gt;
      &lt;td&gt;2.348648&lt;/td&gt;
      &lt;td&gt;7.149106&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;15&lt;/td&gt;
      &lt;td&gt;0.000008&lt;/td&gt;
      &lt;td&gt;0.003979&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;1.579057e+10&lt;/td&gt;
      &lt;td&gt;63162.276697&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;9278.407360&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;242.760175&lt;/td&gt;
      &lt;td&gt;20.123682&lt;/td&gt;
      &lt;td&gt;59.671385&lt;/td&gt;
      &lt;td&gt;324.802883&lt;/td&gt;
      &lt;td&gt;2.051529e+07&lt;/td&gt;
      &lt;td&gt;769.697602&lt;/td&gt;
      &lt;td&gt;8.198398&lt;/td&gt;
      &lt;td&gt;2.511620&lt;/td&gt;
      &lt;td&gt;7.312078&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;0.000004&lt;/td&gt;
      &lt;td&gt;0.001995&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;6.283027e+10&lt;/td&gt;
      &lt;td&gt;251321.062979&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;12672.704838&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;331.568547&lt;/td&gt;
      &lt;td&gt;27.485481&lt;/td&gt;
      &lt;td&gt;81.500824&lt;/td&gt;
      &lt;td&gt;442.802492&lt;/td&gt;
      &lt;td&gt;1.112856e+08&lt;/td&gt;
      &lt;td&gt;564.585802&lt;/td&gt;
      &lt;td&gt;8.798169&lt;/td&gt;
      &lt;td&gt;2.646210&lt;/td&gt;
      &lt;td&gt;8.046439&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;17&lt;/td&gt;
      &lt;td&gt;0.000004&lt;/td&gt;
      &lt;td&gt;0.001995&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;6.283027e+10&lt;/td&gt;
      &lt;td&gt;251321.062979&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;18499.525217&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;484.021428&lt;/td&gt;
      &lt;td&gt;40.123111&lt;/td&gt;
      &lt;td&gt;118.974329&lt;/td&gt;
      &lt;td&gt;645.366508&lt;/td&gt;
      &lt;td&gt;1.621942e+08&lt;/td&gt;
      &lt;td&gt;387.376780&lt;/td&gt;
      &lt;td&gt;8.798169&lt;/td&gt;
      &lt;td&gt;2.809806&lt;/td&gt;
      &lt;td&gt;8.210035&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;0.000002&lt;/td&gt;
      &lt;td&gt;0.001000&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;2.500000e+11&lt;/td&gt;
      &lt;td&gt;1000000.000000&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;25274.694404&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;661.286899&lt;/td&gt;
      &lt;td&gt;54.817589&lt;/td&gt;
      &lt;td&gt;162.546864&lt;/td&gt;
      &lt;td&gt;880.898993&lt;/td&gt;
      &lt;td&gt;8.808990e+08&lt;/td&gt;
      &lt;td&gt;283.800983&lt;/td&gt;
      &lt;td&gt;9.397940&lt;/td&gt;
      &lt;td&gt;2.944926&lt;/td&gt;
      &lt;td&gt;8.944926&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;19&lt;/td&gt;
      &lt;td&gt;0.000002&lt;/td&gt;
      &lt;td&gt;0.001000&lt;/td&gt;
      &lt;td&gt;250000.0&lt;/td&gt;
      &lt;td&gt;2.500000e+11&lt;/td&gt;
      &lt;td&gt;1000000.000000&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;36893.226489&lt;/td&gt;
      &lt;td&gt;2.24764&lt;/td&gt;
      &lt;td&gt;965.274079&lt;/td&gt;
      &lt;td&gt;80.016703&lt;/td&gt;
      &lt;td&gt;237.268082&lt;/td&gt;
      &lt;td&gt;1284.806505&lt;/td&gt;
      &lt;td&gt;1.284807e+09&lt;/td&gt;
      &lt;td&gt;194.581829&lt;/td&gt;
      &lt;td&gt;9.397940&lt;/td&gt;
      &lt;td&gt;3.108838&lt;/td&gt;
      &lt;td&gt;9.108838&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_23_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(50,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(3, 2e6));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_24_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h3 id=&#34;strong-scaling-study-fixed-global-problem-size&#34;&gt;Strong scaling study: fixed global problem size&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
for h in [1e-5]:
    for scale in np.geomspace(2, 1e3, 10):
        for method, its in [(&#39;asm&#39;, asm_its), (&#39;bjacobi&#39;, bjacobi_its)]:
            mdf = mdf.append(perf_model(h, scale**2, method, its), ignore_index=True)
make_stats(mdf)

grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;total&#39;, style=&#39;method&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(2, 2e6), yscale=&#39;log&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_26_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(2, 2e6), ylim=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_27_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h2 id=&#34;accessible-range&#34;&gt;Accessible range&lt;/h2&gt;

&lt;p&gt;Now we grid sample the space of possible configurations to understand the shape of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Pareto_efficiency&#34;&gt;Pareto front&lt;/a&gt; -- those configurations that are optimal in terms of the multiple objectives, which we take to be&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;number of digits of accuracy

&lt;ul&gt;
&lt;li&gt;scales with $O(h^2)$ for this discretization&lt;/li&gt;
&lt;li&gt;sometimes we could change the discretization to converge as $O(h^3)$ or a higher power; these are called &amp;quot;higher order methods&amp;quot;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;total execution time: how long we have wait for the parallel computation to complete&lt;/li&gt;
&lt;li&gt;cost: how many node hours are we charged for&lt;/li&gt;
&lt;li&gt;efficiency: given the required problem size to reach desired accuracy, how well are the node resources being used

&lt;ul&gt;
&lt;li&gt;we measure here as number of degrees of freedom solved per second per core
&lt;br&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;All of these metrics have tangible units and none are input parameters.  We&#39;ll map out the best configurations possible within a class of algorithms and, after identifying a Pareto optimal case that we would like to run, can check the input parameters to see how to run it on a real machine.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
for h in np.geomspace(1e-3, .1, 10):
    for scale in np.geomspace(2, 1e3, 10):
        for method, its in [(&#39;asm&#39;, asm_its), (&#39;bjacobi&#39;, bjacobi_its)]:
            mdf = mdf.append(perf_model(h/scale, scale**2, method, its), ignore_index=True)
make_stats(mdf)

grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;total&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(3, 2e6), yscale=&#39;log&#39;, ylim=(1e-3, 2e5));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_29_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;total&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(1e-3, 1e4), yscale=&#39;log&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_30_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;digits_accuracy&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, hue=&#39;log10_time&#39;, size=&#39;log10_cost&#39;, sizes=(30,400), data=mdf)
grid.axes.set(yscale=&#39;log&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_31_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;total&#39;, y=&#39;digits_accuracy&#39;, style=&#39;method&#39;, size=&#39;log10_cost&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(1, 1e4), ylim=3);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_32_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h2 id=&#34;twolevel-methods&#34;&gt;Two-level methods&lt;/h2&gt;

&lt;p&gt;Two-level methods add a coarse space $P_0$ to the preconditioner&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ M^{-1} = P_0 A_0^{-1} P_0^T + \sum_{i=1}^{\text{subdomains}} P_i A_i^{-1} P_i^T \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;or a similar combination.  In most formulations, the size of the coarse problem $A_0 = P_0^T A P_0$ is proportional to the number of subdomains.&lt;/p&gt;

&lt;p&gt;Compare the figures below with those above to see how two-level methods open up new accessible ranges and bring their own tradeoffs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def perf_model_2level(h, P, method, regress_its):
    n1 = 1/h
    N = n1**2
    n = N / P
    H = 1/np.sqrt(P)
    its = regress_its.intercept + regress_its.slope / np.sqrt(H*h) * H
    nref = (2**9 + 1)**2/2 # 8 levels of refinement from a 3x3 (2x2 element) grid
    pc_setup = 8.5827e-01 / nref**1.5 * n**1.5
    pc_setup += 8.5827e-01 / nref**1.5 * (4*P)**1.5
    pc_apply = 3.3956e-01 / 26 / (nref * np.log(nref)) * (n * np.log(n) + 4*P * np.log(4*P))
    matmult =  2.8539e-02 / 25 / nref * n
    gmres = 8.4230e-02 / 25 / nref * n + 30e-6
    total = pc_setup + its*(pc_apply + matmult + gmres)
    return dict(h=h, H=H, n=n, N=N, P=P, method=method, its=its,
                pc_setup=pc_setup, pc_apply=its*pc_apply, matmult=its*matmult,
                gmres=its*gmres)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;strong-scaling&#34;&gt;Strong scaling&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
for h in [1e-5]:
    for scale in np.geomspace(2, 1e3, 10):
        for method, its in [(&#39;asm&#39;, asm_its), (&#39;bjacobi&#39;, bjacobi_its)]:
            mdf = mdf.append(perf_model_2lev(h, scale**2, method, its), ignore_index=True)
make_stats(mdf)
grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(2, 2e6), ylim=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_36_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why does efficiency drop off on the left?&lt;/li&gt;
&lt;li&gt;Why does it drop off on the right?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;accessible-range-1&#34;&gt;Accessible range&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mdf = pandas.DataFrame(columns=&#39;h H n N P method its pc_setup pc_apply matmult gmres&#39;.split())
for h in np.geomspace(1e-3, .1, 10):
    for scale in np.geomspace(2, 1e3, 10):
        for method, its in [(&#39;asm&#39;, asm_its), (&#39;bjacobi&#39;, bjacobi_its)]:
            mdf = mdf.append(perf_model_2level(h/scale, scale**2, method, its), ignore_index=True)
make_stats(mdf)

grid = seaborn.scatterplot(x=&#39;P&#39;, y=&#39;total&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(3, 2e6), yscale=&#39;log&#39;, ylim=(1e-3, 2e5));
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_38_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;total&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, hue=&#39;digits_accuracy&#39;, size=&#39;its&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(1e-3, 1e4), yscale=&#39;log&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_39_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;digits_accuracy&#39;, y=&#39;efficiency&#39;, style=&#39;method&#39;, hue=&#39;log10_time&#39;, size=&#39;log10_cost&#39;, sizes=(30,400), data=mdf)
grid.axes.set(yscale=&#39;log&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_40_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;grid = seaborn.scatterplot(x=&#39;total&#39;, y=&#39;digits_accuracy&#39;, style=&#39;method&#39;, size=&#39;log10_cost&#39;, sizes=(30,400), data=mdf)
grid.axes.set(xscale=&#39;log&#39;, xlim=(1, 1e4), ylim=3);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_41_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>DD Preconditioning 2</title>
      <link>https://cucs-hpsc.github.io/fall2019/dd-preconditioning-2/</link>
      <pubDate>Wed, 16 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/dd-preconditioning-2/</guid>
      <description>&lt;h3 id=&#34;recap-domain-decomposition-theory&#34;&gt;Recap: Domain decomposition theory&lt;/h3&gt;

&lt;p&gt;Given a linear operator $A : V \to V$, suppose we have a collection of prolongation operators $P_i : V_i \to V$.  The columns of $P_i$ are &amp;quot;basis functions&amp;quot; for the subspace $V_i$.  The Galerkin operator $A_i = P_i^T A P_i$ is the action of the original operator $A$ in the subspace.&lt;/p&gt;

&lt;p&gt;Define the subspace projection&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ S_i = P_i A_i^{-1} P_i^T A . \]&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$S_i$ is a projection: $S_i^2 = S_i$&lt;/li&gt;
&lt;li&gt;If $A$ is SPD, $S_i$ is SPD with respect to the $A$ inner product $x^T A y$&lt;/li&gt;
&lt;li&gt;$I - S_i$ is $A$-orthogonal to the range of $P_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Note, the concept of $A$-orthogonality is meaningful only when $A$ is SPD.
Does the mathematical expression $ P_i^T A (I - S_i) = 0 $ hold even when $A$ is nonsymmetric?&lt;/p&gt;

&lt;p&gt;These projections may be applied additively&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ I - \sum_{i=0}^n S_i, \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;multiplicatively&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \prod_{i=0}^n (I - S_i), \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;or in some hybrid manner, such as&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\( (I - S_0) (I - \sum_{i=1}^n S_i) . \)&lt;/span&gt;
In each case above, the action is expressed in terms of the error iteration operator.&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Jacobi corresponds to the additive preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Gauss-Seidel is the multiplicate preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Block Jacobi corresponds to labeling &amp;quot;subdomains&amp;quot; and $P_i$ as the columns of the identity corresponding to non-overlapping subdomains&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz corresponds to overlapping subdomains&lt;/li&gt;
&lt;li&gt;$P_i$ are eigenvectors of $A$&lt;/li&gt;
&lt;li&gt;A domain is partitioned into interior $V_{I}$ and interface $V_\Gamma$ degrees of freedom.  $P_{I}$ is embedding of the interior degrees of freedom while $P_\Gamma$ is &amp;quot;harmonic extension&amp;quot; of the interface degrees of freedom.  Consider the multiplicative combination $(I - S_\Gamma)(I - S_{I})$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;convergence-theory&#34;&gt;Convergence theory&lt;/h3&gt;

&lt;p&gt;The formal convergence is beyond the scope of this course, but the following estimates are useful.  We let $h$ be the element diameter, $H$ be the subdomain diameter, and $\delta$ be the overlap, each normalized such that the global domain diameter is 1.  We express the convergence in terms of the condition number $\kappa$ for the preconditioned operator.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(Block) Jacobi: $\delta=0$, $\kappa \sim H^{-2} H/h = (Hh)^{-1}$&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz: $\kappa \sim H^{-2} H/\delta = (H \delta)^{-1}$&lt;/li&gt;
&lt;li&gt;2-level overlapping Schwarz: $\kappa \sim H/\delta$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;handson-with-petsc-demonstrate-these-estimates&#34;&gt;Hands-on with PETSc: demonstrate these estimates&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Linear Poisson with geometric multigrid: &lt;code&gt;src/ksp/ksp/examples/tutorials/ex29.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonlinear problems

&lt;ul&gt;
&lt;li&gt;Symmetric scalar problem: &lt;code&gt;src/snes/examples/tutorials/ex5.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonsymmetric system (lid/thermal-driven cavity): &lt;code&gt;src/snes/examples/tutorials/ex19.c&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Compare preconditioned versus unpreconditioned norms.&lt;/li&gt;
&lt;li&gt;Compare BiCG versus GMRES&lt;/li&gt;
&lt;li&gt;Compare domain decomposition and multigrid preconditioning

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-pc_type asm&lt;/code&gt; (Additive Schwarz)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_type basic&lt;/code&gt; (symmetric, versus &lt;code&gt;restrict&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_overlap 2&lt;/code&gt; (increase overlap)&lt;/li&gt;
&lt;li&gt;Effect of direct subdomain solver: &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_type mg&lt;/code&gt; (Geometric Multigrid)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Use monitors:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_true_residual&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_converged_reason&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Explain methods: &lt;code&gt;-snes_view&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Performance info: &lt;code&gt;-log_view&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;example-inhomogeneous-poisson&#34;&gt;Example: Inhomogeneous Poisson&lt;/h4&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ -\nabla\cdot \Big( \rho(x,y) \nabla u(x,y) \Big) = e^{-10 (x^2 + y^2)} \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;in $\Omega = [0,1]^2$ with variable conductivity&lt;/p&gt;

&lt;p&gt;$$\rho(x,y) = \begin{cases}&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;\rho_0 &amp;amp; (x,y) \in [1/3, 2/3]^2 \\
1 &amp;amp; \text{otherwise}
\end{cases} $$
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where $\rho_0 &amp;gt; 0$ is a parameter (with default $\rho_0 = 1$).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

# You may need to change these for your machine
PETSC_DIR=$HOME/petsc PETSC_ARCH=ompi-optg

# Build the example
make -C $PETSC_DIR -f gmakefile $PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex29

# Link it from the current directory to make it easy to run below
cp -sf $PETSC_DIR/$PETSC_ARCH/tests/ksp/ksp/examples/tutorials/ex29 .
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: Entering directory &#39;/home/jed/petsc&#39;
make: &#39;ompi-optg/tests/ksp/ksp/examples/tutorials/ex29&#39; is up to date.
make: Leaving directory &#39;/home/jed/petsc&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Prints solution DM and then a coordinate DM
! mpiexec -n 2 ./ex29 -da_refine 2 -dm_view
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;DM Object: 2 MPI processes
  type: da
Processor [0] M 9 N 9 m 1 n 2 w 1 s 1
X range of indices: 0 9, Y range of indices: 0 5
Processor [1] M 9 N 9 m 1 n 2 w 1 s 1
X range of indices: 0 9, Y range of indices: 5 9
DM Object: 2 MPI processes
  type: da
Processor [0] M 9 N 9 m 1 n 2 w 2 s 1
X range of indices: 0 9, Y range of indices: 0 5
Processor [1] M 9 N 9 m 1 n 2 w 2 s 1
X range of indices: 0 9, Y range of indices: 5 9
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_view_solution draw -draw_pause 5 -draw_cmap plasma
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This problem is nonsymmetric due to boundary conditions, though symmetric solvers like CG and MINRES may still converge&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_monitor_true_residual -ksp_view -ksp_type gmres
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP preconditioned resid norm 1.338744788815e-02 true resid norm 1.433852280437e-02 ||r(i)||/||b|| 1.000000000000e+00
  1 KSP preconditioned resid norm 6.105013156491e-03 true resid norm 8.819020609674e-03 ||r(i)||/||b|| 6.150578222039e-01
  2 KSP preconditioned resid norm 3.380566739974e-03 true resid norm 3.966597605983e-03 ||r(i)||/||b|| 2.766392089410e-01
  3 KSP preconditioned resid norm 2.248884854426e-03 true resid norm 1.950654466953e-03 ||r(i)||/||b|| 1.360429169426e-01
  4 KSP preconditioned resid norm 1.603958727893e-03 true resid norm 1.729343487982e-03 ||r(i)||/||b|| 1.206082043163e-01
  5 KSP preconditioned resid norm 1.017005335066e-03 true resid norm 1.108652090238e-03 ||r(i)||/||b|| 7.731982613301e-02
  6 KSP preconditioned resid norm 5.817999897588e-04 true resid norm 7.954596575686e-04 ||r(i)||/||b|| 5.547709958842e-02
  7 KSP preconditioned resid norm 3.102671011646e-04 true resid norm 4.651546500795e-04 ||r(i)||/||b|| 3.244090457755e-02
  8 KSP preconditioned resid norm 1.547863442961e-04 true resid norm 2.154582266646e-04 ||r(i)||/||b|| 1.502652885547e-02
  9 KSP preconditioned resid norm 7.772941255716e-05 true resid norm 1.166482147907e-04 ||r(i)||/||b|| 8.135302107631e-03
 10 KSP preconditioned resid norm 3.800559054824e-05 true resid norm 5.777187067722e-05 ||r(i)||/||b|| 4.029136854992e-03
 11 KSP preconditioned resid norm 1.694315416916e-05 true resid norm 3.229096611633e-05 ||r(i)||/||b|| 2.252042735288e-03
 12 KSP preconditioned resid norm 6.705763692270e-06 true resid norm 1.252406213904e-05 ||r(i)||/||b|| 8.734555372208e-04
 13 KSP preconditioned resid norm 2.308568861148e-06 true resid norm 4.636253434420e-06 ||r(i)||/||b|| 3.233424738152e-04
 14 KSP preconditioned resid norm 8.946501825242e-07 true resid norm 1.703002880989e-06 ||r(i)||/||b|| 1.187711526650e-04
 15 KSP preconditioned resid norm 2.744515348301e-07 true resid norm 5.751960627589e-07 ||r(i)||/||b|| 4.011543382863e-05
 16 KSP preconditioned resid norm 1.137618031844e-07 true resid norm 2.081989399152e-07 ||r(i)||/||b|| 1.452025029048e-05
KSP Object: 2 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 2 MPI processes
  type: bjacobi
    number of blocks = 2
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      0 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 1.
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqaij
            rows=153, cols=153
            package used to perform factorization: petsc
            total: nonzeros=713, allocated nonzeros=713
            total number of mallocs used during MatSetValues calls =0
              not using I-node routines
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqaij
      rows=153, cols=153
      total: nonzeros=713, allocated nonzeros=713
      total number of mallocs used during MatSetValues calls =0
        not using I-node routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=289, cols=289
    total: nonzeros=1377, allocated nonzeros=1377
    total number of mallocs used during MatSetValues calls =0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;default-parallel-solver&#34;&gt;Default parallel solver&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Krylov method: GMRES

&lt;ul&gt;
&lt;li&gt;restart length of 30 to bound memory requirement and orthogonalization cost&lt;/li&gt;
&lt;li&gt;classical Gram-Schmidt (compare &lt;code&gt;-ksp_gmres_modifiedgramschmidt&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;left preconditioning, uses preconditioned norm
&lt;span  class=&#34;math&#34;&gt;\( P^{-1} A x = P^{-1} b \)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_norm_type unpreconditioned&lt;/code&gt;
&lt;span  class=&#34;math&#34;&gt;\( A P^{-1} (P x) = b \)&lt;/span&gt;&lt;/li&gt;
&lt;li&gt;Can estimate condition number using Hessenberg matrix&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_view_singularvalues&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Contaminated by restarts, so turn off restart &lt;code&gt;-ksp_gmres_restart 1000&lt;/code&gt; for accurate results&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Preconditioner: block Jacobi

&lt;ul&gt;
&lt;li&gt;Expect condition number to scale with $1/(H h)$ where $H$ is the subdomain diameter and $h$ is the element size&lt;/li&gt;
&lt;li&gt;One block per MPI process&lt;/li&gt;
&lt;li&gt;No extra memory to create subdomain problems&lt;/li&gt;
&lt;li&gt;Create two blocks per process: &lt;code&gt;-pc_bjacobi_local_blocks 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Each subdomain solver can be configured/monitored using the &lt;code&gt;-sub_&lt;/code&gt; prefix&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-sub_ksp_type preonly&lt;/code&gt; (default) means just apply the preconditioner&lt;/li&gt;
&lt;li&gt;Incomplete LU factorization with zero fill&lt;/li&gt;
&lt;li&gt;$O(n)$ cost to compute and apply; same memory as matrix $A$&lt;/li&gt;
&lt;li&gt;gets weaker as $n$ increases&lt;/li&gt;
&lt;li&gt;can fail unpredictably at the worst possible time&lt;/li&gt;
&lt;li&gt;Allow &amp;quot;levels&amp;quot; of fill: &lt;code&gt;-sub_pc_factor_levels 2&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Try &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./ex29 -rho 1e-1 -da_refine 3 -ksp_monitor -ksp_view -sub_pc_factor_levels 3
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  0 KSP Residual norm 3.321621226957e-02 
  1 KSP Residual norm 6.488371997792e-03 
  2 KSP Residual norm 3.872608843511e-03 
  3 KSP Residual norm 2.258796172567e-03 
  4 KSP Residual norm 6.146527388370e-04 
  5 KSP Residual norm 4.540373464970e-04 
  6 KSP Residual norm 1.994013489521e-04 
  7 KSP Residual norm 2.170446909144e-05 
  8 KSP Residual norm 7.079429242940e-06 
  9 KSP Residual norm 2.372198219605e-06 
 10 KSP Residual norm 9.203675161062e-07 
 11 KSP Residual norm 2.924907588760e-07 
KSP Object: 2 MPI processes
  type: gmres
    restart=30, using Classical (unmodified) Gram-Schmidt Orthogonalization with no iterative refinement
    happy breakdown tolerance 1e-30
  maximum iterations=10000, initial guess is zero
  tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
  left preconditioning
  using PRECONDITIONED norm type for convergence test
PC Object: 2 MPI processes
  type: bjacobi
    number of blocks = 2
    Local solve is same for all blocks, in the following KSP and PC objects:
  KSP Object: (sub_) 1 MPI processes
    type: preonly
    maximum iterations=10000, initial guess is zero
    tolerances:  relative=1e-05, absolute=1e-50, divergence=10000.
    left preconditioning
    using NONE norm type for convergence test
  PC Object: (sub_) 1 MPI processes
    type: ilu
      out-of-place factorization
      3 levels of fill
      tolerance for zero pivot 2.22045e-14
      matrix ordering: natural
      factor fill ratio given 1., needed 2.34642
        Factored matrix follows:
          Mat Object: 1 MPI processes
            type: seqaij
            rows=153, cols=153
            package used to perform factorization: petsc
            total: nonzeros=1673, allocated nonzeros=1673
            total number of mallocs used during MatSetValues calls =0
              not using I-node routines
    linear system matrix = precond matrix:
    Mat Object: 1 MPI processes
      type: seqaij
      rows=153, cols=153
      total: nonzeros=713, allocated nonzeros=713
      total number of mallocs used during MatSetValues calls =0
        not using I-node routines
  linear system matrix = precond matrix:
  Mat Object: 2 MPI processes
    type: mpiaij
    rows=289, cols=289
    total: nonzeros=1377, allocated nonzeros=1377
    total number of mallocs used during MatSetValues calls =0
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;scaling-estimates&#34;&gt;Scaling estimates&lt;/h3&gt;

&lt;h4 id=&#34;dependence-on-h&#34;&gt;Dependence on $h$&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 16 --oversubscribe ./ex29 -da_refine 3 -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 20
Iteratively computed extreme singular values: max 1.9384 min 0.0694711 max/min 27.9023
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

for refine in {4..8}; do
  mpiexec -n 16 --oversubscribe ./ex29 -da_refine $refine -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 27
Iteratively computed extreme singular values: max 1.98356 min 0.0338842 max/min 58.5395
Linear solve converged due to CONVERGED_RTOL iterations 36
Iteratively computed extreme singular values: max 2.04703 min 0.0167502 max/min 122.209
Linear solve converged due to CONVERGED_RTOL iterations 47
Iteratively computed extreme singular values: max 2.12834 min 0.00830794 max/min 256.182
Linear solve converged due to CONVERGED_RTOL iterations 62
Iteratively computed extreme singular values: max 2.1865 min 0.00412757 max/min 529.731
Linear solve converged due to CONVERGED_RTOL iterations 82
Iteratively computed extreme singular values: max 2.22724 min 0.00206119 max/min 1080.56
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash

for refine in {3..8}; do
  mpiexec -n 16 --oversubscribe ./ex29 -da_refine $refine -pc_type asm -sub_pc_type lu -ksp_gmres_restart 1000 -ksp_converged_reason -ksp_view_singularvalues
done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 12
Iteratively computed extreme singular values: max 1.39648 min 0.183011 max/min 7.63057
Linear solve converged due to CONVERGED_RTOL iterations 16
Iteratively computed extreme singular values: max 1.68852 min 0.0984075 max/min 17.1584
Linear solve converged due to CONVERGED_RTOL iterations 23
Iteratively computed extreme singular values: max 1.8569 min 0.0494302 max/min 37.5661
Linear solve converged due to CONVERGED_RTOL iterations 31
Iteratively computed extreme singular values: max 1.9503 min 0.0247646 max/min 78.7537
Linear solve converged due to CONVERGED_RTOL iterations 41
Iteratively computed extreme singular values: max 2.03979 min 0.0123563 max/min 165.081
Linear solve converged due to CONVERGED_RTOL iterations 54
Iteratively computed extreme singular values: max 2.12275 min 0.00615712 max/min 344.764
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;%%bash
cat &amp;gt; results.csv &amp;lt;&amp;lt;EOF
method,refine,its,cond
bjacobi,3,20,27.90
bjacobi,4,27,58.54
bjacobi,5,36,122.2
bjacobi,6,47,256.2
bjacobi,7,62,529.7
bjacobi,8,82,1080.6
asm,3,12,7.63
asm,4,16,17.15
asm,5,23,37.57
asm,6,31,78.75
asm,7,41,165.1
asm,8,54,344.8
EOF
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import pandas
import seaborn
df = pandas.read_csv(&#39;results.csv&#39;)
n1 = 2**(df.refine + 1) # number of points per dimension
df[&#39;P&#39;] = 16      # number of processes
df[&#39;N&#39;] = n1**2    # number of dofs in global problem
df[&#39;h&#39;] = 1/n1
df[&#39;H&#39;] = 0.25 # 16 procs = 4x4 process grid
df[&#39;1/Hh&#39;] = 1/(df.H * df.h)

seaborn.lmplot(x=&#39;1/Hh&#39;, y=&#39;cond&#39;, hue=&#39;method&#39;, data=df)
df
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;method&lt;/th&gt;
      &lt;th&gt;refine&lt;/th&gt;
      &lt;th&gt;its&lt;/th&gt;
      &lt;th&gt;cond&lt;/th&gt;
      &lt;th&gt;P&lt;/th&gt;
      &lt;th&gt;N&lt;/th&gt;
      &lt;th&gt;h&lt;/th&gt;
      &lt;th&gt;H&lt;/th&gt;
      &lt;th&gt;1/Hh&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;20&lt;/td&gt;
      &lt;td&gt;27.90&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;0.062500&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;1&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;27&lt;/td&gt;
      &lt;td&gt;58.54&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;0.031250&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;128.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;36&lt;/td&gt;
      &lt;td&gt;122.20&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;4096&lt;/td&gt;
      &lt;td&gt;0.015625&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;256.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;47&lt;/td&gt;
      &lt;td&gt;256.20&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;16384&lt;/td&gt;
      &lt;td&gt;0.007812&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;512.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;62&lt;/td&gt;
      &lt;td&gt;529.70&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;65536&lt;/td&gt;
      &lt;td&gt;0.003906&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;1024.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;bjacobi&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;82&lt;/td&gt;
      &lt;td&gt;1080.60&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;262144&lt;/td&gt;
      &lt;td&gt;0.001953&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;2048.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;3&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;7.63&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;256&lt;/td&gt;
      &lt;td&gt;0.062500&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;64.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;17.15&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;1024&lt;/td&gt;
      &lt;td&gt;0.031250&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;128.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;5&lt;/td&gt;
      &lt;td&gt;23&lt;/td&gt;
      &lt;td&gt;37.57&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;4096&lt;/td&gt;
      &lt;td&gt;0.015625&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;256.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;9&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;31&lt;/td&gt;
      &lt;td&gt;78.75&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;16384&lt;/td&gt;
      &lt;td&gt;0.007812&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;512.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;10&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;7&lt;/td&gt;
      &lt;td&gt;41&lt;/td&gt;
      &lt;td&gt;165.10&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;65536&lt;/td&gt;
      &lt;td&gt;0.003906&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;1024.0&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;11&lt;/td&gt;
      &lt;td&gt;asm&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;344.80&lt;/td&gt;
      &lt;td&gt;16&lt;/td&gt;
      &lt;td&gt;262144&lt;/td&gt;
      &lt;td&gt;0.001953&lt;/td&gt;
      &lt;td&gt;0.25&lt;/td&gt;
      &lt;td&gt;2048.0&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_16_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import numpy as np
df[&#39;1/sqrt(Hh)&#39;] = np.sqrt(df[&#39;1/Hh&#39;])
seaborn.lmplot(x=&#39;1/sqrt(Hh)&#39;, y=&#39;its&#39;, hue=&#39;method&#39;, data=df);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_17_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;cost&#34;&gt;Cost&lt;/h4&gt;

&lt;p&gt;Let $n = N/P$ be the subdomain size and suppose $k$ iterations are needed.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Matrix assembly scales like $O(n)$ (perfect parallelism)&lt;/li&gt;
&lt;li&gt;2D factorization in each subdomain scales as $O(n^{3/2})$&lt;/li&gt;
&lt;li&gt;Preconditioner application scales like $O(n \log n)$&lt;/li&gt;
&lt;li&gt;Matrix multiplication scales like $O(n)$&lt;/li&gt;
&lt;li&gt;GMRES scales like $O(k^2 n) + O(k^2 \log P)$

&lt;ul&gt;
&lt;li&gt;With restart length $r \ll k$, GMRES scales with $O(krn) + O(kr\log P)$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 --oversubscribe ./ex29 -da_refine 8 -pc_type asm -sub_pc_type lu -ksp_converged_reason -log_view
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Linear solve converged due to CONVERGED_RTOL iterations 25
************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use &#39;enscript -r -fCourier9&#39; to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./ex29 on a ompi-optg named joule.int.colorado.edu with 2 processors, by jed Wed Oct 16 10:57:30 2019
Using Petsc Development GIT revision: v3.12-32-g78b8d9f084  GIT Date: 2019-10-03 10:45:44 -0500

                         Max       Max/Min     Avg       Total 
Time (sec):           1.484e+00     1.000   1.484e+00
Objects:              1.040e+02     1.000   1.040e+02
Flop:                 1.432e+09     1.004   1.429e+09  2.857e+09
Flop/sec:             9.647e+08     1.004   9.628e+08  1.926e+09
MPI Messages:         6.200e+01     1.000   6.200e+01  1.240e+02
MPI Message Lengths:  2.524e+05     1.000   4.071e+03  5.048e+05
MPI Reductions:       1.710e+02     1.000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --&amp;gt; 2N flop
                            and VecAXPY() for complex vectors of length N --&amp;gt; 8N flop

Summary of Stages:   ----- Time ------  ----- Flop ------  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total    Count   %Total     Avg         %Total    Count   %Total 
 0:      Main Stage: 1.4839e+00 100.0%  2.8574e+09 100.0%  1.240e+02 100.0%  4.071e+03      100.0%  1.630e+02  95.3% 

------------------------------------------------------------------------------------------------------------------------
See the &#39;Profiling&#39; chapter of the users&#39; manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flop: Max - maximum over all processors
                  Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   AvgLen: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flop in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flop over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------
Event                Count      Time (sec)     Flop                              --- Global ---  --- Stage ----  Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   AvgLen  Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage

BuildTwoSided          5 1.0 1.5282e-02 1.7 0.00e+00 0.0 4.0e+00 4.0e+00 0.0e+00  1  0  3  0  0   1  0  3  0  0     0
BuildTwoSidedF         4 1.0 1.1949e-0217.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatMult               25 1.0 2.8539e-02 1.0 2.96e+07 1.0 5.0e+01 4.1e+03 0.0e+00  2  2 40 41  0   2  2 40 41  0  2071
MatSolve              26 1.0 2.9259e-01 1.0 3.50e+08 1.0 0.0e+00 0.0e+00 0.0e+00 20 25  0  0  0  20 25  0  0  0  2393
MatLUFactorSym         1 1.0 1.5648e-01 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00 10  0  0  0  0  10  0  0  0  0     0
MatLUFactorNum         1 1.0 5.9458e-01 1.1 8.64e+08 1.0 0.0e+00 0.0e+00 0.0e+00 39 60  0  0  0  39 60  0  0  0  2896
MatAssemblyBegin       3 1.0 1.0730e-0282.8 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatAssemblyEnd         3 1.0 9.8794e-03 1.1 0.00e+00 0.0 3.0e+00 1.4e+03 4.0e+00  1  0  2  1  2   1  0  2  1  2     0
MatGetRowIJ            1 1.0 5.0642e-03 1.6 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
MatCreateSubMats       1 1.0 3.9036e-02 1.2 0.00e+00 0.0 1.0e+01 7.0e+03 1.0e+00  2  0  8 14  1   2  0  8 14  1     0
MatGetOrdering         1 1.0 8.0494e-02 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  5  0  0  0  0   5  0  0  0  0     0
MatIncreaseOvrlp       1 1.0 1.5691e-02 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+00  1  0  0  0  1   1  0  0  0  1     0
KSPSetUp               2 1.0 2.8898e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 1.0e+01  0  0  0  0  6   0  0  0  0  6     0
KSPSolve               1 1.0 1.2704e+00 1.0 1.43e+09 1.0 1.0e+02 4.1e+03 1.1e+02 86100 82 83 64  86100 82 83 67  2249
KSPGMRESOrthog        25 1.0 8.4230e-02 1.0 1.71e+08 1.0 0.0e+00 0.0e+00 2.5e+01  6 12  0  0 15   6 12  0  0 15  4062
DMCreateMat            1 1.0 6.0364e-02 1.0 0.00e+00 0.0 3.0e+00 1.4e+03 6.0e+00  4  0  2  1  4   4  0  2  1  4     0
SFSetGraph             5 1.0 3.0582e-04 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFSetUp                5 1.0 3.2978e-02 1.5 0.00e+00 0.0 1.2e+01 1.4e+03 0.0e+00  2  0 10  3  0   2  0 10  3  0     0
SFBcastOpBegin        51 1.0 7.6917e-03 1.0 0.00e+00 0.0 1.0e+02 4.1e+03 0.0e+00  1  0 82 83  0   1  0 82 83  0     0
SFBcastOpEnd          51 1.0 1.0617e-02 1.9 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
SFReduceBegin         26 1.0 5.9807e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
SFReduceEnd           26 1.0 5.0625e-03 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecMDot               25 1.0 4.1009e-02 1.0 8.57e+07 1.0 0.0e+00 0.0e+00 2.5e+01  3  6  0  0 15   3  6  0  0 15  4171
VecNorm               26 1.0 6.5928e-03 1.3 6.86e+06 1.0 0.0e+00 0.0e+00 2.6e+01  0  0  0  0 15   0  0  0  0 16  2076
VecScale              26 1.0 2.2696e-03 1.0 3.43e+06 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3015
VecCopy                1 1.0 1.2067e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecSet                85 1.0 6.4445e-03 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAXPY                1 1.0 1.7286e-04 1.0 2.64e+05 1.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0  3045
VecMAXPY              26 1.0 4.5977e-02 1.0 9.23e+07 1.0 0.0e+00 0.0e+00 0.0e+00  3  6  0  0  0   3  6  0  0  0  4007
VecAssemblyBegin       2 1.0 1.3040e-03 2.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         2 1.0 4.9600e-06 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin      129 1.0 2.7052e-02 1.0 0.00e+00 0.0 1.0e+02 4.1e+03 0.0e+00  2  0 82 83  0   2  0 82 83  0     0
VecScatterEnd         77 1.0 1.5437e-02 1.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  1  0  0  0  0   1  0  0  0  0     0
VecNormalize          26 1.0 8.8965e-03 1.2 1.03e+07 1.0 0.0e+00 0.0e+00 2.6e+01  1  1  0  0 15   1  1  0  0 16  2307
PCSetUp                2 1.0 8.5827e-01 1.0 8.64e+08 1.0 1.3e+01 5.7e+03 7.0e+00 58 60 10 15  4  58 60 10 15  4  2006
PCSetUpOnBlocks        1 1.0 7.9431e-01 1.0 8.64e+08 1.0 0.0e+00 0.0e+00 0.0e+00 53 60  0  0  0  53 60  0  0  0  2168
PCApply               26 1.0 3.3956e-01 1.0 3.50e+08 1.0 5.2e+01 4.1e+03 0.0e+00 23 25 42 42  0  23 25 42 42  0  2062
PCApplyOnBlocks       26 1.0 2.9531e-01 1.0 3.50e+08 1.0 0.0e+00 0.0e+00 0.0e+00 20 25  0  0  0  20 25  0  0  0  2371
------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants&#39; Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage

       Krylov Solver     2              2        20056     0.
     DMKSP interface     1              1          664     0.
              Matrix     5              5    105275836     0.
    Distributed Mesh     3              3        15760     0.
           Index Set    17             17      5309508     0.
   IS L to G Mapping     3              3      2119704     0.
   Star Forest Graph    11             11        10648     0.
     Discrete System     3              3         2856     0.
              Vector    50             50     45457728     0.
         Vec Scatter     5              5         4008     0.
      Preconditioner     2              2         2000     0.
              Viewer     2              1          848     0.
========================================================================================================================
Average time to get PetscTime(): 3.32e-08
Average time for MPI_Barrier(): 1.404e-06
Average time for zero size MPI_Send(): 8.8545e-06
#PETSc Option Table entries:
-da_refine 8
-ksp_converged_reason
-log_view
-malloc_test
-pc_type asm
-sub_pc_type lu
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --download-ctetgen --download-exodusii --download-hypre --download-ml --download-mumps --download-netcdf --download-pnetcdf --download-scalapack --download-sundials --download-superlu --download-superlu_dist --download-triangle --with-debugging=0 --with-hdf5 --with-med --with-metis --with-mpi-dir=/home/jed/usr/ccache/ompi --with-parmetis --with-suitesparse --with-x --with-zlib COPTFLAGS=&amp;quot;-O2 -march=native -ftree-vectorize -g&amp;quot; PETSC_ARCH=ompi-optg
-----------------------------------------
Libraries compiled on 2019-10-03 21:38:02 on joule 
Machine characteristics: Linux-5.3.1-arch1-1-ARCH-x86_64-with-arch
Using PETSc directory: /home/jed/petsc
Using PETSc arch: ompi-optg
-----------------------------------------

Using C compiler: /home/jed/usr/ccache/ompi/bin/mpicc  -fPIC -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fstack-protector -fvisibility=hidden -O2 -march=native -ftree-vectorize -g  
Using Fortran compiler: /home/jed/usr/ccache/ompi/bin/mpif90  -fPIC -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g -O    
-----------------------------------------

Using include paths: -I/home/jed/petsc/include -I/home/jed/petsc/ompi-optg/include -I/home/jed/usr/ccache/ompi/include
-----------------------------------------

Using C linker: /home/jed/usr/ccache/ompi/bin/mpicc
Using Fortran linker: /home/jed/usr/ccache/ompi/bin/mpif90
Using libraries: -Wl,-rpath,/home/jed/petsc/ompi-optg/lib -L/home/jed/petsc/ompi-optg/lib -lpetsc -Wl,-rpath,/home/jed/petsc/ompi-optg/lib -L/home/jed/petsc/ompi-optg/lib -Wl,-rpath,/usr/lib/openmpi -L/usr/lib/openmpi -Wl,-rpath,/usr/lib/gcc/x86_64-pc-linux-gnu/9.1.0 -L/usr/lib/gcc/x86_64-pc-linux-gnu/9.1.0 -lHYPRE -lcmumps -ldmumps -lsmumps -lzmumps -lmumps_common -lpord -lscalapack -lumfpack -lklu -lcholmod -lbtf -lccolamd -lcolamd -lcamd -lamd -lsuitesparseconfig -lsuperlu -lsuperlu_dist -lml -lsundials_cvode -lsundials_nvecserial -lsundials_nvecparallel -llapack -lblas -lexodus -lnetcdf -lpnetcdf -lmedC -lmed -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -lparmetis -lmetis -ltriangle -lm -lz -lX11 -lctetgen -lstdc++ -ldl -lmpi_usempif08 -lmpi_usempi_ignore_tkr -lmpi_mpifh -lmpi -lgfortran -lm -lgfortran -lm -lgcc_s -lquadmath -lpthread -lquadmath -lstdc++ -ldl
-----------------------------------------
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;suggested-exercises&#34;&gt;Suggested exercises&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;There is no substitute for experimentation.  Try some different methods or a different example.  How do the constants and scaling compare?&lt;/li&gt;
&lt;li&gt;Can you estimate parameters to model the leading costs for this solver?

&lt;ul&gt;
&lt;li&gt;In your model, how does degrees of freedom solved per second per process depend on discretization size $h$?&lt;/li&gt;
&lt;li&gt;What would be optimal?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Domain Decomposition Preconditioning</title>
      <link>https://cucs-hpsc.github.io/fall2019/dd-preconditioning/</link>
      <pubDate>Mon, 14 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/dd-preconditioning/</guid>
      <description>&lt;h2 id=&#34;classical-methods&#34;&gt;Classical methods&lt;/h2&gt;

&lt;p&gt;We have discussed the Jacobi preconditioner
&lt;span  class=&#34;math&#34;&gt;\( P_{\text{Jacobi}}^{-1} = D^{-1} \)&lt;/span&gt;
where $D$ is the diagonal of $A$.
Gauss-Seidel is
&lt;span  class=&#34;math&#34;&gt;\( P_{GS}^{-1} = (L+D)^{-1} \)&lt;/span&gt;
where $L$ is the (strictly) lower triangular part of $A$.  The upper triangular part may be used instead, or a symmetric form
&lt;span  class=&#34;math&#34;&gt;\( P_{SGS}^{-1} = (D+U)^{-1} D (L+D)^{-1} . \)&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;[&lt;em&gt;Edit after class&lt;/em&gt;: fixed mistake in the above formula and added snippet below.]&lt;/p&gt;

&lt;h4 id=&#34;aside-where-does-psgs1-come-from&#34;&gt;Aside: Where does $P_{SGS}^{-1}$ come from?&lt;/h4&gt;

&lt;p&gt;Let&#39;s take the error iteration matrix for a forward sweep $I - (L+D)^{-1} A$ followed by a backward sweep $I - (D+U)^{-1}A$ and compute&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[\begin{align}
I - P_{SGS}^{-1} A &amp;= \big( I - (D+U)^{-1} A \big) \big(I - (L+D)^{-1} A \big) \\
  &amp;= I - (D+U)^{-1} A - (L+D)^{-1} A + (D+U)^{-1} A (L+D)^{-1} A \\
  &amp;= I - \Big( (D+U)^{-1} + (L+D)^{-1} - (D+U)^{-1} A (L+D)^{-1} \Big) A \\
  &amp;= I - \Big( (D+U)^{-1} + \underbrace{\big[I - (D+U)^{-1} A \big]}_{I - (D+U)^{-1} (D+U+L)} (L+D)^{-1} \Big) A \\
  &amp;= I - \Big( (D+U)^{-1} - (D+U)^{-1} L (L+D)^{-1} \Big) A \\
  &amp;= I - \Big( (D+U)^{-1} - (D+U)^{-1} \underbrace{(L+D-D) (L+D)^{-1}}_{I - D (L+D)^{-1}} \Big) A \\
  &amp;= I - \underbrace{(D+U)^{-1} D (L+D)^{-1}}_{P_{SGS}^{-1}} A .
\end{align}\]&lt;/span&gt;&lt;/p&gt;

&lt;h3 id=&#34;further-resources&#34;&gt;Further resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www-users.cs.umn.edu/~saad/IterMethBook_2ndEd.pdf&#34;&gt;Saad (2003) &lt;strong&gt;Iterative Methods&lt;/strong&gt;&lt;/a&gt;: Chapter 4: Basic Iterative Methods&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;domain-decomposition&#34;&gt;Domain decomposition&lt;/h2&gt;

&lt;p&gt;Suppose we know how to solve problems on &amp;quot;subdomains&amp;quot;, which may overlap.&lt;/p&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/a/a9/Ddm_original_logo.png&#34; alt=&#34;&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;p&gt;This could be possible because they have special structure (e.g., above) or because they are small enough.  We want to use this ability to solve the global problem.&lt;/p&gt;

&lt;h3 id=&#34;alternating-schwarz-method&#34;&gt;Alternating Schwarz method&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;bc_circle = guess()
while not converged:
    u_circle = solve(A_circle, bc_circle)
    bc_rectangle = eval(u_circle, rectangle)
    u_rectangle = solve(A_rectangle, bc_rectangle)
    bc_circle = eval(u_rectangle, circle)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This method was proposed in 1870 by &lt;a href=&#34;https://en.wikipedia.org/wiki/Hermann_Schwarz&#34;&gt;Hermann Schwarz&lt;/a&gt; as a theoretical tool, and is now called a &amp;quot;multiplicative&amp;quot; Schwarz method because the solves depend on each other.  We can see it as a generalization of Gauss-Seidel in which we solve on subdomains instead of at individual grid points.  As with Gauss-Seidel, it is difficult to expose parallelism.&lt;/p&gt;

&lt;h3 id=&#34;additive-schwarz-methods&#34;&gt;Additive Schwarz methods&lt;/h3&gt;

&lt;p&gt;The additive Schwarz method is more comparable to Jacobi, with each domain solved in parallel.  Our fundamental operation will be an embedding of each subdomain $V_i$ into the global domain $V$, which we call the &lt;strong&gt;prolongation&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ P_i : V_i \to V \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;The transpose of prolongation, $P_i^T$, will sometimes be called &lt;strong&gt;restriction&lt;/strong&gt;.
Let&#39;s work an example.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)

N = 21
x = np.linspace(-1, 1, N)
overlap = 0
domains = [(0,N//3+overlap), (N//3-overlap, 2*N//3+overlap), (2*N//3-overlap, N)]
P = []
for i, (start, end) in enumerate(domains):
    P.append(np.eye(N, end-start, -start))
u = 1 + np.cos(3*x)
plt.plot(x, u)
u1 = P[1].T @ u   # Restrict to subdomain 1
plt.plot(P[1].T @ x, u1, &#39;o&#39;)
print(P[1].shape)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(21, 7)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_3_1.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.plot(x, P[1] @ u1, &#39;o-&#39;);  # Prolong to global domain
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_4_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Define a Laplacian
A = np.eye(N)
A[1:-1] = (2*np.eye(N-2, N, 1) - np.eye(N-2, N, 0) - np.eye(N-2, N, 2)) / (N-1)**2
A[:5, :5]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 1.    ,  0.    ,  0.    ,  0.    ,  0.    ],
       [-0.0025,  0.005 , -0.0025,  0.    ,  0.    ],
       [ 0.    , -0.0025,  0.005 , -0.0025,  0.    ],
       [ 0.    ,  0.    , -0.0025,  0.005 , -0.0025],
       [ 0.    ,  0.    ,  0.    , -0.0025,  0.005 ]])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The first and last rows implement boundary conditions; the interior is the familiar centered difference method for the Laplacian.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A1 = P[1].T @ A @ P[1]
A1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 0.005 , -0.0025,  0.    ,  0.    ,  0.    ,  0.    ,  0.    ],
       [-0.0025,  0.005 , -0.0025,  0.    ,  0.    ,  0.    ,  0.    ],
       [ 0.    , -0.0025,  0.005 , -0.0025,  0.    ,  0.    ,  0.    ],
       [ 0.    ,  0.    , -0.0025,  0.005 , -0.0025,  0.    ,  0.    ],
       [ 0.    ,  0.    ,  0.    , -0.0025,  0.005 , -0.0025,  0.    ],
       [ 0.    ,  0.    ,  0.    ,  0.    , -0.0025,  0.005 , -0.0025],
       [ 0.    ,  0.    ,  0.    ,  0.    ,  0.    , -0.0025,  0.005 ]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;rhs = np.zeros_like(x)
rhs[0] = 1 # Boundary condition
u = np.zeros_like(x) # Initial guess
for iter in range(5):
    r = rhs - A @ u      # Residual
    u_next = u.copy()
    for Pi in P:
        Ai = Pi.T @ A @ Pi
        ui = np.linalg.solve(Ai, Pi.T @ r)
        u_next += Pi @ ui
    u = u_next
    plt.plot(x, u, &#39;o-&#39;, label=f&#39;iter {iter}&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;figure&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34;&gt;&lt;/figure&gt;&lt;/p&gt;

&lt;h4 id=&#34;handson&#34;&gt;Hands-on&lt;/h4&gt;

&lt;p&gt;Go back and increase &lt;code&gt;overlap&lt;/code&gt; to see how it affects convergence.&lt;/p&gt;

&lt;h3 id=&#34;theory&#34;&gt;Theory&lt;/h3&gt;

&lt;p&gt;Given a linear operator $A : V \to V$, suppose we have a collection of prolongation operators $P_i : V_i \to V$.  The columns of $P_i$ are &amp;quot;basis functions&amp;quot; for the subspace $V_i$.  The Galerkin operator $A_i = P_i^T A P_i$ is the action of the original operator $A$ in the subspace.&lt;/p&gt;

&lt;p&gt;Define the subspace projection&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ S_i = P_i A_i^{-1} P_i^T A . \]&lt;/span&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$S_i$ is a projection: $S_i^2 = S_i$&lt;/li&gt;
&lt;li&gt;If $A$ is SPD, $S_i$ is SPD with respect to the $A$ inner product $x^T A y$&lt;/li&gt;
&lt;li&gt;$I - S_i$ is $A$-orthogonal to the range of $P_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;S1 = P[1] @ np.linalg.inv(A1) @ P[1].T @ A
np.linalg.norm(S1 @ S1 - S1)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;1.2457015262873114e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;I = np.eye(*S1.shape)
np.linalg.norm(P[1].T @ A @ (I - S1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;6.9011609626021565e-18
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Note, the concept of $A$-orthogonality is meaningful only when $A$ is SPD.
Does the mathematical expression $ P_i^T A (I - S_i) = 0 $ hold even when $A$ is nonsymmetric?&lt;/p&gt;

&lt;p&gt;These projections may be applied additively&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ I - \sum_{i=0}^n S_i, \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;multiplicatively&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\[ \prod_{i=0}^n (I - S_i), \]&lt;/span&gt;&lt;/p&gt;

&lt;p&gt;or in some hybrid manner, such as&lt;/p&gt;

&lt;p&gt;&lt;span  class=&#34;math&#34;&gt;\( (I - S_0) (I - \sum_{i=1}^n S_i) . \)&lt;/span&gt;
In each case above, the action is expressed in terms of the error iteration operator.&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Jacobi corresponds to the additive preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Gauss-Seidel is the multiplicate preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Block Jacobi corresponds to labeling &amp;quot;subdomains&amp;quot; and $P_i$ as the columns of the identity corresponding to non-overlapping subdomains&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz corresponds to overlapping subdomains&lt;/li&gt;
&lt;li&gt;$P_i$ are eigenvectors of $A$&lt;/li&gt;
&lt;li&gt;A domain is partitioned into interior $V_{I}$ and interface $V_\Gamma$ degrees of freedom.  $P_{I}$ is embedding of the interior degrees of freedom while $P_\Gamma$ is &amp;quot;harmonic extension&amp;quot; of the interface degrees of freedom.  Consider the multiplicative combination $(I - S_\Gamma)(I - S_{I})$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;convergence-theory&#34;&gt;Convergence theory&lt;/h3&gt;

&lt;p&gt;The formal convergence is beyond the scope of this course, but the following estimates are useful.  We let $h$ be the element diameter, $H$ be the subdomain diameter, and $\delta$ be the overlap, each normalized such that the global domain diameter is 1.  We express the convergence in terms of the condition number $\kappa$ for the preconditioned operator.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(Block) Jacobi: $\delta=0$, $\kappa \sim H^{-2} H/h = (Hh)^{-1}$&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz: $\kappa \sim H^{-2} H/\delta = (H \delta)^{-1}$&lt;/li&gt;
&lt;li&gt;2-level overlapping Schwarz: $\kappa \sim H/\delta$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;handson-with-petsc-demonstrate-these-estimates&#34;&gt;Hands-on with PETSc: demonstrate these estimates&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Symmetric example: &lt;code&gt;src/snes/examples/tutorials/ex5.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonsymmetric example: &lt;code&gt;src/snes/examples/tutorials/ex19.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Compare preconditioned versus unpreconditioned norms.&lt;/li&gt;
&lt;li&gt;Compare BiCG versus GMRES&lt;/li&gt;
&lt;li&gt;Compare domain decomposition and multigrid preconditioning

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-pc_type asm&lt;/code&gt; (Additive Schwarz)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_type basic&lt;/code&gt; (symmetric, versus &lt;code&gt;restrict&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_overlap 2&lt;/code&gt; (increase overlap)&lt;/li&gt;
&lt;li&gt;Effect of direct subdomain solver: &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_type mg&lt;/code&gt; (Geometric Multigrid)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Use monitors:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_true_residual&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_converged_reason&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Explain methods: &lt;code&gt;-snes_view&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Performance info: &lt;code&gt;-log_view&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;examples-1&#34;&gt;Examples&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;mpiexec -n 4 ./ex19 -lidvelocity 2 -snes_monitor -da_refine 5 -ksp_monitor -pc_type asm -sub_pc_type lu
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Preconditioning</title>
      <link>https://cucs-hpsc.github.io/fall2019/preconditioning/</link>
      <pubDate>Fri, 11 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/preconditioning/</guid>
      <description>

&lt;h2 id=&#34;preconditioning&#34;&gt;Preconditioning&lt;/h2&gt;

&lt;p&gt;Recall that preconditioning is the act of creating an &amp;ldquo;affordable&amp;rdquo; operation &amp;ldquo;$P^{-1}$&amp;rdquo; such that $P^{-1} A$ (or $A P^{-1}$) is is well-conditoned or otherwise has a &amp;ldquo;nice&amp;rdquo; spectrum.  We then solve the system&lt;/p&gt;

&lt;p&gt;$$ P^{-1} A x = P^{-1} b \quad \text{or}\quad A P^{-1} \underbrace{(P x)}_y = b $$&lt;/p&gt;

&lt;p&gt;in which case the convergence rate depends on the spectrum of the iteration matrix
$$ I - \omega P^{-1} A . $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The preconditioner must be applied on each iteration.&lt;/li&gt;
&lt;li&gt;It is &lt;em&gt;not&lt;/em&gt; merely about finding a good initial guess.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;classical-methods&#34;&gt;Classical methods&lt;/h2&gt;

&lt;p&gt;We have discussed the Jacobi preconditioner&lt;/p&gt;

&lt;p&gt;$$ P_{\text{Jacobi}}^{-1} = D^{-1} $$&lt;/p&gt;

&lt;p&gt;where $D$ is the diagonal of $A$.
Gauss-Seidel is&lt;/p&gt;

&lt;p&gt;$$ P_{GS}^{-1} = (L+D)^{-1} $$&lt;/p&gt;

&lt;p&gt;where $L$ is the (strictly) lower triangular part of $A$.  The upper triangular part may be used instead, or a symmetric form&lt;/p&gt;

&lt;p&gt;$$ P_{SGS}^{-1} = (D+U)^{-1} D (L+D)^{-1} . $$&lt;/p&gt;

&lt;h2 id=&#34;domain-decomposition&#34;&gt;Domain decomposition&lt;/h2&gt;

&lt;p&gt;Given a linear operator $A : V \to V$, suppose we have a collection of prolongation operators $P_i : V_i \to V$.  The columns of $P_i$ are &amp;ldquo;basis functions&amp;rdquo; for the subspace $V_i$.  The Galerkin operator $A_i = P_i^T A P_i$ is the action of the original operator $A$ in the subspace.&lt;/p&gt;

&lt;p&gt;Define the subspace projection&lt;/p&gt;

&lt;p&gt;$$ S_i = P_i A_i^{-1} P_i^T A . $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;$S_i$ is a projection: $S_i^2 = S_i$&lt;/li&gt;
&lt;li&gt;If $A$ is SPD, $S_i$ is SPD with respect to the $A$ inner product $x^T A y$&lt;/li&gt;
&lt;li&gt;$I - S_i$ is $A$-orthogonal to the range of $P_i$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;These projections may be applied additively&lt;/p&gt;

&lt;p&gt;$$ I - \sum_{i=0}^n S_i, $$&lt;/p&gt;

&lt;p&gt;multiplicatively&lt;/p&gt;

&lt;p&gt;$$ \prod_{i=0}^n (I - S_i), $$&lt;/p&gt;

&lt;p&gt;or in some hybrid manner, such as&lt;/p&gt;

&lt;p&gt;$$ (I - S&lt;em&gt;0) (I - \sum&lt;/em&gt;{i=1}^n S_i) . $$
In each case above, the action is expressed in terms of the error iteration operator.&lt;/p&gt;

&lt;h3 id=&#34;examples&#34;&gt;Examples&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Jacobi corresponds to the additive preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Gauss-Seidel is the multiplicate preconditioner with $P_i$ as the $i$th column of the identity&lt;/li&gt;
&lt;li&gt;Block Jacobi corresponds to labeling &amp;ldquo;subdomains&amp;rdquo; and $P_i$ as the columns of the identity corresponding to non-overlapping subdomains&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz corresponds to overlapping subdomains&lt;/li&gt;
&lt;li&gt;$P_i$ are eigenvectors of $A$&lt;/li&gt;
&lt;li&gt;A domain is partitioned into interior $V&lt;em&gt;I$ and interface $V&lt;/em&gt;\Gamma$ degrees of freedom.  $P&lt;em&gt;I$ is embedding of the interior degrees of freedom while $P&lt;/em&gt;\Gamma$ is &amp;ldquo;harmonic extension&amp;rdquo; of the interface degrees of freedom.  Consider the multiplicative combination $(I - S_\Gamma)(I - S_I)$.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;convergence-theory&#34;&gt;Convergence theory&lt;/h3&gt;

&lt;p&gt;The formal convergence is beyond the scope of this course, but the following estimates are useful.  We let $h$ be the element diameter, $H$ be the subdomain diameter, and $\delta$ be the overlap, each normalized such that the global domain diameter is 1.  We express the convergence in terms of the condition number $\kappa$ for the preconditioned operator.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;(Block) Jacobi: $\delta=0$, $\kappa \sim H^{-2} H/h = (Hh)^{-1}$&lt;/li&gt;
&lt;li&gt;Overlapping Schwarz: $\kappa \sim H^{-2} H/\delta = (H \delta)^{-1}$&lt;/li&gt;
&lt;li&gt;2-level overlapping Schwarz: $\kappa \sim H/\delta$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;hands-on-with-petsc-demonstrate-these-estimates&#34;&gt;Hands-on with PETSc: demonstrate these estimates&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Symmetric example: &lt;code&gt;src/snes/examples/tutorials/ex5.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Nonsymmetric example: &lt;code&gt;src/snes/examples/tutorials/ex19.c&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Compare preconditioned versus unpreconditioned norms.&lt;/li&gt;
&lt;li&gt;Compare BiCG versus GMRES&lt;/li&gt;
&lt;li&gt;Compare domain decomposition and multigrid preconditioning

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-pc_type asm&lt;/code&gt; (Additive Schwarz)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_type basic&lt;/code&gt; (symmetric, versus &lt;code&gt;restrict&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_asm_overlap 2&lt;/code&gt; (increase overlap)&lt;/li&gt;
&lt;li&gt;Effect of direct subdomain solver: &lt;code&gt;-sub_pc_type lu&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-pc_type mg&lt;/code&gt; (Geometric Multigrid)&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Use monitors:

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_true_residual&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_monitor_singular_value&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-ksp_converged_reason&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Explain methods: &lt;code&gt;-snes_view&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Performance info: &lt;code&gt;-log_view&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;examples-1&#34;&gt;Examples&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;mpiexec -n 4 ./ex19 -lidvelocity 2 -snes_monitor -da_refine 5 -ksp_monitor -pc_type asm -sub_pc_type lu
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Sparse and iterative linear algebra</title>
      <link>https://cucs-hpsc.github.io/fall2019/iterative-solvers/</link>
      <pubDate>Wed, 09 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/iterative-solvers/</guid>
      <description>

&lt;h1 id=&#34;sparse-and-iterative-linear-algebra&#34;&gt;Sparse and iterative linear algebra&lt;/h1&gt;

&lt;p&gt;Many matrices in applications, particularly the study of physical systems and graphs/networks, have the property that most entries are zero.  We can more efficiently store such systems by storing only the nonzero elements.  We will discuss storage and optimized implementations later.  Many of the methods for sparse systems apply to solving systems with matrices $A$ that can be applied to a vector ($y \gets A x$) in significantly less than $O(n^2)$ complexity, or that are &amp;ldquo;well-conditioned&amp;rdquo; such that an iterative method converges in significantly less than $n$ iterations.&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://mcs.anl.gov/petsc&#34; target=&#34;_blank&#34;&gt;PETSc&lt;/a&gt;, the Portable Extensible Toolkit for Scientific computing, is an open source software package for the parallel solution of algebraic and differential-algebraic equations.  This includes linear algebra, for which PETSc offers a broad variety of implementations.  For general information about PETSc, I refer to &lt;a href=&#34;https://jedbrown.org/files/20150924-PETScPrimer.pdf&#34; target=&#34;_blank&#34;&gt;this primer&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;direct-solves&#34;&gt;Direct solves&lt;/h2&gt;

&lt;p&gt;The complexity of this solve is potentially dominant, so we should understand its cost in terms of the problem size.  The standard method for a direct solve is $LU$ (or Cholesky) factorization.  Given a $2\times 2$ block matrix, the algorithm proceeds as
\begin{split}
  \begin{bmatrix} A &amp;amp; B \ C &amp;amp; D \end{bmatrix} &amp;amp;=
  \begin{bmatrix} L_A &amp;amp; \ C U_A^{-1} &amp;amp; S \end{bmatrix}
  \begin{bmatrix} U_A &amp;amp; L_A^{-1} B \ &amp;amp; 1 \end{bmatrix}
\end{split}
where $L_A U_A = A$ and $S = D - C A^{-1} B$.  The factorization continues by factoring the Schur complement, which may be more dense than its original entries $D$.&lt;/p&gt;

&lt;p&gt;For a sparse operator, the complexity depends on the ordering of degrees of freedom.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;natural&amp;rdquo; ordering&lt;/li&gt;
&lt;li&gt;low-bandwidth ordering&lt;/li&gt;
&lt;li&gt;nested dissection ordering&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;For a structured grid, the &amp;ldquo;natural&amp;rdquo; ordering is the ordering of the original operator.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;sparse-natural.png&#34; alt=&#34;Original operator in the natural ordering&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The red values represent positive entries, blue negative, and cyan stored zeros.&lt;/p&gt;

&lt;p&gt;A sparse direct solve of this system will result in fill up to the bandwidth (showing lower triangular factor here).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;factor-natural.png&#34; alt=&#34;Fill in natural ordering&#34; /&gt;&lt;/p&gt;

&lt;p&gt;These plots can be produced in PETSc using &lt;code&gt;-mat_view draw&lt;/code&gt; and &lt;code&gt;-pc_type lu -pc_factor_mat_ordering_type natural -mat_factor_view draw&lt;/code&gt; (e.g., with &lt;code&gt;-draw_pause 2&lt;/code&gt; to wait 2 seconds for the viewer).&lt;/p&gt;

&lt;p&gt;The Reverse Cuthill-McKee (&lt;code&gt;rcm&lt;/code&gt;) ordering applies a breadth-first search to produce a low-bandwidth ordering.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;factor-rcm.png&#34; alt=&#34;Fill in RCM ordering&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;costs-for-banded-solves&#34;&gt;Costs for banded solves&lt;/h4&gt;

&lt;p&gt;Suppose we have a grid containing $N = n^d$ points in $d$ dimensions.  The corresponding matrix is $N\times N$.  The furthest band is $k = n^{d-1}$ off the diagonal, and factorization creates
* Space: $kN = n^{2d-1} = N^{2-1/d}$
* Compute: $k^2N = n^{3d-2} = N^{3-2/d}$&lt;/p&gt;

&lt;h3 id=&#34;nested-dissection&#34;&gt;Nested dissection&lt;/h3&gt;

&lt;p&gt;The nested dissection (&lt;code&gt;nd&lt;/code&gt;) ordering recursively bisects the domain by finding vertex separators.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/d/d9/Grid_separator.svg&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The separator is ordered last so that each side can be factored independently.  That factorization is done by recursive bisection.  The Schur complement $S$ on the vertex separator is dense, and its factorization dominates the cost.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;factor-nd.png&#34; alt=&#34;Fill in ND ordering&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;costs-for-nested-dissection&#34;&gt;Costs for nested dissection&lt;/h4&gt;

&lt;p&gt;The size of the vertex separator is $n^{d-1}$ so its factorization costs $n^{3(d-1)}$.  This leads to
* $d=3$
  * Space: $N^{&lt;sup&gt;4&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt;}$
  * Time: $N^2$
* $d=2$
  * Space: $N \log N$
  * Time: $N^{&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2&lt;/sub&gt;}$&lt;/p&gt;

&lt;h2 id=&#34;convergence-of-stationary-iterative-methods&#34;&gt;Convergence of stationary iterative methods&lt;/h2&gt;

&lt;h3 id=&#34;richardson-iteration&#34;&gt;Richardson iteration&lt;/h3&gt;

&lt;p&gt;The simplest iterative method is &lt;a href=&#34;https://en.wikipedia.org/wiki/Modified_Richardson_iteration&#34; target=&#34;_blank&#34;&gt;Richardson&amp;rsquo;s method&lt;/a&gt;, which solves $A x = b$ by the iteration
$$ x_{k+1} = x_k + \omega (b - A x_k) $$
where $\omega &amp;gt; 0$ is a damping parameter and $x&lt;em&gt;0$ is an initial guess (possibly the zero vector).  If $b = A x&lt;/em&gt;&lt;em&gt;$, this iteration is equivalent to
$$ x&lt;em&gt;{k+1} - x&lt;/em&gt;&lt;/em&gt; = (x&lt;em&gt;k - x&lt;/em&gt;&lt;em&gt;) - \omega A (x&lt;em&gt;k - x&lt;/em&gt;&lt;/em&gt;) = (I - \omega A) (x&lt;em&gt;k - x&lt;/em&gt;&lt;em&gt;) .$$
It is convenient for convergence analysis to identify the &amp;ldquo;error&amp;rdquo; $e_k = x&lt;em&gt;k - x&lt;/em&gt;&lt;/em&gt;$, in which this becomes
$$ e_{k+1} = (I - \omega A) e_k $$
or
$$ e_k = (I - \omega A)^k e_0 $$
in terms of the initial error.  Evidently powers of the &lt;em&gt;iteration matrix&lt;/em&gt; $I - \omega A$ tell the whole story.
Suppose that the eigendecomposition
$$ X \Lambda X^{-1} = I - \omega A $$
exists.  Then
$$ (I - \omega A)^k = (X \Lambda X^{-1})^k = X \Lambda^k X^{-1} $$
and the convergence (or divergence) rate depends only on the largest magnitude eigenvalue.
This analysis isn&amp;rsquo;t great for two reasons:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Not all matrices are diagonalizable.&lt;/li&gt;
&lt;li&gt;The matrix $X$ may be very ill-conditioned.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;We can repair these weaknesses by using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Schur_decomposition&#34; target=&#34;_blank&#34;&gt;Schur decomposition&lt;/a&gt;
$$ Q R Q^h = I - \omega A $$
where $R$ is right-triangular and $Q$ is unitary (i.e., orthogonal if real-valued; $Q^h$ is the Hermitian conjugate of $Q$).
The Schur decomposition always exists and $Q$ has a condition number of 1.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Where are the eigenvalues in $R$?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Evidently we must find $\omega$ to minimize the maximum eigenvalue of $I - \omega A$.  We can do this if $A$ is well conditioned, but not in general.&lt;/p&gt;

&lt;h3 id=&#34;preconditioning&#34;&gt;Preconditioning&lt;/h3&gt;

&lt;p&gt;Preconditioning is the act of creating an &amp;ldquo;affordable&amp;rdquo; operation &amp;ldquo;$P^{-1}$&amp;rdquo; such that $P^{-1} A$ (or $A P^{-1}$) is is well-conditoned or otherwise has a &amp;ldquo;nice&amp;rdquo; spectrum.  We then solve the system&lt;/p&gt;

&lt;p&gt;$$ P^{-1} A x = P^{-1} b \quad \text{or}\quad A P^{-1} \underbrace{(P x)}_y = b $$&lt;/p&gt;

&lt;p&gt;in which case the convergence rate depends on the spectrum of the iteration matrix
$$ I - \omega P^{-1} A . $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The preconditioner must be applied on each iteration.&lt;/li&gt;
&lt;li&gt;It is &lt;em&gt;not&lt;/em&gt; merely about finding a good initial guess.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;There are two complementary techniques necessary for efficient iterative methods:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&amp;ldquo;accelerators&amp;rdquo; or Krylov methods, which use orthogonality to adaptively converge faster than Richardson&lt;/li&gt;
&lt;li&gt;preconditioners that improve the spectrum of the preconditioned operator&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Although there is ongoing research in Krylov methods and they are immensely useful, I would say preconditioning is 90% of the game for practical applications, particularly as a research area.&lt;/p&gt;

&lt;h1 id=&#34;krylov-subspaces&#34;&gt;Krylov subspaces&lt;/h1&gt;

&lt;p&gt;All matrix iterations work with approximations in a &lt;em&gt;Krylov subspace&lt;/em&gt;, which has the form&lt;/p&gt;

&lt;p&gt;$$ K_n = \big[ b \big| Ab \big| A^2 b \big| \dotsm \big| A^{n-1} b \big] . $$&lt;/p&gt;

&lt;p&gt;This matrix is horribly ill-conditioned and cannot stably be computed as written.  Instead, we seek an orthogonal basis $Q_n$ that spans the same space as $K_n$.  We could write this as a factorization&lt;/p&gt;

&lt;p&gt;$$ K_n = Q_n R_n $$&lt;/p&gt;

&lt;p&gt;where the first column $q_0 = b / \lVert b \rVert$.  The $R_n$ is unnecessary and hopelessly ill-conditioned, so a slightly different procedure is used.&lt;/p&gt;

&lt;h3 id=&#34;arnoldi-iteration&#34;&gt;Arnoldi iteration&lt;/h3&gt;

&lt;p&gt;The Arnoldi iteration applies orthogonal similarity transformations to reduce $A$ to &lt;a href=&#34;https://en.wikipedia.org/wiki/Hessenberg_matrix&#34; target=&#34;_blank&#34;&gt;Hessenberg form&lt;/a&gt;, starting from a vector $q_0 = b$,&lt;/p&gt;

&lt;p&gt;$$ A = Q H Q^h . $$&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s multiply on the right by $Q$ and examine the first $n$ columns,&lt;/p&gt;

&lt;p&gt;$$ A Q&lt;em&gt;n = Q&lt;/em&gt;{n+1} H_n $$
where $H_n$ is an $(n+1) \times n$ Hessenberg matrix.&lt;/p&gt;

&lt;h4 id=&#34;conditioning&#34;&gt;Conditioning&lt;/h4&gt;

&lt;p&gt;This representation is well-conditioned because $Q$ is orthogonal and&lt;/p&gt;

&lt;p&gt;$$ \lVert H&lt;em&gt;n \rVert \le \lVert Q&lt;/em&gt;{n+1}^h \rVert \lVert A \rVert \lVert Q_n \rVert \le \lVert A \rVert $$.&lt;/p&gt;

&lt;p&gt;For a lower bound, we have&lt;/p&gt;

&lt;p&gt;$$ \sigma_{\min}(A)^2 \le x^h A^h A x $$&lt;/p&gt;

&lt;p&gt;for all $x$ of norm 1.  It must also be true for any $x = Q_n y$ where $\lVert y\rVert = 1$, thus&lt;/p&gt;

&lt;p&gt;$$ \sigma_{\min}(A)^2 \le y^h Q_n^h A^h A Q_n y = y^h H&lt;em&gt;n^h Q&lt;/em&gt;{n+1}^h Q_{n+1} H_n y = y^h H_n^h H_n y . $$&lt;/p&gt;

&lt;h4 id=&#34;gmres&#34;&gt;GMRES&lt;/h4&gt;

&lt;p&gt;GMRES (Generalized Minimum Residual) minimizes
$$ \lVert A x - b \rVert $$
over the subspace $Q_n$.  I.e., $x = Q&lt;em&gt;n y$ for some $y$.  By the recurrence above, this is equivalent to
$$ \lVert Q&lt;/em&gt;{n+1} H_n y - b \lVert $$
which can be solved by minimizing
$$ \lVert H&lt;em&gt;n y - Q&lt;/em&gt;{n+1}^h b \rVert . $$
Since $q_0 = b/\lVert b \lVert$, the least squares problem is to minimize
$$ \Big\lVert H_n y - \lVert b \rVert e_0 \Big\rVert . $$
The solution of this least squares problem is achieved by incrementally updating a $QR$ factorization of $H_n$.&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;Notes&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;GMRES minimizes the 2-norm of the residual $\lVert r_n \rVert$ which is equivalent to the $A^T A$ norm of the error $\lVert x&lt;em&gt;n - x&lt;/em&gt;* \rVert_{A^T A}$.&lt;/li&gt;
&lt;li&gt;The solution $x_n$ constructed by GMRES at iteration $n$ is not explicitly available.  If a solution is needed, it must be constructed by solving the $(n+1)\times n$ least squares problem and forming the solution as a linear combination of the $n$ vectors $Q_n$.  The leading cost is $2mn$ where $m \gg n$.&lt;/li&gt;
&lt;li&gt;The residual vector $r_n = A x_n - b$ is not explicitly available in GMRES.  To compute it, first build the solution $x_n$ as above.&lt;/li&gt;
&lt;li&gt;GMRES needs to store the full $Q_n$, which is unaffordable for large $n$ (many iterations).  The standard solution is to choose a &amp;ldquo;restart&amp;rdquo; $k$ and to discard $Q_n$ and start over with an initial guess $x_k$ after each $k$ iterations.  This algorithm is called GMRES(k).  PETSc&amp;rsquo;s default solver is GMRES(30) and the restart can be controlled using the run-time option &lt;code&gt;-ksp_gmres_restart&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Most implementations of GMRES use classical Gram-Schmidt because it is much faster in parallel (one reduction per iteration instead of $n$ reductions per iteration).  The PETSc option &lt;code&gt;-ksp_gmres_modifiedgramschmidt&lt;/code&gt; can be used when you suspect that classical Gram-Schmidt may be causing instability.&lt;/li&gt;
&lt;li&gt;There is a very similar (and older) algorithm called GCR that maintains $x_n$ and $r_n$.  This is useful, for example, if a convergence tolerance needs to inspect individual entries.  GCR requires $2n$ vectors instead of $n$ vectors, and can tolerate a nonlinear preconditioner.  FGMRES is a newer algorithm with similar properties to GCR.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;lanczos-iteration-the-symmetric-case&#34;&gt;Lanczos iteration: the symmetric case&lt;/h3&gt;

&lt;p&gt;If $A$ is symmetric, then $H = Q^T A Q$ is also symmetric.  Since $H$ is Hessenberg, this means $H$ is tridiagonal.  Instead of storing $Q_n$, it is sufficient to store only the last two columns since the iteration satisfies a 3-term recurrence.  The analog of GMRES for the symmetric case is called MINRES and is also useful for solving symmetric indefinite problems.&lt;/p&gt;

&lt;h4 id=&#34;conjugate-gradients&#34;&gt;Conjugate Gradients&lt;/h4&gt;

&lt;p&gt;Instead of minimizing the $A^T A$ norm of the error, the Conjugate Gradient method minimizes the $A$ norm of the error.  For $A$ to induce a norm, it must be symmetric positive definite.  &lt;a href=&#34;http://www.cs.cmu.edu/%7Equake-papers/painless-conjugate-gradient.pdf&#34; target=&#34;_blank&#34;&gt;Jeremy Shewchuck&amp;rsquo;s guide to CG&lt;/a&gt; is an excellent resource.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Elemental for distributed dense linear algebra</title>
      <link>https://cucs-hpsc.github.io/fall2019/elemental/</link>
      <pubDate>Fri, 04 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/elemental/</guid>
      <description>

&lt;h2 id=&#34;flame-diagram-for-cholesky&#34;&gt;FLAME diagram for Cholesky&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;elemental-chol.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;a-m-c-m-r-distribution&#34;&gt;$A[M_C, M_R]$ distribution&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;elemental-cyclic.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;the-a-distribution&#34;&gt;The $A[&lt;em&gt;,&lt;/em&gt;]$ distribution&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;elemental-star.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Poulson et al. (2013) &lt;a href=&#34;https://wiki.alcf.anl.gov/parts/images/1/14/Elemental.pdf&#34; target=&#34;_blank&#34;&gt;Elemental: A New Framework for Distributed Memory Dense Matrix Computations&lt;/a&gt; doi:&lt;a href=&#34;https://doi.org/10.1145/2427023.2427030&#34; target=&#34;_blank&#34;&gt;10.&lt;sup&gt;1145&lt;/sup&gt;&amp;frasl;&lt;sub&gt;2427023&lt;/sub&gt;.2427030&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Orthogonality and Conditioning</title>
      <link>https://cucs-hpsc.github.io/fall2019/dense-linalg-3/</link>
      <pubDate>Fri, 04 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/dense-linalg-3/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;orthogonalization-and-qr-factorization&#34;&gt;Orthogonalization and QR factorization&lt;/h2&gt;

&lt;p&gt;Given a collection of vectors (columns of a matrix), we can find an orthogonal basis by applying the above procedure one column at a time and saving the result.  Let&amp;rsquo;s think of the first two columns,
$$ \Bigg[ a_0 \, \Bigg| \, a_1 \Bigg] = \Bigg[ q_0 \,\Bigg|\, q&lt;em&gt;1 \Bigg]
\begin{bmatrix} r&lt;/em&gt;{00} &amp;amp; r&lt;em&gt;{01} \ 0 &amp;amp; r&lt;/em&gt;{11} \end{bmatrix} . $$&lt;/p&gt;

&lt;h4 id=&#34;column-0&#34;&gt;Column 0&lt;/h4&gt;

&lt;p&gt;The equation for column 0 reads
$$ a_0 = q&lt;em&gt;0 r&lt;/em&gt;{00} $$
and we require that $\lVert q&lt;em&gt;0 \rVert = 1$, thus
$$ r&lt;/em&gt;{00} = \lVert a_0 \rVert $$
and
$$ q_0 = a&lt;em&gt;0 / r&lt;/em&gt;{00} . $$&lt;/p&gt;

&lt;h4 id=&#34;column-1&#34;&gt;Column 1&lt;/h4&gt;

&lt;p&gt;This equation reads
$$ a_1 = q&lt;em&gt;0 r&lt;/em&gt;{01} + q&lt;em&gt;1 r&lt;/em&gt;{11} $$
where $a_1$ and $q_0$ are known and we will require that $q_0^T q_1 = 0$.
We can find the part of $a_1$ that is orthogonal to $q_0$ via
$$ (I - q_0 q_0^T) a_1 = a_1 - q_0 \underbrace{q_0^T a&lt;em&gt;1}&lt;/em&gt;{r_{01}} $$
leaving a sub-problem equivalent to that of column 0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_naive(A):
    &amp;quot;&amp;quot;&amp;quot;Compute a QR factorization of A using the Gram-Schmidt algorithm&amp;quot;&amp;quot;&amp;quot;
    Q = np.zeros_like(A)
    R = np.zeros((A.shape[1], A.shape[1]))
    for i in range(len(Q.T)):
        v = A[:,i].copy()
        for j in range(i):
            r = Q[:,j] @ v
            R[j,i] = r
            v -= Q[:,j] * r # &amp;quot;modified Gram-Schmidt&amp;quot;
        R[i,i] = np.linalg.norm(v)
        Q[:,i] = v / R[i,i]
    return Q, R

x = np.linspace(-1, 1)
A = np.vander(x, 4, increasing=True)
Q, R = gram_schmidt_naive(A)
print(Q.T @ Q)
print(np.linalg.norm(Q @ R - A))
plt.plot(x, Q);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[[ 1.00000000e+00  2.06727448e-17 -7.22457952e-17 -2.05232865e-16]
 [ 2.06727448e-17  1.00000000e+00  1.13635722e-16 -5.08904737e-16]
 [-7.22457952e-17  1.13635722e-16  1.00000000e+00  4.66276733e-17]
 [-2.05232865e-16 -5.08904737e-16  4.66276733e-17  1.00000000e+00]]
4.744563050812836e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_3_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;theorem-all-full-rank-m-times-n-matrices-m-ge-n-have-a-unique-q-r-factorization-with-r-j-j-0&#34;&gt;Theorem: all full-rank $m\times n$ matrices ($m \ge n$) have a unique $Q R$ factorization with $R_{j,j} &amp;gt; 0$.&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m = 20
V = np.vander(np.linspace(-1,1,m), increasing=True)
Q, R = gram_schmidt_naive(V)

def qr_test(qr, V):
    Q, R = qr(V)
    m = len(Q.T)
    print(&#39;{:20} {:.2e} {:.2e}&#39;.format(
        qr.__name__,
        np.linalg.norm(Q @ R - V),
        np.linalg.norm(Q.T @ Q - np.eye(m))))
    
qr_test(gram_schmidt_naive, V)
qr_test(np.linalg.qr, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_naive   9.52e-16 3.04e-09
qr                   2.74e-15 2.39e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;left-looking-algorithms-reducing-the-number-of-inner-products&#34;&gt;Left-looking algorithms: reducing the number of inner products&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_classical(A):
    Q = np.zeros_like(A)
    R = np.zeros((len(A.T),len(A.T)))
    for i in range(len(Q.T)):
        v = A[:,i].copy()
        R[:i,i] = Q[:,:i].T @ v
        v -= Q[:,:i] @ R[:i,i]
        R[i,i] = np.linalg.norm(v)
        Q[:,i] = v / R[i,i]
    return Q, R

qr_test(gram_schmidt_classical, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_classical 9.14e-16 1.42e+00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Classical Gram-Schmidt is highly parallel, but unstable, as evidenced by the lack of orthogonality in $Q$.&lt;/p&gt;

&lt;h3 id=&#34;right-looking-algorithms&#34;&gt;Right-looking algorithms&lt;/h3&gt;

&lt;p&gt;The implementations above have been &amp;ldquo;left-looking&amp;rdquo;; when working on column $i$, we compare it only to columns to the left (i.e., $j &amp;lt; i$).  We can reorder the algorithm to look to the right by projecting $q_i$ out of all columns $j &amp;gt; i$.  This algorithm is stable while being just as parallel as &lt;code&gt;gram_schmidt_classical&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_modified(A):
    Q = A.copy()
    R = np.zeros((len(A.T), len(A.T)))
    for i in range(len(Q.T)):
        R[i,i] = np.linalg.norm(Q[:,i])
        Q[:,i] /= R[i,i]
        R[i,i+1:] = Q[:,i].T @ Q[:,i+1:]
        Q[:,i+1:] -= np.outer(Q[:,i], R[i,i+1:])
    return Q, R

qr_test(gram_schmidt_modified, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_modified 8.32e-16 1.32e-08
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;stability&#34;&gt;Stability&lt;/h3&gt;

&lt;p&gt;Since QR factorization is unique (with positive diagonal of $R$), if we were to work in exact arithmetic, classical and modified Gram-Schmidt would produce the same result.  Note that modified Gram-Schmidt sequentially applies the projections into the orthogonal complement of each column $q_j$ of $Q$.  That is, given a vector $x$, we sequentially project $(I - q_j q_j^T) x$ for each column $j &amp;lt; i$.  This is equivalent to projecting all those columns at once due to
\begin{align}
  (I - q_1 q_1^T) (I - q_0 q_0^T) x &amp;amp;= \big(I - q_0 q_0^T - q_1 q_1^T + q_1 \underbrace{q_1^T q&lt;em&gt;0}&lt;/em&gt;{=0} q_0^T \big) x &lt;br /&gt;
  &amp;amp;= (I - q_0 q_0^T - q_1 q_1^T) x &lt;br /&gt;
  &amp;amp;= (I - Q Q^T) x
\end{align}
where $Q = [q_0 | q_1 ]$.  This identity can be applied recursively to convert modified Gram-Schmidt to classical, but the identity is not exact in finite precision arithmetic.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;v = V[:,-1]
print(&#39;norm(v)&#39;, np.linalg.norm(v))
print(&#39;r&#39;, R[-1,-1])
plt.semilogy(np.abs(Q.T @ v), &#39;o&#39;)
plt.title(&#39;Inner products of v with Q&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;norm(v) 1.4245900685395503
r 1.7146698318004178e-07
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_11_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def test_sum(n):
    def gen(first, n, factor=2/3):
        l = [first]
        ifactor = 1-factor
        for i in range(n):
            l.append(-first * factor * ifactor**i)
        return l, first * ifactor**n
    def sum_seq(numbers):
        s = 0
        for a in numbers:
            s += a
        return s
    def sum_block(numbers):
        s = 0
        for a in numbers[1:]:
            s += a
        return numbers[0] + s
    numbers, exact = gen(1, n)
    print(numbers)
    plt.semilogy(np.abs(numbers), &#39;o&#39;)
    seq_err = sum_seq(numbers) - exact
    block_err = sum_block(numbers) - exact
    numpy_err = np.sum(numbers) - exact
    print(&#39;seq   abs {:.4e}  rel {:.4e}&#39;.format(seq_err, seq_err/exact))
    print(&#39;block abs {:.4e}  rel {:.4e}&#39;.format(block_err, block_err/exact))
    print(&#39;numpy abs {:.4e}  rel {:.4e}&#39;.format(numpy_err, numpy_err/exact))
    
test_sum(20)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[1, -0.6666666666666666, -0.22222222222222224, -0.07407407407407408, -0.024691358024691364, -0.008230452674897124, -0.0027434842249657075, -0.0009144947416552361, -0.0003048315805517454, -0.00010161052685058181, -3.3870175616860605e-05, -1.1290058538953536e-05, -3.763352846317846e-06, -1.2544509487726156e-06, -4.181503162575385e-07, -1.3938343875251286e-07, -4.6461146250837626e-08, -1.548704875027921e-08, -5.162349583426404e-09, -1.7207831944754682e-09, -5.735943981584894e-10]
seq   abs 5.9562e-22  rel 2.0768e-12
block abs 5.3534e-17  rel 1.8666e-07
numpy abs 7.4670e-17  rel 2.6036e-07
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_12_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;householder-triangularization&#34;&gt;Householder triangularization&lt;/h3&gt;

&lt;p&gt;Gram-Schmidt methods perform triangular transformations to build an orthogonal matrix.  As we have seen, $X = QR$ is satisfied accurately, but $Q$ may not be orthogonal when $X$ is ill-conditioned.  Householder triangularization instead applies a sequence of orthogonal transformations to build a triangular matrix.&lt;/p&gt;

&lt;p&gt;$$ \underbrace{Q_{n-1} \dotsb Q&lt;em&gt;0}&lt;/em&gt;{Q^T} A = R $$&lt;/p&gt;

&lt;p&gt;The structure of the algorithm is&lt;/p&gt;

&lt;p&gt;$$ \underbrace{\begin{bmatrix} * &amp;amp; * &amp;amp; * \ * &amp;amp; * &amp;amp; * \ * &amp;amp; * &amp;amp; * \ * &amp;amp; * &amp;amp; * \ * &amp;amp; * &amp;amp; * \ \end{bmatrix}}&lt;em&gt;{A} \to
\underbrace{\begin{bmatrix} * &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ \end{bmatrix}}&lt;/em&gt;{Q&lt;em&gt;0 A} \to
\underbrace{\begin{bmatrix} * &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ 0 &amp;amp; 0 &amp;amp; * \ 0 &amp;amp; 0 &amp;amp; * \ 0 &amp;amp; 0 &amp;amp; * \ \end{bmatrix}}&lt;/em&gt;{Q_1 Q&lt;em&gt;0 A} \to
\underbrace{\begin{bmatrix} * &amp;amp; * &amp;amp; * \ 0 &amp;amp; * &amp;amp; * \ 0 &amp;amp; 0 &amp;amp; * \ 0 &amp;amp; 0 &amp;amp; 0 \ 0 &amp;amp; 0 &amp;amp; 0 \ \end{bmatrix}}&lt;/em&gt;{Q_2 Q_1 Q_0 A}
$$&lt;/p&gt;

&lt;p&gt;where the elementary orthogonal matrices $Q_i$ chosen to introduce zeros below the diagonal in the $i$th column of $R$.
Each of these transformations will have the form
$$Q_i = \begin{bmatrix} I_i &amp;amp; 0 \ 0 &amp;amp; F \end{bmatrix}$$
where $F$ is a &amp;ldquo;reflection&amp;rdquo; that achieves
$$ F x = \begin{bmatrix} \lVert x \rVert \ 0 \ 0 \ \vdots \end{bmatrix} $$
where $x$ is the column of $R$ from the diagonal down.
This transformation is a reflection across a plane with normal $v = Fx - x = \lVert x \rVert e_1 - x$.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;TB-Householder.png&#34; alt=&#34;Householder Reflector (Trefethen and Bau, 1999)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The reflection, as depected above by Trefethen and Bau (1999) can be written $F = I - 2 \frac{v v^T}{v^T v}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = np.random.rand(4, 4)
A = A + A.T # Random symmetric matrix
A
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[1.71984228, 0.68338128, 1.12543662, 0.59188991],
       [0.68338128, 1.5609485 , 1.03109546, 1.4707089 ],
       [1.12543662, 1.03109546, 0.02375504, 0.71686222],
       [0.59188991, 1.4707089 , 0.71686222, 0.88113581]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A.T - A
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.],
       [0., 0., 0., 0.]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;from scipy.linalg import block_diag
np.set_printoptions(precision=4)

def reflector(v):
    return np.eye(len(v)) - 2*np.outer(v, v)

v = A[1:,0].copy()
v[0] -= np.linalg.norm(v)
v = v / np.linalg.norm(v)
F = reflector(v)
Q_0 = block_diag(np.eye(1), F)
Q_0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 1.    ,  0.    ,  0.    ,  0.    ],
       [ 0.    ,  0.4734,  0.7796,  0.41  ],
       [ 0.    ,  0.7796, -0.1542, -0.607 ],
       [ 0.    ,  0.41  , -0.607 ,  0.6808]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;Q_0 @ A
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 1.7198e+00,  6.8338e-01,  1.1254e+00,  5.9189e-01],
       [ 1.4436e+00,  2.1458e+00,  8.0055e-01,  1.6164e+00],
       [-6.8853e-17,  1.6526e-01,  3.6506e-01,  5.0122e-01],
       [-2.8229e-17,  1.0154e+00,  8.9636e-01,  7.6773e-01]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A @ Q_0
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;array([[ 1.7198e+00,  1.4436e+00, -6.8853e-17, -2.8229e-17],
       [ 6.8338e-01,  2.1458e+00,  1.6526e-01,  1.0154e+00],
       [ 1.1254e+00,  8.0055e-01,  3.6506e-01,  8.9636e-01],
       [ 5.9189e-01,  1.6164e+00,  5.0122e-01,  7.6773e-01]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def householder_Q_times(V, x):
    &amp;quot;&amp;quot;&amp;quot;Apply orthogonal matrix represented as list of Householder reflectors&amp;quot;&amp;quot;&amp;quot;
    y = x.copy()
    for i in reversed(range(len(V))):
        y[i:] -= 2 * V[i] * V[i].dot(y[i:])
    return y

def qr_householder1(A):
    &amp;quot;Compute QR factorization using naive Householder reflection&amp;quot;
    m, n = A.shape
    R = A.copy()
    V = []
    for i in range(n):
        x = R[i:,i]
        v = -x
        v[0] += np.linalg.norm(x)
        v = v/np.linalg.norm(v)     # Normalized reflector plane
        R[i:,i:] -= 2 * np.outer(v, v @ R[i:,i:])
        V.append(v)                    # Storing reflectors is equivalent to storing orthogonal matrix
    Q = np.eye(m, n)
    for i in range(n):
        Q[:,i] = householder_Q_times(V, Q[:,i])
    return Q, np.triu(R[:n,:])

qr_test(qr_householder1, np.array([[1.,2],[3,4],[5,6]]))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder1      1.88e-15 3.17e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;qr_test(qr_householder1, V)
qr_test(np.linalg.qr, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder1      3.15e-15 3.48e-15
qr                   2.74e-15 2.39e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;choice-of-two-projections&#34;&gt;Choice of two projections&lt;/h3&gt;

&lt;p&gt;It turns out our implementation has a nasty deficiency.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;qr_test(qr_householder1, np.eye(1))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder1      nan nan


/usr/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;qr_test(qr_householder1, np.eye(3,2))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder1      nan nan


/usr/lib/python3.7/site-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Inside &lt;code&gt;qr_householder1&lt;/code&gt;, we have the lines&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;        x = R[i:,i]
        v = -x
        v[0] += numpy.linalg.norm(x)
        v = v/numpy.linalg.norm(v)     # Normalized reflector plane
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What happens when $$x = \begin{bmatrix}1 \ 0 \end{bmatrix}$$
(i.e., the column of $R$ is already upper triangular)?&lt;/p&gt;

&lt;p&gt;We are trying to define a reflector plane (via its normal vector) from the zero vector,
$$v = \lVert x \rVert e_0 - x .$$
When we try to normalize this vector, we divide zero by zero and the algorithm breaks down (&lt;code&gt;nan&lt;/code&gt;).  Maybe we just need to test for this special case and &amp;ldquo;skip ahead&amp;rdquo; when no reflection is needed?  And if so, how would we define $Q$?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;qr_test(qr_householder1, np.array([[1.,1], [2e-8,1]]))
print(qr_householder1(np.array([[1.,1], [2e-8,1]])))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder1      2.20e-09 4.44e-16
(array([[ 1.0000e+00, -2.2204e-08],
       [ 2.2204e-08,  1.0000e+00]]), array([[1., 1.],
       [0., 1.]]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The error $QR - A$ is still $10^{-8}$ for this very well-conditioned matrix so something else must be at play here.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;TB-Householder2.png&#34; alt=&#34;Choosing the better of two Householder reflectors (Trefethen and Bau, 1999).&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def qr_householder2(A):
    &amp;quot;Compute QR factorization using Householder reflection&amp;quot;
    m, n = A.shape
    R = A.copy()
    V = []
    for i in range(n):
        v = R[i:,i].copy()
        v[0] += np.sign(v[0]) * np.linalg.norm(v) # Choose the further of the two reflections
        v = v/np.linalg.norm(v)     # Normalized reflector plane
        R[i:,i:] -= np.outer(v, 2 * (v.T @ R[i:,i:]))
        V.append(v)                    # Storing reflectors is equivalent to storing orthogonal matrix
    Q = np.eye(m, n)
    for i in range(n):
        Q[:,i] = householder_Q_times(V, Q[:,i])
    return Q, np.triu(R[:n,:])

qr_test(qr_householder2, np.eye(3,2))
qr_test(qr_householder2, np.array([[1.,1], [1e-8,1]]))
for mat in qr_householder2(np.array([[1.,1], [1e-8,1]])):
    print(mat)

qr_test(qr_householder2, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;qr_householder2      0.00e+00 0.00e+00
qr_householder2      0.00e+00 0.00e+00
[[-1.e+00  1.e-08]
 [-1.e-08 -1.e+00]]
[[-1. -1.]
 [ 0. -1.]]
qr_householder2      5.20e-15 3.58e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We now have a usable implementation of Householder QR.  There are some further concerns for factoring rank-deficient matrices.  We will visit the concept of pivoting later, in the context of LU and Cholesky factorization.&lt;/p&gt;

&lt;h2 id=&#34;conditioning&#34;&gt;Conditioning&lt;/h2&gt;

&lt;h3 id=&#34;absolute-condition-number&#34;&gt;Absolute condition number&lt;/h3&gt;

&lt;p&gt;Consider a function $f: X \to Y$ and define the &lt;em&gt;absolute condition number&lt;/em&gt;
$$ \hat\kappa = \lim&lt;em&gt;{\delta \to 0} \max&lt;/em&gt;{|\delta x| &amp;lt; \delta} \frac{|f(x + \delta x) - f(x)|}{|\delta x|} = \max_{\delta x} \frac{|\delta f|}{|\delta x|}. $$
If $f$ is differentiable, then $\hat\kappa = |f&amp;rsquo;(x)|$.&lt;/p&gt;

&lt;h3 id=&#34;floating-point-arithmetic&#34;&gt;Floating point arithmetic&lt;/h3&gt;

&lt;p&gt;Floating point arithmetic $x \circledast y := \text{float}(x * y)$ is exact within a relative accuracy $\epsilon&lt;em&gt;{\text{machine}}$.  Formally,
$$ x \circledast y = (x * y) (1 + \epsilon) $$
for some $|\epsilon| \le \epsilon&lt;/em&gt;{\text{machine}}$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;eps = 1
while 1 + eps &amp;gt; 1:
    eps /= 2
eps_machine = eps
print(&#39;Machine epsilon = {}&#39;.format(eps_machine))
(1 + 1.12e-16) - 1
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Machine epsilon = 1.1102230246251565e-16





2.220446049250313e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plot_neighborhood(f, x0, atol=1e-10, rtol=1e-10):
    width = atol + rtol * np.abs(x0)
    x = np.linspace(x0 - width, x0 + width, 201)
    plt.plot(x, f(x))
    plt.xlabel(&#39;x&#39;)
    plt.ylabel(&#39;f(x)&#39;)

plot_neighborhood(lambda x: (x + 1) - 1, 0, 1e-15)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_30_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This function $f(x) = (x + 1) - 1 = x$ is well conditioned for all $x$, but this numerical algorithm is unstable (we&amp;rsquo;ll discuss this below).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plot_neighborhood(np.log, 1, .5)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_32_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;The function $f(x) = \log x$ has $f&amp;rsquo;(1) = 1$.  The conditioning is good in an absolute sense, $\hat \kappa = 1$.  However, the outputs from &lt;code&gt;np.log(1+x)&lt;/code&gt; have large relative error relative to the exact value, provided here by the function &lt;code&gt;np.log1p(x)&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plot_neighborhood(lambda x: np.log(1+x), 0, atol=1e-15)
plot_neighborhood(np.log1p, 0, atol=1e-15)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_34_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;relative-condition-number&#34;&gt;Relative condition number&lt;/h3&gt;

&lt;p&gt;Given the relative nature of floating point arithmetic, it is more useful to discuss &lt;strong&gt;relative condition number&lt;/strong&gt;,
$$ \kappa = \max&lt;em&gt;{\delta x} \frac{|\delta f|/|f|}{|\delta x|/|x|}
= \max&lt;/em&gt;{\delta x} \Big[ \frac{|\delta f|/|\delta x|}{|f| / |x|} \Big] $$
or, if $f$ is differentiable,
$$ \kappa = |f&amp;rsquo;(x)| \frac{|x|}{|f|} . $$&lt;/p&gt;

&lt;p&gt;How does a condition number get big?&lt;/p&gt;

&lt;h4 id=&#34;take-home-message&#34;&gt;Take-home message&lt;/h4&gt;

&lt;p&gt;The relative accuracy of the best-case algorithm will not be reliably better than $\epsilon&lt;em&gt;{\text{machine}}$ times the condition number.
$$ \max&lt;/em&gt;{\delta x} \frac{|\delta f|}{|f|} \ge \kappa \cdot \epsilon_{\text{machine}} .$$&lt;/p&gt;

&lt;h2 id=&#34;stability-1&#34;&gt;Stability&lt;/h2&gt;

&lt;p&gt;We use the notation $\tilde f(x)$ to mean a numerical algorithm for approximating $f(x)$.  Additionally, $\tilde x = x (1 + \epsilon)$ is some &amp;ldquo;good&amp;rdquo; approximation of the exact input $x$.&lt;/p&gt;

&lt;h3 id=&#34;forward-stability&#34;&gt;(Forward) Stability&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&amp;ldquo;nearly the right answer to nearly the right question&amp;rdquo;&lt;/strong&gt;
$$ \frac{\lvert \tilde f(x) - f(\tilde x) \rvert}{| f(\tilde x) |} \in O(\epsilon_{\text{machine}}) $$
for some $\tilde x$ that is close to $x$&lt;/p&gt;

&lt;h3 id=&#34;backward-stability&#34;&gt;Backward Stability&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;&amp;ldquo;exactly the right answer to nearly the right question&amp;rdquo;&lt;/strong&gt;
$$ \tilde f(x) = f(\tilde x) $$
for some $\tilde x$ that is close to $x$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Every backward stable algorithm is stable.&lt;/li&gt;
&lt;li&gt;Not every stable algorithm is backward stable.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;accuracy-of-backward-stable-algorithms-theorem&#34;&gt;Accuracy of backward stable algorithms (Theorem)&lt;/h3&gt;

&lt;p&gt;A backward stable algorithm for computing $f(x)$ has relative accuracy
$$ \left\lvert \frac{\tilde f(x) - f(x)}{f(x)} \right\rvert \in O(\kappa(f) \epsilon_{\text{machine}}) . $$
This is a rewording of a statement made earlier &amp;ndash; backward stability is the best case.&lt;/p&gt;

&lt;h3 id=&#34;condition-number-of-a-matrix&#34;&gt;Condition number of a matrix&lt;/h3&gt;

&lt;p&gt;We may have informally referred to a matrix as &amp;ldquo;ill-conditioned&amp;rdquo; when the columns are nearly linearly dependent, but let&amp;rsquo;s make this concept for precise.  Recall the definition of (relative) condition number from the Rootfinding notes,&lt;/p&gt;

&lt;p&gt;$$ \kappa = \max_{\delta x} \frac{|\delta f|/|f|}{|\delta x|/|x|} . $$&lt;/p&gt;

&lt;p&gt;We understood this definition for scalar problems, but it also makes sense when the inputs and/or outputs are vectors (or matrices, etc.) and absolute value is replaced by vector (or matrix) norms.  Let&amp;rsquo;s consider the case of matrix-vector multiplication, for which $f(x) = A x$.&lt;/p&gt;

&lt;p&gt;$$ \kappa(A) = \max&lt;em&gt;{\delta x} \frac{\lVert A (x+\delta x) - A x \rVert/\lVert A x \rVert}{\lVert \delta x\rVert/\lVert x \rVert}
= \max&lt;/em&gt;{\delta x} \frac{\lVert A \delta x \rVert}{\lVert \delta x \rVert} \, \frac{\lVert x \rVert}{\lVert A x \rVert} = \lVert A \rVert \frac{\lVert x \rVert}{\lVert A x \rVert} . $$&lt;/p&gt;

&lt;p&gt;There are two problems here:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;I wrote $\kappa(A)$ but my formula depends on $x$.&lt;/li&gt;
&lt;li&gt;What is that $\lVert A \rVert$ beastie?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;stack-push-matrix-norms&#34;&gt;Stack push: Matrix norms&lt;/h3&gt;

&lt;p&gt;Vector norms are built into the linear space (and defined in term of the inner product).  Matrix norms are &lt;em&gt;induced&lt;/em&gt; by vector norms, according to&lt;/p&gt;

&lt;p&gt;$$ \lVert A \rVert = \max_{x \ne 0} \frac{\lVert A x \rVert}{\lVert x \rVert} . $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;This equation makes sense for non-square matrices &amp;ndash; the vector norms of the input and output spaces may differ.&lt;/li&gt;
&lt;li&gt;Due to linearity, all that matters is direction of $x$, so it could equivalently be written&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;$$ \lVert A \rVert = \max_{\lVert x \rVert = 1} \lVert A x \rVert . $$&lt;/p&gt;

&lt;h3 id=&#34;stack-pop&#34;&gt;Stack pop&lt;/h3&gt;

&lt;p&gt;Now we understand the formula for condition number, but it depends on $x$.  Consider the matrix&lt;/p&gt;

&lt;p&gt;$$ A = \begin{bmatrix} 1 &amp;amp; 0 \ 0 &amp;amp; 0 \end{bmatrix} . $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;What is the norm of this matrix?&lt;/li&gt;
&lt;li&gt;What is the condition number when $x = [1,0]^T$?&lt;/li&gt;
&lt;li&gt;What is the condition number when $x = [0,1]^T$?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;The condition number of matrix-vector multiplication depends on the vector.  The condition number of the matrix is the worst case (maximum) of the condition number for any vector, i.e.,&lt;/p&gt;

&lt;p&gt;$$ \kappa(A) = \max_{x \ne 0} \lVert A \rVert \frac{\lVert x \rVert}{\lVert A x \rVert} .$$&lt;/p&gt;

&lt;p&gt;If $A$ is invertible, then we can rephrase as&lt;/p&gt;

&lt;p&gt;$$ \kappa(A) = \max&lt;em&gt;{x \ne 0} \lVert A \rVert \frac{\lVert A^{-1} (A x) \rVert}{\lVert A x \rVert} =
\max&lt;/em&gt;{A x \ne 0} \lVert A \rVert \frac{\lVert A^{-1} (A x) \rVert}{\lVert A x \rVert} = \lVert A \rVert \lVert A^{-1} \rVert . $$&lt;/p&gt;

&lt;p&gt;Evidently multiplying by a matrix is just as ill-conditioned of an operation as solving a linear system using that matrix.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def R_solve(R, b):
    &amp;quot;&amp;quot;&amp;quot;Solve Rx = b using back substitution.&amp;quot;&amp;quot;&amp;quot;
    x = b.copy()
    m = len(b)
    for i in reversed(range(m)):
        x[i] -= R[i,i+1:].dot(x[i+1:])
        x[i] /= R[i,i]
    return x

Q, R = np.linalg.qr(A)
x = np.array([1,2,3,4])
bfull = A @ x
breduced = Q.T @ bfull
print(np.linalg.norm(R_solve(R, breduced)
                     - np.linalg.solve(R, breduced)))
R_solve(R, breduced)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;4.440892098500626e-16





array([1., 2., 3., 4.])
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;cost-of-householder-factorization&#34;&gt;Cost of Householder factorization&lt;/h3&gt;

&lt;p&gt;The dominant cost comes from the line&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;    R[i:,i:] -= 2 * numpy.outer(v, v.dot(R[i:,i:]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;were &lt;code&gt;R[i:,i:]&lt;/code&gt; is an $(m-i)\times(n-i)$ matrix.
This line performs $2(m-i)(n-i)$ operations in &lt;code&gt;v.dot(R[i:,i:])&lt;/code&gt;, another $(m-i)(n-i)$ in the &amp;ldquo;outer&amp;rdquo; product and again in subtraction.  As written, multiplication by 2 would be another $(m-i)(n-i)$ operations, but is only $m-i$ operations if we rewrite as&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-Python&#34;&gt;    w = 2*v
    R[i:,i:] -= numpy.outer(w, v.dot(R[i:,i:]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;in which case the leading order cost is $4(m-i)(n-i)$.  To compute the total cost, we need to sum over all columns $i$,
$$\begin{split} \sum&lt;em&gt;{i=1}^n 4(m-i)(n-i) &amp;amp;= 4 \Big[ \sum&lt;/em&gt;{i=1}^n (m-n)(n-i) + \sum&lt;em&gt;{i=1}^n (n-i)^2 \Big] &lt;br /&gt;
&amp;amp;= 4 (m-n) \sum&lt;/em&gt;{i=1}^n i + 4 \sum_{i=1}^n i^2 &lt;br /&gt;
&amp;amp;\approx 2 (m-n) n^2 + 4 n^&lt;sup&gt;3&lt;/sup&gt;&amp;frasl;&lt;sub&gt;3&lt;/sub&gt; &lt;br /&gt;
&amp;amp;= 2 m n^2 - \frac 2 3 n^3 .
\end{split}$$
Recall that Gram-Schmidt QR cost $2 m n^2$, so Householder costs about the same when $m \gg n$ and is markedly less expensive when $m \approx n$.&lt;/p&gt;

&lt;h3 id=&#34;backward-stability-of-housholder&#34;&gt;Backward Stability of Housholder&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def qr_test_backward(qr, n):
    from numpy.linalg import norm
    from numpy.random import randn
    R = np.triu(randn(n,n))
    Q, _ = np.linalg.qr(randn(n,n))
    A = Q @ R
    Q2, R2 = qr(A)
    print(&#39;# Forward error&#39;)
    print(&#39;Q error&#39;, norm(Q2 - Q))
    print(&#39;R error&#39;, norm(R2 - R) / norm(R))
    print(&#39;# Backward error&#39;)
    A2 = Q2 @ R2
    print(&#39;Q2.T @ Q2 - I&#39;, norm(Q2.T @ Q2 - np.eye(n)))
    print(&#39;Q2*R2 - A&#39;, norm(A2 - A) / norm(A))
    Q3, R3 = Q + 1e-5*randn(n,n), R + 1e-5*np.triu(randn(n,n))
    A3 = Q3 @ R3
    print(&#39;Q3*R3 - A&#39;, norm(A3 - A) / norm(A))

qr_test_backward(gram_schmidt_modified, 50)
#qr_test_backward(np.linalg.qr, 50)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;# Forward error
Q error 9.380829776561018
R error 1.3114908995362393
# Backward error
Q2.T @ Q2 - I 0.008203364853000912
Q2*R2 - A 2.797766695296299e-16
Q3*R3 - A 7.070141269858638e-05
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;back-to-parallelism-cholesky-qr-one-reduction&#34;&gt;Back to parallelism: Cholesky QR (one reduction)&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def chol_qr(A):
    import scipy.linalg as la
    B = A.T @ A
    R = la.cholesky(B)
    Q = A @ la.inv(R)
    return Q, R
    
qr_test(chol_qr, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chol_qr              8.12e-15 1.07e-01
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def chol_qr2(A):
    import scipy.linalg as la
    B = A.T @ A
    R = la.cholesky(B)
    Q = A @ la.inv(R)
    R2 = la.cholesky(Q.T @ Q)
    Q = Q @ la.inv(R2)
    R = R2 @ R
    return Q, R

qr_test(chol_qr2, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chol_qr2             8.36e-15 1.29e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;tsqr-tall-skinny-qr&#34;&gt;TSQR: Tall-Skinny QR&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;ballard-tsqr.png&#34; alt=&#34;&#34; /&gt;
Figure from &lt;a href=&#34;https://www.sandia.gov/~gmballa/talks/SIAMPP14.pdf&#34; target=&#34;_blank&#34;&gt;Ballard et al&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Dense Linear Algebra and Orthogonality</title>
      <link>https://cucs-hpsc.github.io/fall2019/dense-linalg-2/</link>
      <pubDate>Wed, 02 Oct 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/dense-linalg-2/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#pragma omp parallel
    {
      for (size_t rep=0; rep&amp;lt;args.repetitions; rep++) {
#pragma omp for
        for (size_t i=0; i&amp;lt;args.array_len; i++)
          y[i] += 3.14 * x[i];
      }
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;    for (size_t rep=0; rep&amp;lt;args.repetitions; rep++) {
#pragma omp parallel for
      for (size_t i=0; i&amp;lt;args.array_len; i++)
        y[i] += 3.14 * x[i];
    }
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! make CFLAGS=&#39;-O3 -march=native -fopenmp -Wall&#39; -B omp-test
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -O3 -march=native -fopenmp -Wall    omp-test.c   -o omp-test
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! ./omp-test -r 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;omp for         : 0.770512 ticks per entry
omp parallel for: 1.576261 ticks per entry
omp for         : 0.419312 ticks per entry
omp parallel for: 1.475976 ticks per entry
omp for         : 0.426896 ticks per entry
omp parallel for: 1.021856 ticks per entry
omp for         : 0.494572 ticks per entry
omp parallel for: 1.270378 ticks per entry
omp for         : 0.444213 ticks per entry
omp parallel for: 1.009316 ticks per entry
omp for         : 0.579121 ticks per entry
omp parallel for: 1.024148 ticks per entry
omp for         : 0.531494 ticks per entry
omp parallel for: 1.174585 ticks per entry
omp for         : 0.442223 ticks per entry
omp parallel for: 1.147614 ticks per entry
omp for         : 0.446249 ticks per entry
omp parallel for: 1.084162 ticks per entry
omp for         : 0.576802 ticks per entry
omp parallel for: 1.325817 ticks per entry
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;matrix-matrix-multiply&#34;&gt;Matrix-matrix multiply&lt;/h2&gt;

&lt;h3 id=&#34;start-local&#34;&gt;Start local&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;blis-gemm-kernels.png&#34; alt=&#34;BLIS GEMM kernels&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;blis-cache.png&#34; alt=&#34;BLIS cache levels&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;further-reading&#34;&gt;Further reading&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.utexas.edu/users/flame/pubs/blis2_toms_rev3.pdf&#34; target=&#34;_blank&#34;&gt;http://www.cs.utexas.edu/users/flame/pubs/blis2_toms_rev3.pdf&lt;/a&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;a href=&#34;http://www.cs.utexas.edu/users/flame/pubs/blis3_ipdps14.pdf&#34; target=&#34;_blank&#34;&gt;http://www.cs.utexas.edu/users/flame/pubs/blis3_ipdps14.pdf&lt;/a&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;orthogonalization-and-qr-factorization&#34;&gt;Orthogonalization and QR factorization&lt;/h2&gt;

&lt;p&gt;Given a collection of vectors (columns of a matrix), we can find an orthogonal basis by applying the above procedure one column at a time and saving the result.  Let&amp;rsquo;s think of the first two columns,
$$ \Bigg[ a_0 \, \Bigg| \, a_1 \Bigg] = \Bigg[ q_0 \,\Bigg|\, q&lt;em&gt;1 \Bigg]
\begin{bmatrix} r&lt;/em&gt;{00} &amp;amp; r&lt;em&gt;{01} \ 0 &amp;amp; r&lt;/em&gt;{11} \end{bmatrix} . $$&lt;/p&gt;

&lt;h4 id=&#34;column-0&#34;&gt;Column 0&lt;/h4&gt;

&lt;p&gt;The equation for column 0 reads
$$ a_0 = q&lt;em&gt;0 r&lt;/em&gt;{00} $$
and we require that $\lVert q&lt;em&gt;0 \rVert = 1$, thus
$$ r&lt;/em&gt;{00} = \lVert a_0 \rVert $$
and
$$ q_0 = a&lt;em&gt;0 / r&lt;/em&gt;{00} . $$&lt;/p&gt;

&lt;h4 id=&#34;column-1&#34;&gt;Column 1&lt;/h4&gt;

&lt;p&gt;This equation reads
$$ a_1 = q&lt;em&gt;0 r&lt;/em&gt;{01} + q&lt;em&gt;1 r&lt;/em&gt;{11} $$
where $a_1$ and $q_0$ are known and we will require that $q_0^T q_1 = 0$.
We can find the part of $a_1$ that is orthogonal to $q_0$ via
$$ (I - q_0 q_0^T) a_1 = a_1 - q_0 \underbrace{q_0^T a&lt;em&gt;1}&lt;/em&gt;{r_{01}} $$
leaving a sub-problem equivalent to that of column 0.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_naive(A):
    &amp;quot;&amp;quot;&amp;quot;Compute a QR factorization of A using the Gram-Schmidt algorithm&amp;quot;&amp;quot;&amp;quot;
    Q = np.zeros_like(A)
    R = np.zeros((A.shape[1], A.shape[1]))
    for i in range(len(Q.T)):
        v = A[:,i].copy()
        for j in range(i):
            r = Q[:,j] @ v
            R[j,i] = r
            v -= Q[:,j] * r # &amp;quot;modified Gram-Schmidt&amp;quot;
        R[i,i] = np.linalg.norm(v)
        Q[:,i] = v / R[i,i]
    return Q, R

x = np.linspace(-1, 1)
A = np.vander(x, 4, increasing=True)
Q, R = gram_schmidt_naive(A)
print(Q.T @ Q)
print(np.linalg.norm(Q @ R - A))
plt.plot(x, Q);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[[ 1.00000000e+00  2.06727448e-17 -7.22457952e-17 -2.05232865e-16]
 [ 2.06727448e-17  1.00000000e+00  1.13635722e-16 -5.08904737e-16]
 [-7.22457952e-17  1.13635722e-16  1.00000000e+00  4.66276733e-17]
 [-2.05232865e-16 -5.08904737e-16  4.66276733e-17  1.00000000e+00]]
4.744563050812836e-16
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_9_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;theorem-all-full-rank-m-times-n-matrices-m-ge-n-have-a-unique-q-r-factorization-with-r-j-j-0&#34;&gt;Theorem: all full-rank $m\times n$ matrices ($m \ge n$) have a unique $Q R$ factorization with $R_{j,j} &amp;gt; 0$.&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;m = 20
V = np.vander(np.linspace(-1,1,m), increasing=True)
Q, R = gram_schmidt_naive(V)

def qr_test(qr, V):
    Q, R = qr(V)
    m = len(Q.T)
    print(&#39;{:20} {:.2e} {:.2e}&#39;.format(
        qr.__name__,
        np.linalg.norm(Q @ R - V),
        np.linalg.norm(Q.T @ Q - np.eye(m))))
    
qr_test(gram_schmidt_naive, V)
qr_test(np.linalg.qr, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_naive   9.52e-16 3.04e-09
qr                   2.74e-15 2.39e-15
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;left-looking-algorithms-reducing-the-number-of-inner-products&#34;&gt;Left-looking algorithms: reducing the number of inner products&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_classical(A):
    Q = np.zeros_like(A)
    R = np.zeros((len(A.T),len(A.T)))
    for i in range(len(Q.T)):
        v = A[:,i].copy()
        R[:i,i] = Q[:,:i].T @ v
        v -= Q[:,:i] @ R[:i,i]
        R[i,i] = np.linalg.norm(v)
        Q[:,i] = v / R[i,i]
    return Q, R

qr_test(gram_schmidt_classical, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_classical 9.14e-16 1.42e+00
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Classical Gram-Schmidt is highly parallel, but unstable, as evidenced by the lack of orthogonality in $Q$.&lt;/p&gt;

&lt;h3 id=&#34;right-looking-algorithms&#34;&gt;Right-looking algorithms&lt;/h3&gt;

&lt;p&gt;The implementations above have been &amp;ldquo;left-looking&amp;rdquo;; when working on column $i$, we compare it only to columns to the left (i.e., $j &amp;lt; i$).  We can reorder the algorithm to look to the right by projecting $q_i$ out of all columns $j &amp;gt; i$.  This algorithm is stable while being just as parallel as &lt;code&gt;gram_schmidt_classical&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def gram_schmidt_modified(A):
    Q = A.copy()
    R = np.zeros((len(A.T), len(A.T)))
    for i in range(len(Q.T)):
        R[i,i] = np.linalg.norm(Q[:,i])
        Q[:,i] /= R[i,i]
        R[i,i+1:] = Q[:,i].T @ Q[:,i+1:]
        Q[:,i+1:] -= np.outer(Q[:,i], R[i,i+1:])
    return Q, R

qr_test(gram_schmidt_modified, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;gram_schmidt_modified 8.32e-16 1.32e-08
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;one-reduction-cholesky-qr&#34;&gt;One reduction: Cholesky QR&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def chol_qr(A):
    import scipy.linalg as la
    B = A.T @ A
    R = la.cholesky(B)
    Q = A @ la.inv(R)
    return Q, R
    
qr_test(chol_qr, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chol_qr              8.12e-15 1.07e-01
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def chol_qr2(A):
    import scipy.linalg as la
    B = A.T @ A
    R = la.cholesky(B)
    Q = A @ la.inv(R)
    R2 = la.cholesky(Q.T @ Q)
    Q = Q @ la.inv(R2)
    R = R2 @ R
    return Q, R

qr_test(chol_qr2, V)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;chol_qr2             8.36e-15 1.29e-15
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Dense Linear Algebra and Networks</title>
      <link>https://cucs-hpsc.github.io/fall2019/dense-linalg/</link>
      <pubDate>Mon, 30 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/dense-linalg/</guid>
      <description>

&lt;h2 id=&#34;inner-products&#34;&gt;Inner products&lt;/h2&gt;

&lt;p&gt;$$ x^T y = \sum_{i=1}^N x_i y_i $$&lt;/p&gt;

&lt;h4 id=&#34;openmp&#34;&gt;OpenMP&lt;/h4&gt;

&lt;p&gt;The vectors &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; of length &lt;code&gt;N&lt;/code&gt; are stored in a contiguous array in shared memory.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double sum = 0;
#pragma omp parallel for reduction(+:sum)
for (int i=0; i&amp;lt;N; i++)
    sum += x[i] * y[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;mpi&#34;&gt;MPI&lt;/h4&gt;

&lt;p&gt;The vectors &lt;code&gt;x&lt;/code&gt; and &lt;code&gt;y&lt;/code&gt; are partitioned into $P$ parts of length $n&lt;em&gt;p$ such that
$$ N = \sum&lt;/em&gt;{p=1}^P n_p . $$
The inner product is computed via&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double sum = 0;
for (int i=0; i&amp;lt;n; i++)
    sum += x[i] * y[i];
MPI_Allreduce(MPI_IN_PLACE, &amp;amp;sum, 1, MPI_DOUBLE, MPI_SUM, comm);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Work: $2N$ flops processed rate $R$&lt;/li&gt;
&lt;li&gt;Execution time: $\frac{2N}{RP} + \text{latency}$&lt;/li&gt;

&lt;li&gt;&lt;p&gt;How big is latency?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
plt.style.use(&#39;seaborn&#39;)
import numpy as np

P = np.geomspace(2, 1e6)
N = 1e9       # length of vectors
R = 10e9/8    # (10 GB/s per core) (2 flops/16 bytes) = 10/8 GF/s per core
t1 = 2e-6     # 2 Âµs message latency

def time_compute(P):
return 2*N / (R*P)

plt.loglog(P, time_compute(P) + t1*(P-1), label=&#39;linear&#39;)
plt.loglog(P, time_compute(P) + t1*2*(np.sqrt(P)-1), label=&#39;2D mesh&#39;)
plt.loglog(P, time_compute(P) + t1*np.log2(P), label=&#39;hypercube&#39;)
plt.xlabel(&#39;P processors&#39;)
plt.ylabel(&#39;Execution time&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_1_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;FischerBGQAllReduce.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;torus-topology&#34;&gt;Torus topology&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/6/60/Torus_from_rectangle.gif&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/1/1f/3d_torus.png&#34; width=&#34;800px&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;3D torus: IBM BlueGene/L (2004) and BlueGene/P (2007)&lt;/li&gt;
&lt;li&gt;5D torus: IBM BlueGene/Q (2011)&lt;/li&gt;
&lt;li&gt;6D torus: Fujitsu K computer (2011)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;dragonfly-topology&#34;&gt;Dragonfly topology&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;CrayAriesDragonfly.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;today-s-research-reducing-contention-and-interference&#34;&gt;Today&amp;rsquo;s research: reducing contention and interference&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/cray-slingshot-congestion-control.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://3s81si1s5ygj3mzby34dq6qf-wpengine.netdna-ssl.com/wp-content/uploads/2019/08/cray-slingshot-trace-latency.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Images from &lt;a href=&#34;https://www.nextplatform.com/2019/08/16/how-cray-makes-ethernet-suited-for-hpc-and-ai-with-slingshot/&#34; target=&#34;_blank&#34;&gt;this article&lt;/a&gt;.&lt;/p&gt;

&lt;h4 id=&#34;compare-to-bg-q&#34;&gt;Compare to BG/Q&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Each job gets an electrically isolated 5D torus&lt;/li&gt;
&lt;li&gt;Excellent performance and reproducibility&lt;/li&gt;
&lt;li&gt;Awkward constraints on job size, lower system utilization.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;outer-product&#34;&gt;Outer product&lt;/h2&gt;

&lt;p&gt;$$ C_{ij} = x_i y_j $$&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Data in: $2N$&lt;/li&gt;
&lt;li&gt;Data out: $N^2$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;matrix-vector-products&#34;&gt;Matrix-vector products&lt;/h2&gt;

&lt;p&gt;$$ y&lt;em&gt;i = \sum&lt;/em&gt;{j} A_{ij} x_j $$&lt;/p&gt;

&lt;p&gt;How to partition the matrix $A$ across $P$ processors?&lt;/p&gt;

&lt;h3 id=&#34;1d-row-partition&#34;&gt;1D row partition&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Every process needs entire vector $x$: &lt;code&gt;MPI_Allgather&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Matrix data does not move&lt;/li&gt;
&lt;li&gt;Execution time
$$ \underbrace{\frac{2N^2}{RP}}_{\text{compute}} + \underbrace{t_1 \log&lt;em&gt;2 P}&lt;/em&gt;{\text{latency}} + \underbrace{t&lt;em&gt;b N \frac{P-1}{P}}&lt;/em&gt;{\text{bandwidth}} $$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;05-matvec-row.png&#34; alt=&#34;Thanks to Abtin Rahimian&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;2d-partition&#34;&gt;2D partition&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Blocks of size $N/\sqrt{P}$&lt;/li&gt;
&lt;li&gt;&amp;ldquo;diagonal&amp;rdquo; ranks hold the input vector&lt;/li&gt;
&lt;li&gt;Broadcast $x$ along columns: &lt;code&gt;MPI_Bcast&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Perform local compute&lt;/li&gt;
&lt;li&gt;Sum &lt;code&gt;y&lt;/code&gt; along rows: &lt;code&gt;MPI_Reduce&lt;/code&gt; with roots on diagonal&lt;/li&gt;
&lt;li&gt;Execution time
$$ \underbrace{\frac{2N^2}{RP}}_{\text{compute}} + \underbrace{2 t_1 \log&lt;em&gt;2 P}&lt;/em&gt;{\text{latency}} + \underbrace{\frac{2 t&lt;em&gt;b N}{\sqrt{P}}}&lt;/em&gt;{\text{bandwidth}} $$&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;05-matvec-block.png&#34; alt=&#34;Thanks to Abtin Rahimian&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;N = 1e4
tb = 8 / 1e9 # 8 bytes / (1 GB/s) ~ bandwidth per core in units of double
tb *= 100

plt.loglog(P, (2*N**2)/(R*P) + t1*np.log2(P) + tb*N*(P-1)/P, label=&#39;1D distribution&#39;)
plt.loglog(P, (2*N**2)/(R*P) + 2*t1*np.log2(P) + 2*tb*N/np.sqrt(P), label=&#39;2D distribution&#39;)
plt.xlabel(&#39;P processors&#39;)
plt.ylabel(&#39;Execution time&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to MPI</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-mpi/</link>
      <pubDate>Tue, 24 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-mpi/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
    from IPython.display import Markdown
    with open(filename) as f:
        contents = f.read()
    return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;processes-and-threads&#34;&gt;Processes and Threads&lt;/h2&gt;

&lt;p&gt;Threads and processes are very similar
* Both created via &lt;a href=&#34;https://linux.die.net/man/2/clone&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;clone&lt;/code&gt; system call&lt;/a&gt; on Linux
* Scheduled in the same way by the operating system
* Separate stacks (automatic variables)
* Access to same memory before &lt;code&gt;fork()&lt;/code&gt; or &lt;code&gt;clone()&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;with some important distinctions&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Threads set &lt;code&gt;CLONE_VM&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;threads share the same virtual-to-physical address mapping&lt;/li&gt;
&lt;li&gt;threads can access the same data at the same addresses; private data is private only because other threads don&amp;rsquo;t know its address&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Threads set &lt;code&gt;CLONE_FILES&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;threads share file descriptors&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Threads set &lt;code&gt;CLONE_THREAD&lt;/code&gt;, &lt;code&gt;CLONE_SIGHAND&lt;/code&gt;

&lt;ul&gt;
&lt;li&gt;process id and signal handlers shared&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;myths&#34;&gt;Myths&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Processes can&amp;rsquo;t share memory

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;mmap()&lt;/code&gt;, &lt;code&gt;shm_open()&lt;/code&gt;, and &lt;code&gt;MPI_Win_allocate_shared()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Processes are &amp;ldquo;heavy&amp;rdquo;

&lt;ul&gt;
&lt;li&gt;same data structures and kernel scheduling; no difference in context switching&lt;/li&gt;
&lt;li&gt;data from parent is inherited copy-on-write at very low overhead&lt;/li&gt;
&lt;li&gt;startup costs ~100 microseconds to duplicate page tables&lt;/li&gt;
&lt;li&gt;caches are physically tagged; processes can share L1 cache&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;mpi-message-passing-interface&#34;&gt;MPI: Message Passing Interface&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Just a library: plain C, C++, or Fortran compiler

&lt;ul&gt;
&lt;li&gt;Two active open source libraries: &lt;a href=&#34;https://www.mpich.org/&#34; target=&#34;_blank&#34;&gt;MPICH&lt;/a&gt; and &lt;a href=&#34;https://www.open-mpi.org/&#34; target=&#34;_blank&#34;&gt;Open MPI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Numerous vendor implementations modify/extend these open source implementations&lt;/li&gt;
&lt;li&gt;MVAPICH is an MPICH-derived open source implementation for InfiniBand and related networks&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Bindings from many other languages; &lt;a href=&#34;https://mpi4py.readthedocs.io/en/stable/&#34; target=&#34;_blank&#34;&gt;mpi4py&lt;/a&gt; is popular&lt;/li&gt;
&lt;li&gt;Scales to millions of processes across ~100k nodes

&lt;ul&gt;
&lt;li&gt;Shared memory systems can be scaled up to &lt;a href=&#34;https://www.uvhpc.com/sgi-uv-3000&#34; target=&#34;_blank&#34;&gt;~4000 cores&lt;/a&gt;, but latency and price ($) increase&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Standard usage: processes are separate on startup&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Timeline&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;MPI-1 (1994) point-to-point messaging, collectives&lt;/li&gt;
&lt;li&gt;MPI-2 (1997) parallel IO, dynamic processes, one-sided&lt;/li&gt;

&lt;li&gt;&lt;p&gt;MPI-3 (2012) nonblocking collectives, neighborhood collectives, improved one-sided&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;mpi-demo.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;mpi.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

int main(int argc, char **argv) {
MPI_Init(&amp;amp;argc, &amp;amp;argv);   // Must call before any other MPI functions
int size, rank, sum;
MPI_Comm_rank(MPI_COMM_WORLD, &amp;amp;rank);
MPI_Comm_size(MPI_COMM_WORLD, &amp;amp;size);
MPI_Allreduce(&amp;amp;rank, &amp;amp;sum, 1, MPI_INT, MPI_SUM, MPI_COMM_WORLD);
printf(&amp;quot;I am rank %d of %d: sum=%d\n&amp;quot;, rank, size, sum);
MPI_Finalize();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This may remind you of the top-level OpenMP strategy&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int main() {
    #pragma omp parallel
    {
        int rank = omp_get_thread_num();
        int size = omp_get_num_threads();
        // your code
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;We use the compiler wrapper &lt;code&gt;mpicc&lt;/code&gt;, but it just passes some flags to the real compiler.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpicc -show
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;gcc -pthread -Wl,-rpath -Wl,/usr/lib/openmpi -Wl,&amp;ndash;enable-new-dtags -L/usr/lib/openmpi -lmpi&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! make CC=mpicc CFLAGS=-Wall mpi-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;mpicc -Wall    mpi-demo.c   -o mpi-demo&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We use &lt;code&gt;mpiexec&lt;/code&gt; to run locally.  Clusters/supercomputers often have different job launching programs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 2 ./mpi-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am rank 0 of 2: sum=1
I am rank 1 of 2: sum=1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;We can run more MPI processes than cores (or hardware threads), but you might need to use the &lt;code&gt;--oversubscribe&lt;/code&gt; option because &lt;strong&gt;oversubscription is usually expensive&lt;/strong&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;! mpiexec -n 6 --oversubscribe ./mpi-demo
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;I am rank 1 of 6: sum=15
I am rank 3 of 6: sum=15
I am rank 4 of 6: sum=15
I am rank 5 of 6: sum=15
I am rank 0 of 6: sum=15
I am rank 2 of 6: sum=15&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;You can use OpenMP within ranks of MPI (but use &lt;code&gt;MPI_Init_thread()&lt;/code&gt;)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Everything is private by default&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;advice-from-bill-gropp&#34;&gt;Advice from Bill Gropp&lt;/h4&gt;

&lt;blockquote&gt;
&lt;p&gt;You want to think about how you decompose your data structures, how
    you think about them globally.  [&amp;hellip;]  If you were building a house,
    you&amp;rsquo;d start with a set of blueprints that give you a picture of what
    the whole house looks like.  You wouldn&amp;rsquo;t start with a bunch of
    tiles and say. &amp;ldquo;Well I&amp;rsquo;ll put this tile down on the ground, and
    then I&amp;rsquo;ll find a tile to go next to it.&amp;rdquo;  But all too many people
    try to build their parallel programs by creating the smallest
    possible tiles and then trying to have the structure of their code
    emerge from the chaos of all these little pieces.  You have to have
    an organizing principle if you&amp;rsquo;re going to survive making your code
    parallel.
    &amp;ndash; &lt;a href=&#34;https://www.rce-cast.com/Podcast/rce-28-mpich2.html&#34; target=&#34;_blank&#34;&gt;https://www.rce-cast.com/Podcast/rce-28-mpich2.html&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&#34;communicators&#34;&gt;Communicators&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;MPI_COMM_WORLD&lt;/code&gt; contains all ranks in the &lt;code&gt;mpiexec&lt;/code&gt;.  Those ranks may be on different nodes, even in different parts of the world.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;MPI_COMM_SELF&lt;/code&gt; contains only one rank&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Can create new communicators from existing ones&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int MPI_Comm_dup(MPI_Comm comm, MPI_Comm *newcomm);
int MPI_Comm_split(MPI_Comm comm, int color, int key, MPI_Comm *newcomm);
int MPI_Comm_create(MPI_Comm comm, MPI_Group group, MPI_Comm *newcomm);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Can spawn new processes (but not supported on all machines)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int MPI_Comm_spawn(const char *command, char *argv[], int maxprocs,
        MPI_Info info, int root, MPI_Comm comm,
        MPI_Comm *intercomm, int array_of_errcodes[]);
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Can attach &lt;em&gt;attributes&lt;/em&gt; to communicators (useful for library composition)&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;collective-operations&#34;&gt;Collective operations&lt;/h3&gt;

&lt;p&gt;MPI has a rich set of collective operations scoped by communicator, including the following.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int MPI_Allreduce(const void *sendbuf, void *recvbuf, int count,
        MPI_Datatype datatype, MPI_Op op, MPI_Comm comm);
int MPI_Reduce(const void *sendbuf, void *recvbuf, int count,
        MPI_Datatype datatype, MPI_Op op, int root, MPI_Comm comm);
int MPI_Scan(const void *sendbuf, void *recvbuf, int count,
        MPI_Datatype datatype, MPI_Op op, MPI_Comm comm);
int MPI_Gather(const void *sendbuf, int sendcount, MPI_Datatype sendtype,
        void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm);
int MPI_Scatter(const void *sendbuf, int sendcount, MPI_Datatype sendtype,
        void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm);
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Implementations are optimized by vendors for their custom networks, and can be very fast.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;https://www.mcs.anl.gov/~fischer/gop/bgp_gop_png.png&#34; alt=&#34;Fischer BGP&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Notice how the time is basically independent of number of processes $P$, and only a small multiple of the cost to send a single message. Not all networks are this good.&lt;/p&gt;

&lt;h3 id=&#34;point-to-point-messaging&#34;&gt;Point-to-point messaging&lt;/h3&gt;

&lt;p&gt;In addition to collectives, MPI supports messaging directly between individual ranks.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mpi-send-recv.png&#34; alt=&#34;send-recv&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Interfaces can be:

&lt;ul&gt;
&lt;li&gt;blocking like &lt;code&gt;MPI_Send()&lt;/code&gt; and &lt;code&gt;MPI_Recv()&lt;/code&gt;, or&lt;/li&gt;
&lt;li&gt;&amp;ldquo;immediate&amp;rdquo; (asynchronous), like &lt;code&gt;MPI_Isend()&lt;/code&gt; and &lt;code&gt;MPI_Irecv()&lt;/code&gt;.  The immediate varliants return an &lt;code&gt;MPI_Request&lt;/code&gt;, which must be waited on to complete the send or receive.&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Be careful of deadlock when using blocking interfaces.

&lt;ul&gt;
&lt;li&gt;I never use blocking send/recv.&lt;/li&gt;
&lt;li&gt;There are also &amp;ldquo;synchronous&amp;rdquo; &lt;code&gt;MPI_Ssend&lt;/code&gt; and &amp;ldquo;buffered&amp;rdquo; &lt;code&gt;MPI_Bsend&lt;/code&gt;, and nonblocking variants of these, &lt;code&gt;MPI_Issend&lt;/code&gt;, etc.&lt;/li&gt;
&lt;li&gt;I never use these either (with one cool exception that we&amp;rsquo;ll talk about).&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Point-to-point messaging is like the assembly of parallel computing

&lt;ul&gt;
&lt;li&gt;It can be good for building libraries, but it&amp;rsquo;s a headache to use directly for most purposes&lt;/li&gt;
&lt;li&gt;Better to use collectives when possible, or higher level libraries&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;neighbors&#34;&gt;Neighbors&lt;/h3&gt;

&lt;p&gt;A common pattern involves communicating with neighbors, often many times in sequence (such as each iteration or time step).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;mpi-neighbor-grid.png&#34; alt=&#34;Neighbor comm&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This can be achieved with
* Point-to-point: &lt;code&gt;MPI_Isend&lt;/code&gt;, &lt;code&gt;MPI_Irecv&lt;/code&gt;, &lt;code&gt;MPI_Waitall&lt;/code&gt;
* Persistent: &lt;code&gt;MPI_Send_init&lt;/code&gt; (once), &lt;code&gt;MPI_Startall&lt;/code&gt;, &lt;code&gt;MPI_Waitall&lt;/code&gt;.
* Neighborhood collectives (need to create special communicator)
* One-sided (need to manage safety yourself)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More bitonic sorting, graphs</title>
      <link>https://cucs-hpsc.github.io/fall2019/sorting-graphs/</link>
      <pubDate>Mon, 23 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/sorting-graphs/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import pandas
import numpy as np
import itertools
plt.style.use(&#39;seaborn&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;bitonic-sorting&#34;&gt;Bitonic sorting&lt;/h2&gt;

&lt;h3 id=&#34;definition-bitonic-sequence&#34;&gt;Definition: bitonic sequence&lt;/h3&gt;

&lt;p&gt;A bitonic sequence of length $n$ satisfies
$$ x_0 \le x_1 \le \dotsb \le x&lt;em&gt;k \ge x&lt;/em&gt;{k+1} \ge \dotsb \ge x_{n-1} $$
&lt;strong&gt;or a cyclic shift&lt;/strong&gt; thereof,
$$\hat x&lt;em&gt;i = x&lt;/em&gt;{i+c \bmod n} .$$&lt;/p&gt;

&lt;p&gt;sorting relies on the bitonic swapping operation,&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def bitonic_split(x):
    L = len(x) // 2
    for i in range(L):    # each pair is independent
        if (x[i] &amp;gt; x[L + i]):
            x[i], x[L + i] = x[L + i], x[i]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;after which the resulting subsequences &lt;code&gt;x[:L]&lt;/code&gt; and &lt;code&gt;x[L:]&lt;/code&gt; are bitonic and &lt;code&gt;max(x[:L]) &amp;lt;= min(x[L:])&lt;/code&gt;. (It is beyond the scope of this class to formally prove this property, but we&amp;rsquo;ll show examples.)&lt;/p&gt;

&lt;h3 id=&#34;example&#34;&gt;Example&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;x = list(range(10, 22)) + [16, 13, 10, 7]
idx = np.arange(len(x))
plt.plot(x, &#39;s&#39;, label=&#39;orig&#39;)
bitonic_split(x)
plt.plot(x, &#39;^k&#39;, label=&#39;swapped&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_4_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note that the bitonic sequence on the right side is cyclicly permuted.&lt;/p&gt;

&lt;h3 id=&#34;putting-it-together&#34;&gt;Putting it together&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/b/bd/BitonicSort1.svg&#34; alt=&#34;Bitonic sort from Wikipedia&#34; /&gt;&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;The blue blocks are forward bitonic merge networks, consisting of &lt;code&gt;bitonic_split&lt;/code&gt; followed by recursive splits.&lt;/li&gt;
&lt;li&gt;The green blocks are reverse networks.&lt;/li&gt;
&lt;li&gt;The left half of the diagram constructs a global bitonic sequence that is increasing in the top half and decreasing in the bottom half. This bitonic sequence is balanced and not &amp;ldquo;shifted&amp;rdquo;.&lt;/li&gt;
&lt;li&gt;The right half of the diagram merges a global bitonic sequence. The bitonic sequences produced in each stage of the merge may be unbalanced and/or cyclicly shifted.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;demo&#34;&gt;Demo&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def bitonic_sort(up, x, start=0, end=None, plot=[]):
    if end is None:
        end = len(x)
    if end - start &amp;lt;= 1:
        return
    mid = start + (end - start) // 2
    bitonic_sort(True, x, start, mid)
    bitonic_sort(False, x, mid, end)
    if (start, end) in plot:
        bitonic_plot(x, start, end, &#39;sort&#39;)
    bitonic_merge(up, x, start, end, plot=plot)

def bitonic_merge(up, x, start, end, plot=False): 
    # assume input x is bitonic, and sorted list is returned 
    if end - start == 1:
        return
    bitonic_split2(up, x, start, end)
    if (start, end) in plot:
        bitonic_plot(x, start, end, &#39;merge&#39;)
    mid = start + (end - start) // 2
    bitonic_merge(up, x, start, mid, plot=plot)
    bitonic_merge(up, x, mid, end, plot=plot)

def bitonic_split2(up, x, start, end):
    L = (end - start) // 2
    for i in range(start, start + L):
        if (x[i] &amp;gt; x[L + i]) == up:
            x[i], x[L + i] = x[L + i], x[i] # swap

def bitonic_plot(x, start, end, phase):
    plt.plot(range(start, end), x[start:end], next(marker), label=f&#39;{phase} {start}:{end}&#39;)
            
marker = itertools.cycle([&#39;s&#39;, &#39;o&#39;, &#39;^&#39;, &#39;&amp;lt;&#39;, &#39;*&#39;])
x = list(range(10, 38)) + [16, 13, 10, 7]
plt.plot(x, next(marker), label=&#39;orig&#39;)
bitonic_sort(True, x, plot=[(0, 32), (0,16), (8,16)])
#plt.plot(x, next(marker), label=&#39;sorted&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_7_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;further-resources-on-sorting&#34;&gt;Further resources on Sorting&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Chapter 9 of &lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/&#34; target=&#34;_blank&#34;&gt;Grama, Gupta, Karypis, Kumar (2003), &lt;strong&gt;Introduction to Parallel Computing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/Lectures/AG/chap9_slides.pdf&#34; target=&#34;_blank&#34;&gt;Grama slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;graphs&#34;&gt;Graphs&lt;/h1&gt;

&lt;p&gt;An (undirected) graph $(V, E)$ is a set of vertices $V$ and unordered pairs $(u,v) = (v,u) \in E$ of vertices $u,v \in V$.&lt;/p&gt;

&lt;p&gt;Graphs are often expressed by their adjacency matrix of dimension $n\times n$ where $n = |V|$,
$$ A_{ij} = \begin{cases}
    1, &amp;amp; \text{if } (i,j) \in E &lt;br /&gt;
    0,              &amp;amp; \text{otherwise}
\end{cases}
$$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;import networkx as nx

G = nx.grid_2d_graph(3, 3)
nx.draw(G, with_labels=True)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_10_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A = nx.adjacency_matrix(G)
A.todense()
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;matrix([[0, 1, 0, 1, 0, 0, 0, 0, 0],
        [1, 0, 1, 0, 1, 0, 0, 0, 0],
        [0, 1, 0, 0, 0, 1, 0, 0, 0],
        [1, 0, 0, 0, 1, 0, 1, 0, 0],
        [0, 1, 0, 1, 0, 1, 0, 1, 0],
        [0, 0, 1, 0, 1, 0, 0, 0, 1],
        [0, 0, 0, 1, 0, 0, 0, 1, 0],
        [0, 0, 0, 0, 1, 0, 1, 0, 1],
        [0, 0, 0, 0, 0, 1, 0, 1, 0]], dtype=int64)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;compressed-representation&#34;&gt;Compressed representation&lt;/h3&gt;

&lt;p&gt;Adjacency matrices often have many zeros so it&amp;rsquo;s common to store a compressed representation.
We&amp;rsquo;ll revisit such formats for sparse matrices.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;A.indptr, A.indices
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;(array([ 0,  2,  5,  7, 10, 14, 17, 19, 22, 24], dtype=int32),
 array([1, 3, 0, 2, 4, 1, 5, 0, 4, 6, 1, 3, 5, 7, 2, 4, 8, 3, 7, 4, 6, 8,
        5, 7], dtype=int32))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for row in range(A.shape[0]):
    print(A.indices[A.indptr[row]:A.indptr[row+1]])
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[1 3]
[0 2 4]
[1 5]
[0 4 6]
[1 3 5 7]
[2 4 8]
[3 7]
[4 6 8]
[5 7]
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;maximal-independent-set-mis&#34;&gt;Maximal independent set (MIS)&lt;/h2&gt;

&lt;p&gt;An independent set is a set of vertices $S \subset V$ such that $(u,v) \notin E$ for any pair $u,v \in S$.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;mis = nx.maximal_independent_set(G)
mis
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;[(2, 0), (1, 2), (0, 0)]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def plot_mis(G, mis):
    node_colors = [&#39;red&#39; if n in mis else &#39;#1f78b4&#39; for n in G.nodes()]
    nx.draw_networkx(G, node_color = node_colors)
plot_mis(G, mis)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_17_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# Maximal independent sets are not unique
plot_mis(G, [(0,0), (0,2), (1,1), (2,0), (2,2)])
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_18_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;# We can coax the greedy algorithm to give a better MIS by specifying
# some nodes to include
plot_mis(G, nx.maximal_independent_set(G, [(1,1)]))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_19_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;greedy-algorithms&#34;&gt;Greedy Algorithms&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;Start with all vertices in candidate set $C = V$, empty $S$&lt;/li&gt;
&lt;li&gt;While $C \ne \emptyset$: Choose a vertex $v \in C$

&lt;ul&gt;
&lt;li&gt;Add $v$ to $S$&lt;/li&gt;
&lt;li&gt;Remove $v$ and all neighbors of $v$ from $C$&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Algorithms differ in how they choose the next vertex $v \in C$.&lt;/p&gt;

&lt;h3 id=&#34;tiebreaking&#34;&gt;Tiebreaking&lt;/h3&gt;

&lt;p&gt;Suppose we index the vertices by integer and allow parallel selection of any $v$ for which
$$ v &amp;lt; \mathcal N(v) . $$&lt;/p&gt;

&lt;h4 id=&#34;hash-variant&#34;&gt;Hash variant&lt;/h4&gt;

&lt;p&gt;Consider a hash function $h(v)$ and allow any time&lt;/p&gt;

&lt;p&gt;$$ h(v) &amp;lt; \min_{u\in \mathcal N(v)} h(u). $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;G = nx.karate_club_graph()
plot_mis(G, nx.maximal_independent_set(G))
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;/usr/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: 
The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.
  if not cb.iterable(width):
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_21_1.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Chapter 10 of &lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/&#34; target=&#34;_blank&#34;&gt;Grama, Gupta, Karypis, Kumar (2003), &lt;strong&gt;Introduction to Parallel Computing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/Lectures/AG/chap10_slides.pdf&#34; target=&#34;_blank&#34;&gt;Grama slides&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Parallel Reductions and Scans</title>
      <link>https://cucs-hpsc.github.io/fall2019/strategies/</link>
      <pubDate>Wed, 18 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/strategies/</guid>
      <description>

&lt;h2 id=&#34;reductions&#34;&gt;Reductions&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double reduce(int n, double x[]) {
    double y = 0;
    for (int i=0; i&amp;lt;n; i++)
        y += x[i];
    return y;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;abtin-reduction-iterative.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;dag-properties&#34;&gt;DAG properties&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Work $W(n) = n$&lt;/li&gt;
&lt;li&gt;Depth $D(n) = n$&lt;/li&gt;
&lt;li&gt;Parallelism $P(n) = \frac{W(n)}{D(n)} = 1$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;a-2-level-method&#34;&gt;A 2-level method&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double reduce(int n, double x[]) {
    int P = sqrt(n); // ways of parallelism
    double y[P];
    #pragma omp parallel for shared(y)
    for (int p=0; p&amp;lt;P; p++) {
        y[p] = 0;
        for (int i=0; i&amp;lt;n/P; i++)
            y[p] += x[p*(n/P) + i];
    }
    double sum = 0;
    for (int p=0; p&amp;lt;P; p++)
        sum += y[p];
    return sum;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;dag-properties-1&#34;&gt;DAG properties&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Work $W(n) = n + \sqrt{n}$&lt;/li&gt;
&lt;li&gt;Depth $D(n) = 2 \sqrt{n}$&lt;/li&gt;
&lt;li&gt;Parallelism $P(n) = \sqrt{n}$&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;pram-performance-model&#34;&gt;PRAM performance model&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Processing units (e.g., OpenMP threads) execute local programs&lt;/li&gt;
&lt;li&gt;Communication through shared memory with no access cost&lt;/li&gt;
&lt;li&gt;Synchronous operation on a common clock

&lt;ul&gt;
&lt;li&gt;Barrier-like constructs are free&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Multiple Instruction, Multiple Data (MIMD)&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;scheduling&#34;&gt;Scheduling&lt;/h4&gt;

&lt;p&gt;How much time does it take to execute a DAG on $p$ processors?&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Sum work of each node $i$ along critical path of length $D(n)$
$$ \sum_{i=1}^{D(n)} W_i $$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Partition total work $W(n)$ over $p \le P(n)$ processors (as though there were no data dependencies)
$$ \left\lceil \frac{W(n)}{p} \right\rceil $$&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Total time must be at least as large as either of these
$$ T(n,p) \ge \max\left( D(n), \left\lceil \frac{W(n)}{p} \right\rceil \right) $$&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;more-levels&#34;&gt;More levels?&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double reduce(int n, double x[]) {
    if (n == 1) return x[0];
    double y[n/2];
    #pragma omp parallel for shared(y)
    for (int i=0; i&amp;lt;n/2; i++)
        y[i] = x[2*i] + x[2*i+1];
    return reduce(n/2, y);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;abtin-reduction-recursive.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;dag-properties-2&#34;&gt;DAG properties&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;$W(n) = n/2 + n/4 + n/8 + \dotsb = n$&lt;/li&gt;
&lt;li&gt;$D(n) = \log_2 n$&lt;/li&gt;
&lt;li&gt;$P(n) = n/2$&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;parallel-scans&#34;&gt;Parallel scans&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void scan(int n, double x[], double y[]) {
    y[0] = x[0];
    for (int i=1; i&amp;lt;n; i++)
        y[i] = y[i-1] + x[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;What are the DAG properties of this algorithm?&lt;/li&gt;
&lt;li&gt;How fast can we make it?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;abtin-scan-recursive.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void scan_inplace(int n, double y[], int stride) {
    if (2*stride &amp;gt; n) return;
    #pragma omp parallel for
    for (int i=2*stride-1; i&amp;lt;n; i+=2*stride)
        y[i] += [i - stride];

    scan(n, y, 2*stride);

    #pragma omp parallel for
    for (int i=3*stride-1; i&amp;lt;n; i+=2*stride)
        y[i] += y[i - stride];
}

// call like
scan_inplace(n, x, 1);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;application-of-scans-parallel-select&#34;&gt;Application of scans: parallel select&lt;/h3&gt;

&lt;p&gt;Select elements of array &lt;code&gt;x[]&lt;/code&gt; that satisfy a condition.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int c[n];
#pragma omp parallel for
for (int i=0; i&amp;lt;n; i++)
    c[i] = cond(x[i]); // returns 1 or 0

scan_inplace(n, c, 1);

double results[c[n-1]]; // allocate array with total number of items
#pragma omp parallel for
for (int i=0; i&amp;lt;n; i++)
    if (cond(x[i])) // Can use `c[i] - c[i-1]` to avoid recomputing
        results[c[i]-1] = x[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;hr /&gt;

&lt;p&gt;Figures courtesy Abtin Rahimian&amp;rsquo;s course notes.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenMP Tasks</title>
      <link>https://cucs-hpsc.github.io/fall2019/openmp-3/</link>
      <pubDate>Mon, 16 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/openmp-3/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
    from IPython.display import Markdown
    with open(filename) as f:
        contents = f.read()
    return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;using-pragma-omp-task&#34;&gt;Using &lt;code&gt;#pragma omp task&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Up to now, we&amp;rsquo;ve been expressing parallelism for iterating over an array.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;task_dep.4.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
int main() {
  int x = 1;
  #pragma omp parallel
  #pragma omp single
  {
    #pragma omp task shared(x) depend(out: x)
    x = 2;
    #pragma omp task shared(x) depend(in: x)
    printf(&amp;quot;x + 1 = %d. &amp;quot;, x+1);
    #pragma omp task shared(x) depend(in: x)
    printf(&amp;quot;x + 2 = %d. &amp;quot;, x+2);
  }
  puts(&amp;quot;&amp;quot;);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=-fopenmp -B task_dep.4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -fopenmp    task_dep.4.c   -o task_dep.4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!for i in {1..10}; do ./task_dep.4; done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;x + 2 = 4. x + 1 = 3. 
x + 1 = 3. x + 2 = 4. 
x + 2 = 4. x + 1 = 3. 
x + 1 = 3. x + 2 = 4. 
x + 2 = 4. x + 1 = 3. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 2 = 4. x + 1 = 3. 
x + 2 = 4. x + 1 = 3. 
x + 2 = 4. x + 1 = 3. 
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;task_dep.4inout.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
int main() {
  int x = 1;
  #pragma omp parallel
  #pragma omp single
  {
    #pragma omp task shared(x) depend(out: x)
    x = 2;
    #pragma omp task shared(x) depend(inout: x)
    printf(&amp;quot;x + 1 = %d. &amp;quot;, x+1);
    #pragma omp task shared(x) depend(in: x)
    printf(&amp;quot;x + 2 = %d. &amp;quot;, x+2);
  }
  puts(&amp;quot;&amp;quot;);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=-fopenmp -B task_dep.4inout
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -fopenmp    task_dep.4inout.c   -o task_dep.4inout
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!for i in {1..10}; do ./task_dep.4inout; done
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
x + 1 = 3. x + 2 = 4. 
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;computing-the-fibonacci-numbers-https-en-wikipedia-org-wiki-fibonacci-number-with-openmp&#34;&gt;Computing the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fibonacci_number&#34; target=&#34;_blank&#34;&gt;Fibonacci numbers&lt;/a&gt; with OpenMP&lt;/h2&gt;

&lt;p&gt;Fibonacci numbers are defined by the recurrence
\begin{align}
  F_0 &amp;amp;= 0 &lt;br /&gt;
  F_1 &amp;amp;= 1 &lt;br /&gt;
  F&lt;em&gt;n &amp;amp;= F&lt;/em&gt;{n-1} + F_{n-2}
\end{align}&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

long fib(long n) {
  if (n &amp;lt; 2) return n;
  return fib(n - 1) + fib(n - 2);
}

int main(int argc, char **argv) {
  if (argc != 2) {
    fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
    return 1;
  }
  long N = atol(argv[1]);
  long fibs[N];
  #pragma omp parallel for
  for (long i=0; i&amp;lt;N; i++)
    fibs[i] = fib(i+1);
  for (long i=0; i&amp;lt;N; i++)
    printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; -B fib
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -O2 -march=native -fopenmp -Wall    fib.c   -o fib
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=4 time ./fib 40
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; 1:     1
 2:     1
 3:     2
 4:     3
 5:     5
 6:     8
 7:    13
 8:    21
 9:    34
10:    55
11:    89
12:   144
13:   233
14:   377
15:   610
16:   987
17:  1597
18:  2584
19:  4181
20:  6765
21: 10946
22: 17711
23: 28657
24: 46368
25: 75025
26: 121393
27: 196418
28: 317811
29: 514229
30: 832040
31: 1346269
32: 2178309
33: 3524578
34: 5702887
35: 9227465
36: 14930352
37: 24157817
38: 39088169
39: 63245986
40: 102334155
0.85user 0.00system 0:00.78elapsed 109%CPU (0avgtext+0avgdata 2044maxresident)k
0inputs+0outputs (0major+99minor)pagefaults 0swaps
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;use-tasks&#34;&gt;Use tasks&lt;/h2&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib2.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

long fib(long n) {
  if (n &amp;lt; 2) return n;
  long n1, n2;
  #pragma omp task shared(n1)
  n1 = fib(n - 1);
  #pragma omp task shared(n2)
  n2 = fib(n - 2);
  #pragma omp taskwait
  return n1 + n2;
}

int main(int argc, char **argv) {
  if (argc != 2) {
    fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
    return 1;
  }
  long N = atol(argv[1]);
  long fibs[N];
  #pragma omp parallel
  #pragma omp single nowait
  {
    for (long i=0; i&amp;lt;N; i++)
      fibs[i] = fib(i+1);
  }
  for (long i=0; i&amp;lt;N; i++)
    printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; fib2
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: &#39;fib2&#39; is up to date.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=2 time ./fib2 30
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; 1:     1
 2:     1
 3:     2
 4:     3
 5:     5
 6:     8
 7:    13
 8:    21
 9:    34
10:    55
11:    89
12:   144
13:   233
14:   377
15:   610
16:   987
17:  1597
18:  2584
19:  4181
20:  6765
21: 10946
22: 17711
23: 28657
24: 46368
25: 75025
26: 121393
27: 196418
28: 317811
29: 514229
30: 832040
2.42user 0.81system 0:02.54elapsed 127%CPU (0avgtext+0avgdata 2028maxresident)k
0inputs+0outputs (0major+100minor)pagefaults 0swaps
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It&amp;rsquo;s expensive to create tasks when &lt;code&gt;n&lt;/code&gt; is small, even with only one thread.  How can we cut down on that overhead?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib3.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

long fib(long n) {
if (n &amp;lt; 2) return n;
if (n &amp;lt; 30)
return fib(n - 1) + fib(n - 2);
long n1, n2;
#pragma omp task shared(n1)
n1 = fib(n - 1);
#pragma omp task shared(n2)
n2 = fib(n - 2);
#pragma omp taskwait
return n1 + n2;
}

int main(int argc, char **argv) {
if (argc != 2) {
fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
return 1;
}
long N = atol(argv[1]);
long fibs[N];
#pragma omp parallel
#pragma omp single nowait
{
for (long i=0; i&amp;lt;N; i++)
  fibs[i] = fib(i+1);
}
for (long i=0; i&amp;lt;N; i++)
printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; fib3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;cc -O2 -march=native -fopenmp -Wall    fib3.c   -o fib3&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=3 time ./fib3 40
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1:     1
 2:     1
 3:     2
 4:     3
 5:     5
 6:     8
 7:    13
 8:    21
 9:    34
10:    55
11:    89
12:   144
13:   233
14:   377
15:   610
16:   987
17:  1597
18:  2584
19:  4181
20:  6765
21: 10946
22: 17711
23: 28657
24: 46368
25: 75025
26: 121393
27: 196418
28: 317811
29: 514229
30: 832040
31: 1346269
32: 2178309
33: 3524578
34: 5702887
35: 9227465
36: 14930352
37: 24157817
38: 39088169
39: 63245986
40: 102334155
3.56user 0.00system 0:01.27elapsed 280%CPU (0avgtext+0avgdata 1920maxresident)k
0inputs+0outputs (0major+103minor)pagefaults 0swaps&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;This is just slower, even with one thread.  Why might that be?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib4.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

long fib_seq(long n) {
if (n &amp;lt; 2) return n;
return fib_seq(n - 1) + fib_seq(n - 2);
}

long fib(long n) {
if (n &amp;lt; 30)
return fib_seq(n);
long n1, n2;
#pragma omp task shared(n1)
n1 = fib(n - 1);
#pragma omp task shared(n2)
n2 = fib(n - 2);
#pragma omp taskwait
return n1 + n2;
}

int main(int argc, char **argv) {
if (argc != 2) {
fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
return 1;
}
long N = atol(argv[1]);
long fibs[N];
#pragma omp parallel
#pragma omp single nowait
{
for (long i=0; i&amp;lt;N; i++)
  fibs[i] = fib(i+1);
}
for (long i=0; i&amp;lt;N; i++)
printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; fib4
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;make: &amp;lsquo;fib4&amp;rsquo; is up to date.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=2 time ./fib4 40
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;1:     1
 2:     1
 3:     2
 4:     3
 5:     5
 6:     8
 7:    13
 8:    21
 9:    34
10:    55
11:    89
12:   144
13:   233
14:   377
15:   610
16:   987
17:  1597
18:  2584
19:  4181
20:  6765
21: 10946
22: 17711
23: 28657
24: 46368
25: 75025
26: 121393
27: 196418
28: 317811
29: 514229
30: 832040
31: 1346269
32: 2178309
33: 3524578
34: 5702887
35: 9227465
36: 14930352
37: 24157817
38: 39088169
39: 63245986
40: 102334155
0.94user 0.00system 0:00.53elapsed 177%CPU (0avgtext+0avgdata 2040maxresident)k
8inputs+0outputs (0major+97minor)pagefaults 0swaps&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;alt-schedule-static-1&#34;&gt;Alt: &lt;code&gt;schedule(static,1)&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib5.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

long fib(long n) {
  if (n &amp;lt; 2) return n;
  return fib(n - 1) + fib(n - 2);
}

int main(int argc, char **argv) {
  if (argc != 2) {
    fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
    return 1;
  }
  long N = atol(argv[1]);
  long fibs[N];
  #pragma omp parallel for schedule(static,1)
  for (long i=0; i&amp;lt;N; i++)
    fibs[i] = fib(i+1);
  for (long i=0; i&amp;lt;N; i++)
    printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; fib5
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;make: &#39;fib5&#39; is up to date.
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=2 time ./fib5 40
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; 1:     1
 2:     1
 3:     2
 4:     3
 5:     5
 6:     8
 7:    13
 8:    21
 9:    34
10:    55
11:    89
12:   144
13:   233
14:   377
15:   610
16:   987
17:  1597
18:  2584
19:  4181
20:  6765
21: 10946
22: 17711
23: 28657
24: 46368
25: 75025
26: 121393
27: 196418
28: 317811
29: 514229
30: 832040
31: 1346269
32: 2178309
33: 3524578
34: 5702887
35: 9227465
36: 14930352
37: 24157817
38: 39088169
39: 63245986
40: 102334155
0.88user 0.00system 0:00.54elapsed 161%CPU (0avgtext+0avgdata 1908maxresident)k
8inputs+0outputs (0major+93minor)pagefaults 0swaps
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;better-math&#34;&gt;Better math&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;fib6.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdio.h&amp;gt;
#include &amp;lt;stdlib.h&amp;gt;

int main(int argc, char **argv) {
  if (argc != 2) {
    fprintf(stderr, &amp;quot;Usage: %s N\n&amp;quot;, argv[0]);
    return 1;
  }
  long N = atol(argv[1]);
  long fibs[N];
  fibs[0] = 1;
  fibs[1] = 2;
  for (long i=2; i&amp;lt;N; i++)
    fibs[i] = fibs[i-1] + fibs[i-2];
  for (long i=0; i&amp;lt;N; i++)
    printf(&amp;quot;%2ld: %5ld\n&amp;quot;, i+1, fibs[i]);
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O2 -march=native -fopenmp -Wall&#39; fib6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -O2 -march=native -fopenmp -Wall    fib6.c   -o fib6
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!time ./fib6 100
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt; 1:     1
 2:     2
 3:     3
 4:     5
 5:     8
 6:    13
 7:    21
 8:    34
 9:    55
10:    89
11:   144
12:   233
13:   377
14:   610
15:   987
16:  1597
17:  2584
18:  4181
19:  6765
20: 10946
21: 17711
22: 28657
23: 46368
24: 75025
25: 121393
26: 196418
27: 317811
28: 514229
29: 832040
30: 1346269
31: 2178309
32: 3524578
33: 5702887
34: 9227465
35: 14930352
36: 24157817
37: 39088169
38: 63245986
39: 102334155
40: 165580141
41: 267914296
42: 433494437
43: 701408733
44: 1134903170
45: 1836311903
46: 2971215073
47: 4807526976
48: 7778742049
49: 12586269025
50: 20365011074
51: 32951280099
52: 53316291173
53: 86267571272
54: 139583862445
55: 225851433717
56: 365435296162
57: 591286729879
58: 956722026041
59: 1548008755920
60: 2504730781961
61: 4052739537881
62: 6557470319842
63: 10610209857723
64: 17167680177565
65: 27777890035288
66: 44945570212853
67: 72723460248141
68: 117669030460994
69: 190392490709135
70: 308061521170129
71: 498454011879264
72: 806515533049393
73: 1304969544928657
74: 2111485077978050
75: 3416454622906707
76: 5527939700884757
77: 8944394323791464
78: 14472334024676221
79: 23416728348467685
80: 37889062373143906
81: 61305790721611591
82: 99194853094755497
83: 160500643816367088
84: 259695496911122585
85: 420196140727489673
86: 679891637638612258
87: 1100087778366101931
88: 1779979416004714189
89: 2880067194370816120
90: 4660046610375530309
91: 7540113804746346429
92: -6246583658587674878
93: 1293530146158671551
94: -4953053512429003327
95: -3659523366270331776
96: -8612576878699335103
97: 6174643828739884737
98: -2437933049959450366
99: 3736710778780434371
100: 1298777728820984005
0.002 real   0.002 user   0.000 sys   99.42 cpu
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;to-fork-join-or-to-task&#34;&gt;To fork/join or to task?&lt;/h2&gt;

&lt;p&gt;When the work unit &lt;strong&gt;size&lt;/strong&gt; and &lt;strong&gt;compute speed&lt;/strong&gt; is predictable, we can partition work in advance and schedule with &lt;code&gt;omp for&lt;/code&gt; to achieve load balance.
Satisfying both criteria is often hard:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Adaptive algorithms, adaptive physics, implicit constitutive models&lt;/li&gt;
&lt;li&gt;AVX throttling, thermal throttling, network or file system contention, OS jitter&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Fork/join and barriers are also high overhead, so we might want to express data dependencies more precisely.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://community.arm.com/resized-image/__size/1040x0/__key/communityserver-blogs-components-weblogfiles/00-00-00-37-98/Screenshot-2019_2D00_09_2D00_02-at-17.50.07.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;For tasking to be efficient, it relies on &lt;strong&gt;overdecomposition&lt;/strong&gt;, creating more work units than there are processing units.
For many numerical algorithms, there is some overhead to overdecomposition.  For example, in array processing, a halo/fringe/ghost/overlap region might need to be computed as part of each work patch, leading to time models along the lines of
$$ t&lt;em&gt;{\text{tile}}(n) = t&lt;/em&gt;{\text{latency}} + \frac{(n+2)^3}{R} $$
where $R$ is the processing rate.
In addition to the latency, the overhead fraction is
$$ \frac{(n+2)^3 - n^3}{n^3} \approx 6/n $$
indicating that larger $n$ should be more efficient.&lt;/p&gt;

&lt;p&gt;However, if this overhead is acceptable and you still have load balancing challenges, tasking can be a solution.
(Example from a recent &lt;a href=&#34;https://community.arm.com/developer/research/b/articles/posts/tasking-lives-up-to-its-promises&#34; target=&#34;_blank&#34;&gt;blog/talk&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://community.arm.com/resized-image/__size/2080x0/__key/communityserver-blogs-components-weblogfiles/00-00-00-37-98/timestamp.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;computational-depth-and-the-critical-path&#34;&gt;Computational depth and the critical path&lt;/h2&gt;

&lt;p&gt;Consider the block Cholesky factorization algorithm (applying to the lower-triangular matrix $A$).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./chol-alg.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Expressing essential data dependencies, this results in the following directed acyclic graph (DAG).
No parallel algorithm can complete in less time than it takes for a sequential algorithm to perform each operation along the critical path (i.e., the minimum depth of this graph such that all arrows point downward).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;./chol-graph.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Figures from &lt;a href=&#34;https://doi.org/10.1109/IPDPS.2016.9&#34; target=&#34;_blank&#34;&gt;Agullo et al (2016): Are Static Schedules so Bad? A Case Study on Cholesky Factorization&lt;/a&gt;, which is an interesting counterpoint to the common narrative pushing dynamic scheduling.&lt;/p&gt;

&lt;h3 id=&#34;question-what-is-the-computational-depth-of-summing-an-array&#34;&gt;Question: what is the computational depth of summing an array?&lt;/h3&gt;

&lt;p&gt;$$ \sum_{i=0}^{N-1} a_i $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double sum = 0;
for (int i=0; i&amp;lt;N; i++)
    sum += array[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Given an arbitrarily large number $P$ of processing units, what is the smallest computational depth to compute this mathematical result?  (You&amp;rsquo;re free to use any associativity.)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>More OpenMP</title>
      <link>https://cucs-hpsc.github.io/fall2019/openmp-2/</link>
      <pubDate>Fri, 13 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/openmp-2/</guid>
      <description>

&lt;p&gt;What does the compiler do when we add &lt;code&gt;#pragma omp parallel&lt;/code&gt;?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static double dot_opt3(size_t n, const double *a, const double *b) {
  double sum = 0;
  omp_set_num_threads(4);
  #pragma omp parallel
  {
    #pragma omp for reduction(+:sum)
    for (size_t i=0; i&amp;lt;n; i++)
      sum += a[i] * b[i];
  }
  return sum;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;gcc -Os -march=native -fopenmp dot.c -o dot
objdump -d --prefix-addresses -M intel dot | grep dot_opt3
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;000000000000129f &amp;lt;main+0x1af&amp;gt; call   0000000000001779 &amp;lt;dot_opt3&amp;gt;
0000000000001779 &amp;lt;dot_opt3&amp;gt; push   r12
000000000000177b &amp;lt;dot_opt3+0x2&amp;gt; mov    r12,rdx
000000000000177e &amp;lt;dot_opt3+0x5&amp;gt; push   rbp
000000000000177f &amp;lt;dot_opt3+0x6&amp;gt; mov    rbp,rsi
0000000000001782 &amp;lt;dot_opt3+0x9&amp;gt; push   rbx
0000000000001783 &amp;lt;dot_opt3+0xa&amp;gt; mov    rbx,rdi
0000000000001786 &amp;lt;dot_opt3+0xd&amp;gt; mov    edi,0x4
000000000000178b &amp;lt;dot_opt3+0x12&amp;gt; sub    rsp,0x30
000000000000178f &amp;lt;dot_opt3+0x16&amp;gt; mov    rax,QWORD PTR fs:0x28
0000000000001798 &amp;lt;dot_opt3+0x1f&amp;gt; mov    QWORD PTR [rsp+0x28],rax
000000000000179d &amp;lt;dot_opt3+0x24&amp;gt; xor    eax,eax
000000000000179f &amp;lt;dot_opt3+0x26&amp;gt; call   0000000000001070 &amp;lt;omp_set_num_threads@plt&amp;gt;
00000000000017a4 &amp;lt;dot_opt3+0x2b&amp;gt; xor    ecx,ecx
00000000000017a6 &amp;lt;dot_opt3+0x2d&amp;gt; xor    edx,edx
00000000000017a8 &amp;lt;dot_opt3+0x2f&amp;gt; lea    rsi,[rsp+0x8]
00000000000017ad &amp;lt;dot_opt3+0x34&amp;gt; lea    rdi,[rip+0xc1]        # 0000000000001875 &amp;lt;dot_opt3._omp_fn.0&amp;gt;
00000000000017b4 &amp;lt;dot_opt3+0x3b&amp;gt; mov    QWORD PTR [rsp+0x18],r12
00000000000017b9 &amp;lt;dot_opt3+0x40&amp;gt; mov    QWORD PTR [rsp+0x10],rbp
00000000000017be &amp;lt;dot_opt3+0x45&amp;gt; mov    QWORD PTR [rsp+0x8],rbx
00000000000017c3 &amp;lt;dot_opt3+0x4a&amp;gt; mov    QWORD PTR [rsp+0x20],0x0
00000000000017cc &amp;lt;dot_opt3+0x53&amp;gt; call   00000000000010e0 &amp;lt;GOMP_parallel@plt&amp;gt;
00000000000017d1 &amp;lt;dot_opt3+0x58&amp;gt; mov    rax,QWORD PTR [rsp+0x28]
00000000000017d6 &amp;lt;dot_opt3+0x5d&amp;gt; xor    rax,QWORD PTR fs:0x28
00000000000017df &amp;lt;dot_opt3+0x66&amp;gt; vmovsd xmm0,QWORD PTR [rsp+0x20]
00000000000017e5 &amp;lt;dot_opt3+0x6c&amp;gt; je     00000000000017ec &amp;lt;dot_opt3+0x73&amp;gt;
00000000000017e7 &amp;lt;dot_opt3+0x6e&amp;gt; call   0000000000001080 &amp;lt;__stack_chk_fail@plt&amp;gt;
00000000000017ec &amp;lt;dot_opt3+0x73&amp;gt; add    rsp,0x30
00000000000017f0 &amp;lt;dot_opt3+0x77&amp;gt; pop    rbx
00000000000017f1 &amp;lt;dot_opt3+0x78&amp;gt; pop    rbp
00000000000017f2 &amp;lt;dot_opt3+0x79&amp;gt; pop    r12
00000000000017f4 &amp;lt;dot_opt3+0x7b&amp;gt; ret    
0000000000001875 &amp;lt;dot_opt3._omp_fn.0&amp;gt; push   r12
0000000000001877 &amp;lt;dot_opt3._omp_fn.0+0x2&amp;gt; push   rbp
0000000000001878 &amp;lt;dot_opt3._omp_fn.0+0x3&amp;gt; mov    rbp,rdi
000000000000187b &amp;lt;dot_opt3._omp_fn.0+0x6&amp;gt; push   rbx
000000000000187c &amp;lt;dot_opt3._omp_fn.0+0x7&amp;gt; sub    rsp,0x10
0000000000001880 &amp;lt;dot_opt3._omp_fn.0+0xb&amp;gt; mov    rbx,QWORD PTR [rdi]
0000000000001883 &amp;lt;dot_opt3._omp_fn.0+0xe&amp;gt; test   rbx,rbx
0000000000001886 &amp;lt;dot_opt3._omp_fn.0+0x11&amp;gt; jne    00000000000018b5 &amp;lt;dot_opt3._omp_fn.0+0x40&amp;gt;
0000000000001888 &amp;lt;dot_opt3._omp_fn.0+0x13&amp;gt; vxorpd xmm0,xmm0,xmm0
000000000000188c &amp;lt;dot_opt3._omp_fn.0+0x17&amp;gt; mov    rax,QWORD PTR [rbp+0x18]
0000000000001890 &amp;lt;dot_opt3._omp_fn.0+0x1b&amp;gt; lea    rdx,[rbp+0x18]
0000000000001894 &amp;lt;dot_opt3._omp_fn.0+0x1f&amp;gt; mov    QWORD PTR [rsp],rax
0000000000001898 &amp;lt;dot_opt3._omp_fn.0+0x23&amp;gt; vaddsd xmm1,xmm0,QWORD PTR [rsp]
000000000000189d &amp;lt;dot_opt3._omp_fn.0+0x28&amp;gt; vmovsd QWORD PTR [rsp+0x8],xmm1
00000000000018a3 &amp;lt;dot_opt3._omp_fn.0+0x2e&amp;gt; mov    rdi,QWORD PTR [rsp+0x8]
00000000000018a8 &amp;lt;dot_opt3._omp_fn.0+0x33&amp;gt; lock cmpxchg QWORD PTR [rdx],rdi
00000000000018ad &amp;lt;dot_opt3._omp_fn.0+0x38&amp;gt; cmp    QWORD PTR [rsp],rax
00000000000018b1 &amp;lt;dot_opt3._omp_fn.0+0x3c&amp;gt; je     000000000000190c &amp;lt;dot_opt3._omp_fn.0+0x97&amp;gt;
00000000000018b3 &amp;lt;dot_opt3._omp_fn.0+0x3e&amp;gt; jmp    0000000000001894 &amp;lt;dot_opt3._omp_fn.0+0x1f&amp;gt;
00000000000018b5 &amp;lt;dot_opt3._omp_fn.0+0x40&amp;gt; call   00000000000010b0 &amp;lt;omp_get_num_threads@plt&amp;gt;
00000000000018ba &amp;lt;dot_opt3._omp_fn.0+0x45&amp;gt; mov    r12d,eax
00000000000018bd &amp;lt;dot_opt3._omp_fn.0+0x48&amp;gt; call   0000000000001060 &amp;lt;omp_get_thread_num@plt&amp;gt;
00000000000018c2 &amp;lt;dot_opt3._omp_fn.0+0x4d&amp;gt; movsxd rcx,eax
00000000000018c5 &amp;lt;dot_opt3._omp_fn.0+0x50&amp;gt; movsxd rsi,r12d
00000000000018c8 &amp;lt;dot_opt3._omp_fn.0+0x53&amp;gt; mov    rax,rbx
00000000000018cb &amp;lt;dot_opt3._omp_fn.0+0x56&amp;gt; xor    edx,edx
00000000000018cd &amp;lt;dot_opt3._omp_fn.0+0x58&amp;gt; div    rsi
00000000000018d0 &amp;lt;dot_opt3._omp_fn.0+0x5b&amp;gt; cmp    rcx,rdx
00000000000018d3 &amp;lt;dot_opt3._omp_fn.0+0x5e&amp;gt; jb     0000000000001905 &amp;lt;dot_opt3._omp_fn.0+0x90&amp;gt;
00000000000018d5 &amp;lt;dot_opt3._omp_fn.0+0x60&amp;gt; imul   rcx,rax
00000000000018d9 &amp;lt;dot_opt3._omp_fn.0+0x64&amp;gt; vxorpd xmm0,xmm0,xmm0
00000000000018dd &amp;lt;dot_opt3._omp_fn.0+0x68&amp;gt; add    rdx,rcx
00000000000018e0 &amp;lt;dot_opt3._omp_fn.0+0x6b&amp;gt; add    rax,rdx
00000000000018e3 &amp;lt;dot_opt3._omp_fn.0+0x6e&amp;gt; cmp    rdx,rax
00000000000018e6 &amp;lt;dot_opt3._omp_fn.0+0x71&amp;gt; jae    000000000000188c &amp;lt;dot_opt3._omp_fn.0+0x17&amp;gt;
00000000000018e8 &amp;lt;dot_opt3._omp_fn.0+0x73&amp;gt; mov    rcx,QWORD PTR [rbp+0x10]
00000000000018ec &amp;lt;dot_opt3._omp_fn.0+0x77&amp;gt; mov    rsi,QWORD PTR [rbp+0x8]
00000000000018f0 &amp;lt;dot_opt3._omp_fn.0+0x7b&amp;gt; vmovsd xmm2,QWORD PTR [rsi+rdx*8]
00000000000018f5 &amp;lt;dot_opt3._omp_fn.0+0x80&amp;gt; vfmadd231sd xmm0,xmm2,QWORD PTR [rcx+rdx*8]
00000000000018fb &amp;lt;dot_opt3._omp_fn.0+0x86&amp;gt; inc    rdx
00000000000018fe &amp;lt;dot_opt3._omp_fn.0+0x89&amp;gt; cmp    rax,rdx
0000000000001901 &amp;lt;dot_opt3._omp_fn.0+0x8c&amp;gt; jne    00000000000018f0 &amp;lt;dot_opt3._omp_fn.0+0x7b&amp;gt;
0000000000001903 &amp;lt;dot_opt3._omp_fn.0+0x8e&amp;gt; jmp    000000000000188c &amp;lt;dot_opt3._omp_fn.0+0x17&amp;gt;
0000000000001905 &amp;lt;dot_opt3._omp_fn.0+0x90&amp;gt; inc    rax
0000000000001908 &amp;lt;dot_opt3._omp_fn.0+0x93&amp;gt; xor    edx,edx
000000000000190a &amp;lt;dot_opt3._omp_fn.0+0x95&amp;gt; jmp    00000000000018d5 &amp;lt;dot_opt3._omp_fn.0+0x60&amp;gt;
000000000000190c &amp;lt;dot_opt3._omp_fn.0+0x97&amp;gt; add    rsp,0x10
0000000000001910 &amp;lt;dot_opt3._omp_fn.0+0x9b&amp;gt; pop    rbx
0000000000001911 &amp;lt;dot_opt3._omp_fn.0+0x9c&amp;gt; pop    rbp
0000000000001912 &amp;lt;dot_opt3._omp_fn.0+0x9d&amp;gt; pop    r12
0000000000001914 &amp;lt;dot_opt3._omp_fn.0+0x9f&amp;gt; ret    
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;anatomy-of-a-parallel-region&#34;&gt;Anatomy of a parallel region&lt;/h2&gt;

&lt;div class=&#34;mermaid&#34;&gt;
graph LR;
  A[&lt;tt&gt;dot_opt3&lt;/tt&gt;]--&gt;B[&lt;tt&gt;GOMP_parallel&lt;/tt&gt;];
  B-- id=0_ --&gt;C{&lt;tt&gt;dot_opt3._omp_fn.0&lt;/tt&gt;};
  B-- id=1_ --&gt;C{&lt;tt&gt;dot_opt3._omp_fn.0&lt;/tt&gt;};
  B-- id=2_ --&gt;C{&lt;tt&gt;dot_opt3._omp_fn.0&lt;/tt&gt;};
  A-. &#34;Body inside__&#34; .-&gt;C;
  C--&gt;D[&lt;tt&gt;omp_get_num_threads&lt;/tt&gt;];
  C--&gt;E[&lt;tt&gt;omp_get_thread_num&lt;/tt&gt;];
  style A fill:#9b9,stroke:#686,stroke-width:4px;
  style C fill:#9b9,stroke:#668,stroke-width:8px;
&lt;/div&gt;

&lt;h2 id=&#34;memory-semantics&#34;&gt;Memory semantics&lt;/h2&gt;

&lt;p&gt;For each variable accessed within the parallel region, we can specify
whether it is&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;private&lt;/code&gt; to the thread, with value undefined inside the region&lt;/li&gt;
&lt;li&gt;&lt;code&gt;firstprivate&lt;/code&gt;, which is like private, but initialized by the value
upon entering the parallel region&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;shared&lt;/code&gt;, meaning that every thread accesses the same value in
memory (but changes are not immediately visible)&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;int a=0, b=1, c=2;
#pragma omp parallel private(a) firstprivate(b) shared(c)
{
int id = omp_get_thread_num();
a++;
b++;
c++;
printf(&amp;quot;[%d] %d %d %d\n&amp;quot;, id, a, b, c);
}
printf(&amp;quot;END: %d %d %d\n&amp;quot;, a, b, c);
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;make CFLAGS=&#39;-fopenmp -Wall&#39; -B omp-mem
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -fopenmp -Wall    omp-mem.c   -o omp-mem
omp-mem.c: In function â€˜main._omp_fn.0â€™:
omp-mem.c:8:6: warning: â€˜aâ€™ is used uninitialized in this function [-Wuninitialized]
8 |     a++;
  |     ~^~
omp-mem.c:5:7: note: â€˜aâ€™ was declared here
5 |   int a=1, b=2, c=3;
  |       ^
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;strong&gt;Question:&lt;/strong&gt; How could the compiler get &lt;code&gt;firstprivate&lt;/code&gt; and &lt;code&gt;shared&lt;/code&gt; variables into
the scope of &lt;code&gt;dot_opt3._omp_fn.0&lt;/code&gt;?&lt;/p&gt;

&lt;h3 id=&#34;programming-style&#34;&gt;Programming style&lt;/h3&gt;

&lt;p&gt;I find &lt;code&gt;private&lt;/code&gt; semantics unnecessary and error-prone.  We can just
declare those variables at inner-most scope.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;  int b=1, c=2;
  #pragma omp parallel firstprivate(b) shared(c)
  {
    int a = 0;
    int id = omp_get_thread_num();
    a++;
    b++;
    c++;
    printf(&amp;quot;[%d] %d %d %d\n&amp;quot;, id, a, b, c);
  }
  printf(&amp;quot;END: %d %d %d\n&amp;quot;, a, b, c); // Error: a not in scope here
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;updating-shared-variables&#34;&gt;Updating shared variables&lt;/h3&gt;

&lt;p&gt;We see that the shared variable &lt;code&gt;c&lt;/code&gt; has lots of opportunities for conflict.&lt;/p&gt;

&lt;div class=&#34;mermaid&#34;&gt;
sequenceDiagram
Thread0--&gt;Memory: load c=2
Thread1--&gt;Memory: load c=2
Note left of Thread0: c++ (=3)
Note right of Thread1: c++ (=3)
Note right of Thread1: print c
Thread0--&gt;Memory: store c=3
Thread1--&gt;Memory: store c=3
Note left of Thread0: print c
&lt;/div&gt;

&lt;p&gt;If we run the above many times, we may sometimes find that multiple
processes have the same value of &lt;code&gt;c&lt;/code&gt;, each thread observes different
increments from others, and the total number of increments may vary.&lt;/p&gt;

&lt;p&gt;We can define ordering semantics using &lt;code&gt;atomic&lt;/code&gt;, &lt;code&gt;critical&lt;/code&gt;, and &lt;code&gt;barrier&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;  int b=1, c=2;
  #pragma omp parallel firstprivate(b) shared(c)
  {
    int a = 1;
    int id = omp_get_thread_num();
    b++;
    #pragma omp critical
    c++;
    #pragma omp barrier
    printf(&amp;quot;[%d] %d %d %d\n&amp;quot;, id, a, b, c);
  }
  printf(&amp;quot;END: _ %d %d\n&amp;quot;, b, c);
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;a-quick-demo-of-perf&#34;&gt;A quick demo of &lt;code&gt;perf&lt;/code&gt;&lt;/h2&gt;

&lt;p&gt;Linux &lt;code&gt;perf&lt;/code&gt; is a kernel interrupt-based profiling tool.  It uses
performance counters and interrupts to diagnose all sorts of
bottlenecks.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ perf stat ./dot -n 10000 &amp;gt; /dev/null

 Performance counter stats for &#39;./dot -n 10000&#39;:

              1.56 msec task-clock:u              #    1.201 CPUs utilized          
                 0      context-switches:u        #    0.000 K/sec                  
                 0      cpu-migrations:u          #    0.000 K/sec                  
               124      page-faults:u             #    0.079 M/sec                  
         3,041,706      cycles:u                  #    1.947 GHz                    
         2,272,231      instructions:u            #    0.75  insn per cycle         
           410,889      branches:u                #  262.962 M/sec                  
             7,911      branch-misses:u           #    1.93% of all branches        

       0.001301176 seconds time elapsed

       0.001970000 seconds user
       0.000000000 seconds sys
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ perf record -g ./dot -n 10000 -r 1000 &amp;gt; /dev/null
[ perf record: Woken up 1 times to write data ]
[ perf record: Captured and wrote 0.075 MB perf.data (1098 samples) ]
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;$ perf report -M intel
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;perf-report.png&#34; alt=&#34;perf report&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Note how GOMP overhead dominates the cost in this experiment.  We need
more work (longer arrays, etc.) to justify the overhead of
distributing and collecting the parallel work.&lt;/p&gt;

&lt;p&gt;We can drill down into particular functions (especially ours, which we
have hopefully compiled with &lt;code&gt;-g&lt;/code&gt; to include debugging information).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;perf-report-ann.png&#34; alt=&#34;perf report annotation&#34; /&gt;&lt;/p&gt;

&lt;p&gt;From this, we see specific instructions, and their corresponding lines
of code, that are most frequently being processed when the kernel
interrupts to check.  In this experiment, we see &lt;code&gt;*sd&lt;/code&gt; &amp;ldquo;scalar double&amp;rdquo;
instructions, indicating lack of vectorization.&lt;/p&gt;

&lt;p&gt;In contrast, the following annotation shows use of &lt;code&gt;*pd&lt;/code&gt; &amp;ldquo;packed
double&amp;rdquo; instructions, indicating that the &amp;ldquo;hot&amp;rdquo; loop has been
vectorized.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;perf-report-ann-vec.png&#34; alt=&#34;perf report annotation with vectorization&#34; /&gt;&lt;/p&gt;

&lt;p&gt;(The reason for vectorization can sometimes be determined by
&lt;code&gt;-fopt-info -fopt-info-missed&lt;/code&gt;, and can be encouraged by techniques
like manually splitting accumulators, preventing aliasing by using
&lt;code&gt;restrict&lt;/code&gt;, directives like &lt;code&gt;#pragma omp simd&lt;/code&gt;, and global compiler
flags like &lt;code&gt;-ffast-math&lt;/code&gt;.)&lt;/p&gt;

&lt;p&gt;For more on &lt;code&gt;perf&lt;/code&gt;, see &lt;a href=&#34;http://www.brendangregg.com/linuxperf.html&#34; target=&#34;_blank&#34;&gt;Brendan Gregg&amp;rsquo;s Linux Performance site&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>OpenMP Basics</title>
      <link>https://cucs-hpsc.github.io/fall2019/openmp/</link>
      <pubDate>Wed, 11 Sep 2019 06:49:25 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/openmp/</guid>
      <description>

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def render_c(filename):
    from IPython.display import Markdown
    with open(filename) as f:
        contents = f.read()
    return Markdown(&amp;quot;```c\n&amp;quot; + contents + &amp;quot;```\n&amp;quot;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;what-is-openmp-https-en-wikipedia-org-wiki-openmp&#34;&gt;What is &lt;a href=&#34;https://en.wikipedia.org/wiki/OpenMP&#34; target=&#34;_blank&#34;&gt;OpenMP&lt;/a&gt;?&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/f/f1/Fork_join.svg&#34; alt=&#34;By Wikipedia user A1 - w:en:File:Fork_join.svg, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=32004077&#34; /&gt;&lt;/p&gt;

&lt;p&gt;A community-developed standard Application Programming Interface (with &amp;ldquo;directives&amp;rdquo;) for
* multithreaded programming
* vectorization
* offload to coprocessors (such as GPUs)&lt;/p&gt;

&lt;p&gt;OpenMP is available for C, C++, and Fortran.&lt;/p&gt;

&lt;p&gt;Latest version: OpenMP-5.0, released November 2018.  Implementations are still incomplete!&lt;/p&gt;

&lt;h3 id=&#34;openmp-resources&#34;&gt;OpenMP Resources&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openmp.org/resources/refguides/&#34; target=&#34;_blank&#34;&gt;OpenMP-5.0 Reference Cards&lt;/a&gt; (a few pages, printable)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.openmp.org/spec-html/5.0/openmp.html&#34; target=&#34;_blank&#34;&gt;OpenMP-5.0 Standard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.openmp.org/wp-content/uploads/openmp-examples-4.5.0.pdf&#34; target=&#34;_blank&#34;&gt;OpenMP-4.5 Examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://computing.llnl.gov/tutorials/openMP/&#34; target=&#34;_blank&#34;&gt;LLNL Tutorial&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://press3.mcs.anl.gov//atpesc/files/2019/07/ATPESC_2019_Track-2_2_7-31_830am_Mattson-The-OpenMP_Common_Core.pdf&#34; target=&#34;_blank&#34;&gt;Mattson: The OpenMP Common Core&lt;/a&gt; from &lt;a href=&#34;https://extremecomputingtraining.anl.gov/&#34; target=&#34;_blank&#34;&gt;ATPESC&lt;/a&gt; (&lt;a href=&#34;https://www.youtube.com/watch?v=T0csnAirv-U&amp;amp;list=PLGj2a3KTwhRa6Ux64xg5L5ga6Jg8QykoQ&amp;amp;index=2&#34; target=&#34;_blank&#34;&gt;video&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;pragma-omp-parallel&#34;&gt;&lt;code&gt;#pragma omp parallel&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;The standard is &lt;strong&gt;big&lt;/strong&gt;, but most applications only use a few constructs.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;omp-hello.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;omp.h&amp;gt;
#include &amp;lt;stdio.h&amp;gt;

int main() {
  #pragma omp parallel
  {
    int num_threads = omp_get_num_threads();
    int my_thread_num = omp_get_thread_num();
    printf(&amp;quot;I am %d of %d\n&amp;quot;, my_thread_num, num_threads);
  }
  return 0;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-fopenmp -Wall&#39; -B omp-hello
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -fopenmp -Wall    omp-hello.c   -o omp-hello
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!./omp-hello
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;I am 1 of 4
I am 2 of 4
I am 0 of 4
I am 3 of 4
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=8 ./omp-hello
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;I am 0 of 8
I am 7 of 8
I am 1 of 8
I am 3 of 8
I am 4 of 8
I am 6 of 8
I am 2 of 8
I am 5 of 8
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;parallelizing-triad&#34;&gt;Parallelizing &lt;code&gt;triad&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void triad(int N, double *a, const double *b, double scalar, const double *c) {
#pragma omp parallel
    {
        for (int i=0; i&amp;lt;N; i++)
            a[i] = b[i] + scalar * c[i];
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;What does this code do?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void triad(int N, double *a, const double *b, double scalar, const double *c) {
#pragma omp parallel
    {
        int id = omp_get_thread_num();
        int num_threads = omp_get_num_threads();
        for (int i=id; i&amp;lt;N; i+=num_threads)
            a[i] = b[i] + scalar * c[i];
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;parallelizing-dot&#34;&gt;Parallelizing &lt;code&gt;dot&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;static double dot_ref(size_t n, const double *a, const double *b) {
  double sum = 0;
  for (size_t i=0; i&amp;lt;n; i++)
    sum += a[i] * b[i];
  return sum;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!make CFLAGS=&#39;-O3 -march=native -fopenmp&#39; -B dot
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;cc -O3 -march=native -fopenmp    dot.c   -o dot
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!OMP_NUM_THREADS=2 ./dot -r 10 -n 10000
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;  Name      flops   ticks   flops/tick
 dot_ref    20000   40327       0.50    
 dot_ref    20000   35717       0.56    
 dot_ref    20000   36096       0.55    
 dot_ref    20000   36487       0.55    
 dot_ref    20000   37157       0.54    
 dot_ref    20000   36024       0.56    
 dot_ref    20000   35322       0.57    
 dot_ref    20000   36601       0.55    
 dot_ref    20000   72193       0.28    
 dot_ref    20000   37924       0.53    
dot_opt1    20000   51256384        0.00    
dot_opt1    20000   23343145        0.00    
dot_opt1    20000   4646174     0.00    
dot_opt1    20000   16710       1.20    
dot_opt1    20000   15512       1.29    
dot_opt1    20000   16016       1.25    
dot_opt1    20000   16982       1.18    
dot_opt1    20000   452064      0.04    
dot_opt1    20000   16278       1.23    
dot_opt1    20000   16311       1.23    
dot_opt2    20000   24616       0.81    
dot_opt2    20000   16095       1.24    
dot_opt2    20000   17561       1.14    
dot_opt2    20000   16270       1.23    
dot_opt2    20000   18130       1.10    
dot_opt2    20000   16831       1.19    
dot_opt2    20000   16968       1.18    
dot_opt2    20000   16391       1.22    
dot_opt2    20000   17063       1.17    
dot_opt2    20000   16315       1.23    
dot_opt3    20000   77013       0.26    
dot_opt3    20000   12419       1.61    
dot_opt3    20000   12124       1.65    
dot_opt3    20000   12193       1.64    
dot_opt3    20000   12051       1.66    
dot_opt3    20000   12009       1.67    
dot_opt3    20000   11944       1.67    
dot_opt3    20000   12032       1.66    
dot_opt3    20000   12687       1.58    
dot_opt3    20000   12188       1.64    
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;vectorization&#34;&gt;Vectorization&lt;/h3&gt;

&lt;p&gt;OpenMP-4.0 added the &lt;code&gt;omp simd&lt;/code&gt; construct, which is a portable way to request that the compiler vectorize code.
An example of a reason why a compiler might fail to vectorize code is aliasing, which we investigate below.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;triad.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;#include &amp;lt;stdlib.h&amp;gt;

void triad(size_t N, double *a, const double *b, double scalar, const double *c) {
  for (size_t i=0; i&amp;lt;N; i++)
    a[i] = b[i] + scalar * c[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!gcc -O2 -ftree-vectorize -fopt-info-all -c triad.c
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Unit growth for small function inlining: 15-&amp;gt;15 (0%)

Inlined 0 calls, eliminated 0 functions

triad.c:4:3: optimized: loop vectorized using 16 byte vectors
triad.c:4:3: optimized:  loop versioned for vectorization because of possible aliasing
triad.c:3:6: note: vectorized 1 loops in function.
triad.c:4:3: optimized: loop turned into non-loop; it never loops
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;gcc autovectorization starts at &lt;code&gt;-O3&lt;/code&gt; or if you use &lt;code&gt;-ftree-vectorize&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;options such as &lt;a href=&#34;https://gcc.gnu.org/onlinedocs/gcc/Developer-Options.html#index-fopt-info&#34; target=&#34;_blank&#34;&gt;-fopt-info&lt;/a&gt; give useful diagnostics, but are compiler-dependent and sometimes referring to assembly is useful&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man gcc&lt;/code&gt; with search (&lt;code&gt;/&lt;/code&gt;) is your friend&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;what-is-aliasing&#34;&gt;What is aliasing?&lt;/h3&gt;

&lt;p&gt;Is this valid code?  What xs &lt;code&gt;x&lt;/code&gt; after this call?&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double x[5] = {1, 2, 3, 4, 5};
triad(2, x+1, x, 10., x);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;C allows memory to overlap arbitrarily.  You can inform the compiler of this using the &lt;a href=&#34;https://en.wikipedia.org/wiki/Restrict&#34; target=&#34;_blank&#34;&gt;&lt;code&gt;restrict&lt;/code&gt; qualifier&lt;/a&gt; (C99/C11; &lt;code&gt;__restrict&lt;/code&gt; or &lt;code&gt;__restrict__&lt;/code&gt; work with most C++ and &lt;a href=&#34;https://devblogs.nvidia.com/cuda-pro-tip-optimize-pointer-aliasing/&#34; target=&#34;_blank&#34;&gt;CUDA&lt;/a&gt; compilers).&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;triad-restrict.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void triad(int N, double *restrict a, const double *restrict b, double scalar, const double *restrict c) {
  for (int i=0; i&amp;lt;N; i++)
    a[i] = b[i] + scalar * c[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!gcc -O2 -march=native -ftree-vectorize -fopt-info-all -c triad-restrict.c
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Unit growth for small function inlining: 15-&amp;gt;15 (0%)

Inlined 0 calls, eliminated 0 functions

triad-restrict.c:2:5: optimized: loop vectorized using 32 byte vectors
triad-restrict.c:1:6: note: vectorized 1 loops in function.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Notice how there is no more &lt;code&gt;loop versioned for vectorization because of possible aliasing&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;The complexity of checking for aliasing can grow combinatorially in the number of arrays being processed, leading to many loop variants and/or preventing vectorization.&lt;/p&gt;

&lt;h4 id=&#34;aside-warnings&#34;&gt;Aside: Warnings&lt;/h4&gt;

&lt;p&gt;The &lt;code&gt;-Wrestrict&lt;/code&gt; flag (included in &lt;code&gt;-Wall&lt;/code&gt;) can catch some programming errors&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void foo(double *x) {
  triad(2, x, x, 10, x);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!gcc -O2 -Wall -c triad-foo.c
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The powers of &lt;code&gt;-Wrestrict&lt;/code&gt; are limited, however, and (as of gcc-9) do not even catch&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void foo(double *x) {
  triad(2, x+1, x, 10, x);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;check-the-assembly&#34;&gt;Check the assembly&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!objdump -d --prefix-addresses -M intel triad-restrict.o
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;triad-restrict.o:     file format elf64-x86-64


Disassembly of section .text:
0000000000000000 &amp;lt;triad&amp;gt; test   edi,edi
0000000000000002 &amp;lt;triad+0x2&amp;gt; jle    0000000000000067 &amp;lt;triad+0x67&amp;gt;
0000000000000004 &amp;lt;triad+0x4&amp;gt; lea    eax,[rdi-0x1]
0000000000000007 &amp;lt;triad+0x7&amp;gt; cmp    eax,0x2
000000000000000a &amp;lt;triad+0xa&amp;gt; jbe    0000000000000074 &amp;lt;triad+0x74&amp;gt;
000000000000000c &amp;lt;triad+0xc&amp;gt; mov    r8d,edi
000000000000000f &amp;lt;triad+0xf&amp;gt; shr    r8d,0x2
0000000000000013 &amp;lt;triad+0x13&amp;gt; vbroadcastsd ymm2,xmm0
0000000000000018 &amp;lt;triad+0x18&amp;gt; shl    r8,0x5
000000000000001c &amp;lt;triad+0x1c&amp;gt; xor    eax,eax
000000000000001e &amp;lt;triad+0x1e&amp;gt; xchg   ax,ax
0000000000000020 &amp;lt;triad+0x20&amp;gt; vmovupd ymm1,YMMWORD PTR [rcx+rax*1]
0000000000000025 &amp;lt;triad+0x25&amp;gt; vfmadd213pd ymm1,ymm2,YMMWORD PTR [rdx+rax*1]
000000000000002b &amp;lt;triad+0x2b&amp;gt; vmovupd YMMWORD PTR [rsi+rax*1],ymm1
0000000000000030 &amp;lt;triad+0x30&amp;gt; add    rax,0x20
0000000000000034 &amp;lt;triad+0x34&amp;gt; cmp    rax,r8
0000000000000037 &amp;lt;triad+0x37&amp;gt; jne    0000000000000020 &amp;lt;triad+0x20&amp;gt;
0000000000000039 &amp;lt;triad+0x39&amp;gt; mov    eax,edi
000000000000003b &amp;lt;triad+0x3b&amp;gt; and    eax,0xfffffffc
000000000000003e &amp;lt;triad+0x3e&amp;gt; test   dil,0x3
0000000000000042 &amp;lt;triad+0x42&amp;gt; je     0000000000000070 &amp;lt;triad+0x70&amp;gt;
0000000000000044 &amp;lt;triad+0x44&amp;gt; vzeroupper 
0000000000000047 &amp;lt;triad+0x47&amp;gt; cdqe   
0000000000000049 &amp;lt;triad+0x49&amp;gt; nop    DWORD PTR [rax+0x0]
0000000000000050 &amp;lt;triad+0x50&amp;gt; vmovsd xmm1,QWORD PTR [rcx+rax*8]
0000000000000055 &amp;lt;triad+0x55&amp;gt; vfmadd213sd xmm1,xmm0,QWORD PTR [rdx+rax*8]
000000000000005b &amp;lt;triad+0x5b&amp;gt; vmovsd QWORD PTR [rsi+rax*8],xmm1
0000000000000060 &amp;lt;triad+0x60&amp;gt; inc    rax
0000000000000063 &amp;lt;triad+0x63&amp;gt; cmp    edi,eax
0000000000000065 &amp;lt;triad+0x65&amp;gt; jg     0000000000000050 &amp;lt;triad+0x50&amp;gt;
0000000000000067 &amp;lt;triad+0x67&amp;gt; ret    
0000000000000068 &amp;lt;triad+0x68&amp;gt; nop    DWORD PTR [rax+rax*1+0x0]
0000000000000070 &amp;lt;triad+0x70&amp;gt; vzeroupper 
0000000000000073 &amp;lt;triad+0x73&amp;gt; ret    
0000000000000074 &amp;lt;triad+0x74&amp;gt; xor    eax,eax
0000000000000076 &amp;lt;triad+0x76&amp;gt; jmp    0000000000000047 &amp;lt;triad+0x47&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;How do the results change if you go up and replace &lt;code&gt;-march=native&lt;/code&gt; with &lt;code&gt;-march=skylake-avx512 -mprefer-vector-width=512&lt;/code&gt;?&lt;/li&gt;
&lt;li&gt;Is the assembly qualitatively different without &lt;code&gt;restrict&lt;/code&gt; (in which case the compiler &amp;ldquo;versions&amp;rdquo; the loop).&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;pragma-omp-simd&#34;&gt;Pragma &lt;code&gt;omp simd&lt;/code&gt;&lt;/h3&gt;

&lt;p&gt;An alternative (or supplement) to &lt;code&gt;restrict&lt;/code&gt; is &lt;code&gt;#pragma omp simd&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;render_c(&#39;triad-omp-simd.c&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;void triad(int N, double *a, const double *b, double scalar, const double *c) {
#pragma omp simd
  for (int i=0; i&amp;lt;N; i++)
    a[i] = b[i] + scalar * c[i];
}
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!gcc -O2 -march=native -ftree-vectorize -fopenmp -fopt-info-all -c triad-omp-simd.c
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;Unit growth for small function inlining: 15-&amp;gt;15 (0%)

Inlined 0 calls, eliminated 0 functions

triad-omp-simd.c:4:17: optimized: loop vectorized using 32 byte vectors
triad-omp-simd.c:1:6: note: vectorized 1 loops in function.
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Parallel Scaling</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-parallel-scaling/</link>
      <pubDate>Fri, 06 Sep 2019 08:07:31 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-parallel-scaling/</guid>
      <description>

&lt;h2 id=&#34;programs-with-more-than-one-part&#34;&gt;Programs with more than one part&lt;/h2&gt;

&lt;p&gt;So far, we&amp;rsquo;ve focused on simple programs with only one part, but real programs have several different parts, often with data dependencies.
Some parts will be amenable to optimization and/or parallelism and others will not.
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Optimizing-different-parts.svg/2880px-Optimizing-different-parts.svg.png&#34; alt=&#34;Diminishing returns&#34; /&gt;
This principle is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34; target=&#34;_blank&#34;&gt;Amdahl&amp;rsquo;s Law&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_time(f, p, n=10, latency=1):
    # Suppose that a fraction f of the total work is amenable to optimization
    # We run a problem size n with parallelization factor p
    return latency + (1-f)*n + f*n/p
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import pandas
import numpy as np
plt.style.use(&#39;seaborn&#39;)

ps = np.geomspace(1, 1000)

plt.loglog(ps, exec_time(.99, ps, latency=0))
plt.loglog(ps, exec_time(1, ps, latency=0))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;time&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;strong-scaling-fixed-total-problem-size&#34;&gt;Strong scaling: fixed total problem size&lt;/h2&gt;

&lt;h3 id=&#34;cost-time-p&#34;&gt;Cost = &lt;code&gt;time * p&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_cost(f, p, **kwargs):
    return exec_time(f, p, **kwargs) * p

plt.loglog(ps, exec_cost(.99, ps))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;cost&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_4_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;efficiency&#34;&gt;Efficiency&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.semilogx(ps, 1/exec_cost(.99, ps, latency=1))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_6_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;speedup&#34;&gt;Speedup&lt;/h3&gt;

&lt;p&gt;$$ S(p) = \frac{T(1)}{T(p)} $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.plot(ps, exec_time(.99, 1, latency=1) / exec_time(.99, ps, latency=1))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;speedup&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stunt-1-report-speedup-not-absolute-performance&#34;&gt;Stunt 1: Report speedup, not absolute performance!&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;stunt1.jpg&#34; alt=&#34;Hager&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;efficiency-time-spectrum-my-preference&#34;&gt;Efficiency-Time spectrum (my preference)&lt;/h2&gt;

&lt;p&gt;People care about two observable properties
* &lt;strong&gt;Time&lt;/strong&gt; until job completes
* &lt;strong&gt;Cost&lt;/strong&gt; in core-hours or dollars to do job&lt;/p&gt;

&lt;p&gt;Most HPC applications have access to large machines, so don&amp;rsquo;t really care how many processes they use for any given job.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.plot(exec_time(.99, ps), 1/exec_cost(.99, ps), &#39;o-&#39;)
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;time&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
plt.xlim(left=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_11_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;principles&#34;&gt;Principles&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/archives/5835&#34; target=&#34;_blank&#34;&gt;No &amp;ldquo;soft&amp;rdquo; &lt;code&gt;log&lt;/code&gt; scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Both axes have tangible units&lt;/li&gt;
&lt;li&gt;Bigger is better on the $y$ axis&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;weak-scaling-fixed-work-per-processor&#34;&gt;Weak Scaling: Fixed work per processor&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve kept the problem size $n$ fixed thus far, but parallel computers are also used to solve large problems.  If we keep the amount of work per processor fixed, we are &lt;a href=&#34;https://en.wikipedia.org/wiki/Gustafson&#39;s_law&#34; target=&#34;_blank&#34;&gt;weak/Gustafson scaling&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ns = 10*ps
plt.semilogx(ps, ns/exec_cost(.99, ps, n=ns, latency=1), &#39;o-&#39;)
ns = 100*ps
plt.semilogx(ps, ns/exec_cost(.99, ps, n=ns, latency=1), &#39;s-&#39;)
plt.title(&#39;Weak scaling&#39;)
plt.xlabel(&#39;procs&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_14_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for w in np.geomspace(0.1, 1e3, 20):
    ns = w*ps
    plt.semilogx(exec_time(.99, ps, n=ns, latency=1),
                 ns/exec_cost(.99, ps, n=ns, latency=1), &#39;o-&#39;)
plt.title(&#39;Weak scaling&#39;)
plt.xlabel(&#39;time&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_15_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;fuhrer-et-al-2018-near-global-climate-simulation-at-1-km-resolution-https-www-geosci-model-dev-net-11-1665-2018-gmd-11-1665-2018-pdf&#34;&gt;&lt;a href=&#34;https://www.geosci-model-dev.net/11/1665/2018/gmd-11-1665-2018.pdf&#34; target=&#34;_blank&#34;&gt;Fuhrer et al (2018): Near-global climate simulation at 1 km resolution&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;fuhrer2018-fig4.png&#34; alt=&#34;Fuhrer (2018)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I replotted these data for &lt;a href=&#34;https://jedbrown.org/files/20190822-Latsis.pdf&#34; target=&#34;_blank&#34;&gt;my talk&lt;/a&gt; at the &lt;a href=&#34;https://latsis2019.ethz.ch/&#34; target=&#34;_blank&#34;&gt;Latsis Symposium&lt;/a&gt; last month.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;fuhrer2018-scaling-time-ann4.png&#34; alt=&#34;Fuhrer (2018) replotted&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;further-resources&#34;&gt;Further resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/archives/5260&#34; target=&#34;_blank&#34;&gt;Hager: Fooling the masses&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Learn by counter-examples&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://htor.inf.ethz.ch/publications/index.php?pub=222&#34; target=&#34;_blank&#34;&gt;Hoefler and Belli: Scientific Benchmarking of Parallel Computing Systems&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Recommended best practices, especially for dealing with performance variability&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please read/watch something from this list and be prepared to share on Monday.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Performance Modeling</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-modeling/</link>
      <pubDate>Wed, 04 Sep 2019 09:17:28 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-modeling/</guid>
      <description>

&lt;h2 id=&#34;why-model-performance&#34;&gt;Why model performance?&lt;/h2&gt;

&lt;p&gt;Models give is a conceptual and roughly quantitative framework by which to answer the following types of questions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why is an implementation exhibiting its observed performance?&lt;/li&gt;
&lt;li&gt;How will performance change if we:

&lt;ul&gt;
&lt;li&gt;optimize this component?&lt;/li&gt;
&lt;li&gt;buy new hardware? (Which new hardware?)&lt;/li&gt;
&lt;li&gt;run a different configuration?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;While conceptualizing a new algorithm, what performance can we expect and what will be bottlenecks?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Models are a guide for performance, but not an absolute.&lt;/p&gt;

&lt;h3 id=&#34;terms&#34;&gt;Terms&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Symbol&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$n$&lt;/td&gt;
&lt;td&gt;Input parameter related to problem size&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$W$&lt;/td&gt;
&lt;td&gt;Amount of work to solve problem $n$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T$&lt;/td&gt;
&lt;td&gt;Execution time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$R$&lt;/td&gt;
&lt;td&gt;Rate at which work is done&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;stream-triad&#34;&gt;STREAM Triad&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (i=0; i&amp;lt;n; i++)
    a[i] = b[i] + scalar*c[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$n$ is the array size and
$$W = 3 \cdot \texttt{sizeof(double)} \cdot n$$
is the number of bytes transferred.  The rate $R = W/T$ is measured in bytes per second (or MB/s, etc.).&lt;/p&gt;

&lt;h4 id=&#34;dense-matrix-multiplication&#34;&gt;Dense matrix multiplication&lt;/h4&gt;

&lt;p&gt;To perform the operation $C \gets C + A B$ where $A,B,C$ are $n\times n$ matrices.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (i=0; i&amp;lt;n; i++)
    for (j=0; j&amp;lt;n; j++)
        for (k=0; k&amp;lt;n; k++)
            c[i*n+j] += a[i*n+k] * b[k*n+j];
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can you identify two expressions for the total amount of work $W(n)$ and the associated units?&lt;/li&gt;
&lt;li&gt;Can you think of a context in which one is better than the other and vice-versa?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;estimating-time&#34;&gt;Estimating time&lt;/h3&gt;

&lt;p&gt;To estimate time, we need to know how fast hardware executes flops and moves bytes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import pandas
import numpy as np
plt.style.use(&#39;seaborn&#39;)

hardware = pandas.read_csv(&#39;data-intel.csv&#39;, index_col=&amp;quot;Name&amp;quot;)
hardware
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;GFLOPs-SP&lt;/th&gt;
      &lt;th&gt;GFLOPs-DP&lt;/th&gt;
      &lt;th&gt;Cores&lt;/th&gt;
      &lt;th&gt;Mem-GBps&lt;/th&gt;
      &lt;th&gt;TDP&lt;/th&gt;
      &lt;th&gt;Freq(MHz)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5482&lt;/th&gt;
      &lt;td&gt;2007&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5492&lt;/th&gt;
      &lt;td&gt;2008&lt;/td&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon W5590&lt;/th&gt;
      &lt;td&gt;2009&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5680&lt;/th&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5690&lt;/th&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3470&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2690&lt;/th&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;2900&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2697 v2&lt;/th&gt;
      &lt;td&gt;2013&lt;/td&gt;
      &lt;td&gt;518&lt;/td&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;2700&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v3&lt;/th&gt;
      &lt;td&gt;2014&lt;/td&gt;
      &lt;td&gt;1324&lt;/td&gt;
      &lt;td&gt;662&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v3&lt;/th&gt;
      &lt;td&gt;2015&lt;/td&gt;
      &lt;td&gt;1324&lt;/td&gt;
      &lt;td&gt;662&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v4&lt;/th&gt;
      &lt;td&gt;2016&lt;/td&gt;
      &lt;td&gt;1548&lt;/td&gt;
      &lt;td&gt;774&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon Platinum 8180&lt;/th&gt;
      &lt;td&gt;2017&lt;/td&gt;
      &lt;td&gt;4480&lt;/td&gt;
      &lt;td&gt;2240&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;205&lt;/td&gt;
      &lt;td&gt;2500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon Platinum 9282&lt;/th&gt;
      &lt;td&gt;2018&lt;/td&gt;
      &lt;td&gt;9320&lt;/td&gt;
      &lt;td&gt;4660&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;2600&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = hardware.plot(x=&#39;GFLOPs-DP&#39;, y=&#39;Mem-GBps&#39;, marker=&#39;o&#39;)
fig.set_xlim(left=0)
fig.set_ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So we have rates $R_f = 4660 \cdot 10^9$ flops/second and $R_m = 175 \cdot 10^9$ bytes/second.  Now we need to characterize some algorithms.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;algs = pandas.read_csv(&#39;algs.csv&#39;, index_col=&#39;Name&#39;)
algs[&#39;intensity&#39;] = algs[&#39;flops&#39;] / algs[&#39;bytes&#39;]
algs = algs.sort_values(&#39;intensity&#39;)
algs
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;bytes&lt;/th&gt;
      &lt;th&gt;flops&lt;/th&gt;
      &lt;th&gt;intensity&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Triad&lt;/th&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.083333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;SpMV&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stencil27-cache&lt;/th&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;2.250000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MatFree-FEM&lt;/th&gt;
      &lt;td&gt;2376&lt;/td&gt;
      &lt;td&gt;15228&lt;/td&gt;
      &lt;td&gt;6.409091&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stencil27-ideal&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;6.750000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_time(machine, alg, n):
    bytes = n * alg.bytes
    flops = n * alg.flops
    T_mem = bytes / (machine[&#39;Mem-GBps&#39;] * 1e9)
    T_flops = flops / (machine[&#39;GFLOPs-DP&#39;] * 1e9)
    return max(T_mem, T_flops)
    
exec_time(hardware.loc[&#39;Xeon Platinum 9282&#39;], algs.loc[&#39;SpMV&#39;], 1e8)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.006857142857142857
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for _, machine in hardware.iterrows():
    for _, alg in algs.iterrows():
        ns = np.geomspace(1e4, 1e9, 10)
        times = np.array([exec_time(machine, alg, n) for n in ns])
        flops = np.array([alg.flops * n for n in ns])
        rates = flops/times
        plt.loglog(ns, rates, &#39;o-&#39;)
plt.xlabel(&#39;n&#39;)
plt.ylabel(&#39;rate&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_6_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It looks like performance does not depend on problem size.&lt;/p&gt;

&lt;p&gt;Well, yeah, we chose a model in which flops and bytes were both proportional to $n$, and our machine model has no sense of cache hierarchy or latency, so time is also proportional to $n$.  We can divide through by $n$ and yield a more illuminating plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for _, machine in hardware.iterrows():
    times = np.array([exec_time(machine, alg, 1) 
                      for _, alg in algs.iterrows()])
    rates = algs.flops/times
    intensities = algs.intensity
    plt.loglog(intensities, rates, &#39;o-&#39;, label=machine.name)
plt.xlabel(&#39;intensity&#39;)
plt.ylabel(&#39;rate&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re seeing the &amp;ldquo;roofline&amp;rdquo; for the older processors while the newer models are memory bandwidth limited for all of these algorithms.&lt;/p&gt;

&lt;h3 id=&#34;recommended-reading-on-single-node-performance-modeling&#34;&gt;Recommended reading on single-node performance modeling&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1145/1498765.1498785&#34; target=&#34;_blank&#34;&gt;Williams, Waterman, Patterson (2009): &lt;strong&gt;Roofline: An insightful visual performance model for multicore architectures&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Vectorization and Instruction-Level Parallelism</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-vectorization/</link>
      <pubDate>Fri, 30 Aug 2019 11:00:00 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-vectorization/</guid>
      <description>

&lt;p&gt;Remember how single-thread performance has increased significantly
since ~2004 when clock frequency stagnated?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.karlrupp.net/wp-content/uploads/2018/02/42-years-processor-trend.png&#34; alt=&#34;42 years of microprocessor data&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is a result of doing more per clock cycle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.karlrupp.net/wp-content/uploads/2013/06/flops-per-cycle-sp.png&#34; alt=&#34;Flops per clock cycle&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s visit some slides:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://moodle.rrze.uni-erlangen.de/pluginfile.php/12916/mod_resource/content/6/01_IntroArchitecture.pdf&#34; target=&#34;_blank&#34;&gt;Georg Hager (2019): Modern Computer Architucture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://software.intel.com/sites/landingpage/IntrinsicsGuide/#&#34; target=&#34;_blank&#34;&gt;Intel Intrinsics Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wikichip

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake&#34; target=&#34;_blank&#34;&gt;Intel Xeon: Cascade Lake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/amd/cores/rome&#34; target=&#34;_blank&#34;&gt;AMD EPYC gen2: Rome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/ibm/microarchitectures/power9&#34; target=&#34;_blank&#34;&gt;IBM POWER9&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.agner.org/optimize/&#34; target=&#34;_blank&#34;&gt;Agner Fog&amp;rsquo;s website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Architecture</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-architecture/</link>
      <pubDate>Wed, 28 Aug 2019 08:10:18 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-architecture/</guid>
      <description>

&lt;h1 id=&#34;cores-caches-and-memory&#34;&gt;Cores, caches, and memory&lt;/h1&gt;

&lt;h3 id=&#34;a-von-neumann-architecture-https-en-wikipedia-org-wiki-von-neumann-architecture&#34;&gt;A &lt;a href=&#34;https://en.wikipedia.org/wiki/Von_Neumann_architecture&#34; target=&#34;_blank&#34;&gt;von Neumann Architecture&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Von_Neumann_Architecture.svg/2880px-Von_Neumann_Architecture.svg.png&#34; alt=&#34;von Neumann architecture&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-contemporary-architecture&#34;&gt;A contemporary architecture&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/physicalMemoryAccess.png&#34; alt=&#34;Core 2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;my-laptop&#34;&gt;My laptop&lt;/h3&gt;

&lt;p&gt;We can get this kind of information for our machine using &lt;a href=&#34;https://www.open-mpi.org/projects/hwloc/&#34; target=&#34;_blank&#34;&gt;hwloc&lt;/a&gt;, which provides a library as well as the command-line tool &lt;code&gt;lstopo&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!lstopo --output-format svg &amp;gt; lstopo-local.svg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;lstopo-local.svg&#34; alt=&#34;lstopo&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-double-socket-compute-node-with-two-gpus&#34;&gt;A double-socket compute node with two GPUs&lt;/h3&gt;

&lt;p&gt;2x Xeon Ivy-Bridge-EP &lt;a href=&#34;https://ark.intel.com/content/www/us/en/ark/products/75277/intel-xeon-processor-e5-2680-v2-25m-cache-2-80-ghz.html&#34; target=&#34;_blank&#34;&gt;E5-2680v2&lt;/a&gt; + 2x NVIDIA GPUs (from 2013, with hwloc v1.11).
GPUs are reported as CUDA devices and X11 display :1.0: (from the &lt;a href=&#34;https://www-lb.open-mpi.org/projects/hwloc/lstopo/&#34; target=&#34;_blank&#34;&gt;hwloc gallery&lt;/a&gt;)
&lt;img src=&#34;https://www-lb.open-mpi.org/projects/hwloc/lstopo/images/2XeonE5v2+2cuda+1display_v1.11.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;block-diagrams&#34;&gt;Block diagrams&lt;/h3&gt;

&lt;p&gt;A block diagram from a vendor can include additional information about how cores are physically connected.&lt;/p&gt;

&lt;h4 id=&#34;ring-bus-xeon-e5-2600-family&#34;&gt;Ring bus (Xeon E5-2600 family)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/e3/a4/xeon-processor-scalable-family-tech-overview-fig04.png&#34; alt=&#34;Intel Xeon E5-2600&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;mesh-bus-xeon-scalable-family&#34;&gt;Mesh bus (Xeon Scalable family)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/5a/03/xeon-processor-scalable-family-tech-overview-fig05.png&#34; alt=&#34;Intel Xeon Scalable&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;multi-socket-configurations&#34;&gt;Multi-socket configurations&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/77/f2/xeon-processor-scalable-family-tech-overview-fig07.png&#34; alt=&#34;4-socket ring&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview&#34; target=&#34;_blank&#34;&gt;https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;multiple-nodes-go-into-racks-or-cabinets&#34;&gt;Multiple nodes go into &lt;strong&gt;racks&lt;/strong&gt; or &lt;strong&gt;cabinets&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;BlueGenePRacks.png&#34; alt=&#34;Blue Gene/P Racks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.olcf.ornl.gov/wp-content/uploads/2018/06/summit-1.jpg&#34; alt=&#34;OLCF Summit&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;terminology&#34;&gt;Terminology&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt; (virtual and physical): has a single program counter (logically sequential processing of instructions)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory channel&lt;/strong&gt;: e.g., DDR4-2400: transfers 64 bits (8 bytes) at a rate of 2400 MHz = 15.36 GB/s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socket&lt;/strong&gt; or &lt;strong&gt;CPU&lt;/strong&gt;: contains multiple cores in a single piece* of silicon&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-Uniform Memory Access (NUMA)&lt;/strong&gt;: different channels may be different distances from a core&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compute node&lt;/strong&gt;: one or more sockets, plus memory, network card, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-expensive-is-it-to-access-memory&#34;&gt;How expensive is it to access memory?&lt;/h3&gt;

&lt;p&gt;What does that mean?  How would we measure?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.rdrop.com/~paulmck/RCU/RCU.2013.01.22d.PLMW.pdf&#34; target=&#34;_blank&#34;&gt;McKenney (2013): Laws of Physics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#34; target=&#34;_blank&#34;&gt;Interactive&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.anandtech.com/show/14694/amd-rome-epyc-2nd-gen/7&#34; target=&#34;_blank&#34;&gt;Variation by vendor&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;how-your-program-accesses-memory&#34;&gt;How your program accesses memory&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double a[1000];

void foo() {
    for (int i=0; i&amp;lt;1000; i++)
        a[i] = 1.234 * i;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The compiler turns the loop body into instructions, which we can examine using &lt;a href=&#34;https://gcc.godbolt.org/z/gbhuZR&#34; target=&#34;_blank&#34;&gt;Godbolt&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pxor xmm0, xmm0                  ; zero the xmm0 register
cvtsi2sd xmm0, eax               ; convert the integer i to double
mulsd xmm0, xmm1                 ; multiply by 1.234 (held in xmm1)
movsd QWORD PTR a[0+rax*8], xmm0 ; store to memory address a[i]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Only one instruction here accesses memory, and the performance will be affected greatly by where that memory resides (which level of cache, where in DRAM).&lt;/p&gt;

&lt;p&gt;Most architectures today have &lt;strong&gt;64-byte cache lines&lt;/strong&gt;: all transfers from main memory (DRAM) to and from cache operate in units of 64 bytes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/L1CacheExample.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;let-s-compare-three-code-samples&#34;&gt;Let&amp;rsquo;s compare three code samples&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[(i*8) % N];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[random() % N];
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;what-happens-when-you-request-a-cache-line&#34;&gt;What happens when you request a cache line?&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/memoryRead.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;operating-system-effects&#34;&gt;Operating system effects&lt;/h2&gt;

&lt;p&gt;Most systems today use virtual addressing, so every address in your program needs to be translated to a physical address before looking for it (in cache or memory).  Fortunately, there is hardware to assist with this: the Translation Lookaside Buffer (TLB).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://drawings.jvns.ca/drawings/pagetable.svg&#34; alt=&#34;Virtual memory and the page table&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jvns.ca/blog/2016/12/03/how-much-memory-is-my-process-using-/&#34; target=&#34;_blank&#34;&gt;Julia Evans (2016): How much memory is my process using?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://manybutfinite.com/post/intel-cpu-caches/&#34; target=&#34;_blank&#34;&gt;Gustavo Duarte (2009): Cache: a place for concealment and safekeeping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://manybutfinite.com/post/getting-physical-with-memory/&#34; target=&#34;_blank&#34;&gt;Gustavo Duarte (2009): Getting Physical With Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.akkadia.org/drepper/cpumemory.pdf&#34; target=&#34;_blank&#34;&gt;Ulrich Drepper (2007): What Every Programmer Should Know About Memory&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Trends</title>
      <link>https://cucs-hpsc.github.io/fall2019/trends/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/trends/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/&#34; target=&#34;_blank&#34;&gt;https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/&#34; target=&#34;_blank&#34;&gt;https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Fischer2015-Latency.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
