<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Logistics | HPSC</title>
    <link>https://cucs-hpsc.github.io/fall2019/</link>
      <atom:link href="https://cucs-hpsc.github.io/fall2019/index.xml" rel="self" type="application/rss+xml" />
    <description>Logistics</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language>
    <image>
      <url>https://cucs-hpsc.github.io/img/icon-192.png</url>
      <title>Logistics</title>
      <link>https://cucs-hpsc.github.io/fall2019/</link>
    </image>
    
    <item>
      <title>Syllabus</title>
      <link>https://cucs-hpsc.github.io/fall2019/syllabus/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/syllabus/</guid>
      <description>

&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;

&lt;p&gt;This course will develop the skills necessary to reason about
performance of applications and modern architectures, to identify
opportunities and side-effects of changes, to develop high-performance
software, to transfer algorithmic patterns and lessons learned from
different domains, and to communicate such analyses with diverse
stakeholders.  These skills are important for research and development
of numerical methods and performance-sensitive science and engineering
applications, obtaining allocations via NSF&amp;rsquo;s
&lt;a href=&#34;https://www.xsede.org/&#34; target=&#34;_blank&#34;&gt;XSEDE&lt;/a&gt; and DOE &lt;a href=&#34;https://science.osti.gov/ascr/Facilities/Accessing-ASCR-Facilities&#34; target=&#34;_blank&#34;&gt;ASCR
facilities&lt;/a&gt;,
as well as in jobs affiliated with computing facilities at &lt;a href=&#34;https://www.alcf.anl.gov/about/careers&#34; target=&#34;_blank&#34;&gt;national
labs&lt;/a&gt;, industry, and academia.&lt;/p&gt;

&lt;p&gt;We will introduce widely-used parallel programming models such as
OpenMP, MPI, and CUDA, as well as ubiquitous parallel libraries, but
the purpose of the course is not to teach interfaces, but to develop
skills that will be durable and transferrable.&lt;/p&gt;

&lt;h2 id=&#34;preparation&#34;&gt;Preparation&lt;/h2&gt;

&lt;p&gt;This course does not assume prior experience with parallel
programming.  It will use Linux command-line tools, and some
activities will involve batch computing environments (SLURM).  Most
exercises will use the C programming language, though you can use any
appropriate language for projects.  Some of the exercises will involve
techniques from numerical computing (e.g., CSCI-3656).  I will do my
best to avoid assuming prior knowledge of these topics, and to provide
resources for you to learn or refresh your memory as we use them.&lt;/p&gt;

&lt;p&gt;Everyone here is capable of succeeding in the course, but the effort
level will be higher if most of the topics above are new to you.
Regardless of your preparation, it is normal to feel lost sometimes.
A big part of pragmatic HPC is learning to efficiently answer your
questions through documentation, online resources, and even consulting
the code or running experiments.  (Most of our software stack is open
source.)  That said, it&amp;rsquo;s easy to lose lots of time in a rabbit hole.
My hope is that you will have the courage to dive into that rabbit
hole occasionally, but also to &lt;a href=&#34;https://jvns.ca/blog/good-questions/&#34; target=&#34;_blank&#34;&gt;ask questions&lt;/a&gt; when stuck and to budget
your time for such excursions so that you can complete assignments
on-time without compromising your work/life balance.&lt;/p&gt;

&lt;h2 id=&#34;approximate-timeline&#34;&gt;Approximate timeline&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Week&lt;/th&gt;
&lt;th&gt;Topics&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Aug 26&lt;/td&gt;
&lt;td&gt;Introduction and modern computer architecture (vectorization and memory hierarchy)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 2&lt;/td&gt;
&lt;td&gt;Performance modeling, analysis, and scaling; profiling&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 9&lt;/td&gt;
&lt;td&gt;Intro to OpenMP and non-numerical algorithms (sorting and searching)&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 16&lt;/td&gt;
&lt;td&gt;Parallel algorithmic patterns&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 23&lt;/td&gt;
&lt;td&gt;Dense linear algebra&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Sep 30&lt;/td&gt;
&lt;td&gt;Intro to MPI and distributed memory parallelism&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 7&lt;/td&gt;
&lt;td&gt;Sparse and iterative linear algebra&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 14&lt;/td&gt;
&lt;td&gt;Domain decomposition&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 21&lt;/td&gt;
&lt;td&gt;Graph algorithms&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Oct 28&lt;/td&gt;
&lt;td&gt;GPU programming via OpenMP-5 and CUDA&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 4&lt;/td&gt;
&lt;td&gt;Parallel file systems and IO&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 11&lt;/td&gt;
&lt;td&gt;Data analysis/machine learning algorithms and dynamic cloud environments&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 18&lt;/td&gt;
&lt;td&gt;Particles and N-body systems&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Nov 25&lt;/td&gt;
&lt;td&gt;Fall Break&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Dec 2&lt;/td&gt;
&lt;td&gt;Multigrid, FFT, and FMM&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Dec 9&lt;/td&gt;
&lt;td&gt;Special topics&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;evaluation&#34;&gt;Evaluation&lt;/h2&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Activity&lt;/th&gt;
&lt;th&gt;Percentage&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;Participation&lt;/td&gt;
&lt;td&gt;10%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Labs and homework assignments&lt;/td&gt;
&lt;td&gt;40%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Community contribution&lt;/td&gt;
&lt;td&gt;15%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Community analysis&lt;/td&gt;
&lt;td&gt;15%&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;Final project (written + presentation)&lt;/td&gt;
&lt;td&gt;20%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&#34;git-and-github&#34;&gt;Git and GitHub&lt;/h3&gt;

&lt;p&gt;Homework assignments and in-class activities will be submitted via Git.  This class will use GitHub classroom.
Homeworks will be completed by cloning GitHub repositories, completing coding and analysis activities, and pushing completed assignments back to GitHub.&lt;/p&gt;

&lt;p&gt;Assignments may be completed using &lt;a href=&#34;https://coding.csel.io/&#34; target=&#34;_blank&#34;&gt;Coding CSEL Hub&lt;/a&gt; and/or &lt;a href=&#34;https://www.colorado.edu/rc/resources/summit/specifications&#34; target=&#34;_blank&#34;&gt;RMACC Summit&lt;/a&gt; (&lt;a href=&#34;https://rcamp.rc.colorado.edu/accounts/account-request/create/organization&#34; target=&#34;_blank&#34;&gt;request an account&lt;/a&gt;).
Assignments will typically have written analysis, for which I recommend &lt;a href=&#34;https://jupyter.org/&#34; target=&#34;_blank&#34;&gt;Jupyter&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;It is notoriously difficult to predict the time required to develop
quality code and understand its performance, so please start early to
give yourself plenty of time.  You are welcome to work together on all
assignments, but must acknowledge collaborators.  You should ensure
that your written work is entirely your own.&lt;/p&gt;

&lt;h3 id=&#34;community-contributions-and-analysis&#34;&gt;Community contributions and analysis&lt;/h3&gt;

&lt;p&gt;Over the course of the semester, you will follow the development
activities of an active open source project of your choosing.  This
should be a project with an active developer community from multiple
institutions that discuss their rationale in public, such as a mailing
list and/or GitHub/GitLab issues and pull requests.  You will write
and present about the performance and capability needs of key
stakeholders, the way project resources are allocated, their metrics
for success, and any notable achievements made over the course of the
semester.&lt;/p&gt;

&lt;p&gt;You will also make a contribution to be merged by the project.  Adding
new examples and/or improving documentation are extremely valuable
contributions, but you may also add features or improve
implementations.  Please respect the time of project maintainers and
reviewers by learning about the project and its expectations and
process, communicating in advance if appropriate, and leaving plenty
of time for multiple rounds of review and revision.&lt;/p&gt;

&lt;h3 id=&#34;distance-sections-and-labs&#34;&gt;Distance sections and labs&lt;/h3&gt;

&lt;p&gt;The lectures for this class can be joined synchronously via Zoom (see
&lt;a href=&#34;fall2019/&#34; target=&#34;_blank&#34;&gt;instructions&lt;/a&gt;); they are also recorded and will be posted
&lt;a href=&#34;fall2019/#videos&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; (and automatically on Canvas).  Some labs
will be activities that can be completed within the time period (with
group discussion and compare/contrast) while others will be a jump
start for homeworks.  I envision that distance students will form
groups and set a time for virtual discussion in lieu of synchronous
discussion during the lab period.  In both settings, there will be a
peer evaluation component during which each participant credits one or
more peers with some specific contributions to the conversation.&lt;/p&gt;

&lt;h2 id=&#34;moodle&#34;&gt;Moodle&lt;/h2&gt;

&lt;p&gt;Moodle will be used to maintain grades.  Please enroll yourself at &lt;a href=&#34;https://moodle.cs.colorado.edu&#34; target=&#34;_blank&#34;&gt;https://moodle.cs.colorado.edu&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;resources&#34;&gt;Resources&lt;/h2&gt;

&lt;p&gt;This course will use a variety of online resources and papers.
There is no required textbook, but the following resources may be helpful.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/hpc-book&#34; target=&#34;_blank&#34;&gt;Hager and Wellein (2010), &lt;strong&gt;Introduction to High Performance Computing for Scientists and Engineers&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://www.cs.utexas.edu/users/flame/laff/pfhp/index.html&#34; target=&#34;_blank&#34;&gt;van de Geijn, Myers, Parikh (2019): &lt;strong&gt;LAFF on Programming for High Performance&lt;/strong&gt;&lt;/a&gt; (free online)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://pages.tacc.utexas.edu/~eijkhout/istc/istc.html&#34; target=&#34;_blank&#34;&gt;Eijkhout, Chow, van de Geijn (2017), &lt;strong&gt;Introduction to High-Performance Scientific Computing&lt;/strong&gt;&lt;/a&gt; (free PDF)&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www-users.cs.umn.edu/~karypis/parbook/&#34; target=&#34;_blank&#34;&gt;Grama, Gupta, Karypis, Kumar (2003), &lt;strong&gt;Introduction to Parallel Computing&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h4 id=&#34;additional-resources&#34;&gt;Additional resources&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://press.princeton.edu/titles/9763.html&#34; target=&#34;_blank&#34;&gt;Greenbaum and Chartier (2012), &lt;strong&gt;Numerical Methods Design, Analysis, and Computer Implementation of Algorithms&lt;/strong&gt;&lt;/a&gt; &amp;ndash; an excellent, comprehensive book.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/~boyd/vmls/&#34; target=&#34;_blank&#34;&gt;Boyd and Vandenberghe (2018), &lt;strong&gt;Introduction to Applied Linear Algebra&lt;/strong&gt;&lt;/a&gt; &amp;ndash; practical introduction to linear algebra for computer scientists; free PDF&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://bookstore.siam.org/ot50/&#34; target=&#34;_blank&#34;&gt;Trefethen and Bau (1997), &lt;strong&gt;Numerical Linear Algebra&lt;/strong&gt;&lt;/a&gt; &amp;ndash; fantastic, but limited to numerical linear algebra and covers more advanced topics.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://physics.codes/&#34; target=&#34;_blank&#34;&gt;Scopatz and Huff (2015), &lt;strong&gt;Effective Computation in Physics&lt;/strong&gt;&lt;/a&gt; &amp;ndash; Python language, data science workflow, and computation.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;A &lt;a href=&#34;http://www.siam.org/students/memberships.php&#34; target=&#34;_blank&#34;&gt;SIAM Membership&lt;/a&gt; is free for CU students and provides a 30% discount on SIAM books.&lt;/p&gt;

&lt;h2 id=&#34;disability-accommodations&#34;&gt;Disability Accommodations&lt;/h2&gt;

&lt;p&gt;If you qualify for accommodations because of a disability, please submit to your professor a letter from Disability Services in a timely manner (for exam accommodations provide your letter at least one week prior to the exam) so that your needs can be addressed. Disability Services determines accommodations based on documented disabilities. Contact Disability Services at 303-492-8671 or by e-mail at dsinfo@colorado.edu. If you have a temporary medical condition or injury, see the Temporary Injuries guidelines under the Quick Links at the Disability Services website and discuss your needs with your professor.&lt;/p&gt;

&lt;h2 id=&#34;religious-observances&#34;&gt;Religious Observances&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://www.colorado.edu/policies/fac_relig.html&#34; target=&#34;_blank&#34;&gt;Campus policy regarding religious observances&lt;/a&gt; requires that faculty make every effort to deal reasonably and fairly with all students who, because of religious obligations, have conflicts with scheduled exams, assignments or required assignments/attendance. If this applies to you, please speak with me directly as soon as possible at the beginning of the term. See the &lt;a href=&#34;http://www.colorado.edu/policies/observance-religious-holidays-and-absences-classes-andor-exams&#34; target=&#34;_blank&#34;&gt;campus policy regarding religious observances&lt;/a&gt; for full details.&lt;/p&gt;

&lt;h2 id=&#34;classroom-behavior&#34;&gt;Classroom Behavior&lt;/h2&gt;

&lt;p&gt;Students and faculty each have responsibility for maintaining an appropriate learning environment. Those who fail to adhere to such behavioral standards may be subject to discipline. Professional courtesy and sensitivity are especially important with respect to individuals and topics dealing with differences of race, color, culture, religion, creed, politics, veteran&amp;rsquo;s status, sexual orientation, gender, gender identity and gender expression, age, disability,and nationalities. Class rosters are provided to the instructor with the student&amp;rsquo;s legal name. I will gladly honor your request to address you by an alternate name or gender pronoun. Please advise me of this preference early in the semester so that I may make appropriate changes to my records. For more information, see the policies on &lt;a href=&#34;http://www.colorado.edu/policies/student-classroom-and-course-related-behavior&#34; target=&#34;_blank&#34;&gt;classroom behavior&lt;/a&gt; and the &lt;a href=&#34;http://www.colorado.edu/osc/sites/default/files/attached-files/studentconductcode_16-17-a.pdf&#34; target=&#34;_blank&#34;&gt;student code&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;discrimination-and-harassment&#34;&gt;Discrimination and Harassment&lt;/h2&gt;

&lt;p&gt;The University of Colorado Boulder (CU Boulder) is committed to maintaining a positive learning, working, and living environment. CU Boulder will not tolerate acts of sexual misconduct, discrimination, harassment or related retaliation against or by any employee or student. CU&amp;rsquo;s Sexual Misconduct Policy prohibits sexual assault, sexual exploitation, sexual harassment,intimate partner abuse (dating or domestic violence), stalking or related retaliation. CU Boulder&amp;rsquo;s Discrimination and Harassment Policy prohibits discrimination, harassment or related retaliation based on race, color,national origin, sex, pregnancy, age, disability, creed, religion, sexual orientation, gender identity, gender expression, veteran status, political affiliation or political philosophy. Individuals who believe they have been subject to misconduct under either policy should contact the Office of Institutional Equity and Compliance (OIEC) at 303-492-2127. Information about the OIEC, the above referenced policies, and the campus resources available to assist individuals regarding sexual misconduct, discrimination, harassment or related retaliation can be found at the &lt;a href=&#34;http://www.colorado.edu/institutionalequity/&#34; target=&#34;_blank&#34;&gt;OIEC website&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;honor-code&#34;&gt;Honor Code&lt;/h2&gt;

&lt;p&gt;All students enrolled in a University of Colorado Boulder course are responsible for knowing and adhering to the &lt;a href=&#34;http://www.colorado.edu/policies/academic-integrity-policy&#34; target=&#34;_blank&#34;&gt;academic integrity policy&lt;/a&gt; of the institution. Violations of the policy may include: plagiarism, cheating,fabrication, lying, bribery, threat, unauthorized access, clicker fraud,resubmission, and aiding academic dishonesty.  All incidents of academic misconduct will be reported to the Honor Code Council (honor@colorado.edu; 303-735-2273). Students who are found responsible for violating the academic integrity policy will be subject to nonacademic sanctions from the Honor Code Council as well as academic sanctions from the faculty member. Additional information regarding the academic integrity policy can be found at &lt;a href=&#34;http://honorcode.colorado.edu&#34; target=&#34;_blank&#34;&gt;http://honorcode.colorado.edu&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Parallel Scaling</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-parallel-scaling/</link>
      <pubDate>Fri, 06 Sep 2019 08:07:31 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-parallel-scaling/</guid>
      <description>

&lt;h2 id=&#34;programs-with-more-than-one-part&#34;&gt;Programs with more than one part&lt;/h2&gt;

&lt;p&gt;So far, we&amp;rsquo;ve focused on simple programs with only one part, but real programs have several different parts, often with data dependencies.
Some parts will be amenable to optimization and/or parallelism and others will not.
&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/4/40/Optimizing-different-parts.svg/2880px-Optimizing-different-parts.svg.png&#34; alt=&#34;Diminishing returns&#34; /&gt;
This principle is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Amdahl%27s_law&#34; target=&#34;_blank&#34;&gt;Amdahl&amp;rsquo;s Law&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_time(f, p, n=10, latency=1):
    # Suppose that a fraction f of the total work is amenable to optimization
    # We run a problem size n with parallelization factor p
    return latency + (1-f)*n + f*n/p
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import pandas
import numpy as np
plt.style.use(&#39;seaborn&#39;)

ps = np.geomspace(1, 1000)

plt.loglog(ps, exec_time(.99, ps, latency=0))
plt.loglog(ps, exec_time(1, ps, latency=0))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;time&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;strong-scaling-fixed-total-problem-size&#34;&gt;Strong scaling: fixed total problem size&lt;/h2&gt;

&lt;h3 id=&#34;cost-time-p&#34;&gt;Cost = &lt;code&gt;time * p&lt;/code&gt;&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_cost(f, p, **kwargs):
    return exec_time(f, p, **kwargs) * p

plt.loglog(ps, exec_cost(.99, ps))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;cost&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_4_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;efficiency&#34;&gt;Efficiency&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.semilogx(ps, 1/exec_cost(.99, ps, latency=1))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_6_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;speedup&#34;&gt;Speedup&lt;/h3&gt;

&lt;p&gt;$$ S(p) = \frac{T(1)}{T(p)} $$&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.plot(ps, exec_time(.99, 1, latency=1) / exec_time(.99, ps, latency=1))
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;p&#39;)
plt.ylabel(&#39;speedup&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;stunt-1-report-speedup-not-absolute-performance&#34;&gt;Stunt 1: Report speedup, not absolute performance!&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;stunt1.jpg&#34; alt=&#34;Hager&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;efficiency-time-spectrum-my-preference&#34;&gt;Efficiency-Time spectrum (my preference)&lt;/h2&gt;

&lt;p&gt;People care about two observable properties
* &lt;strong&gt;Time&lt;/strong&gt; until job completes
* &lt;strong&gt;Cost&lt;/strong&gt; in core-hours or dollars to do job&lt;/p&gt;

&lt;p&gt;Most HPC applications have access to large machines, so don&amp;rsquo;t really care how many processes they use for any given job.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;plt.plot(exec_time(.99, ps), 1/exec_cost(.99, ps), &#39;o-&#39;)
plt.title(&#39;Strong scaling&#39;)
plt.xlabel(&#39;time&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
plt.xlim(left=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_11_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;principles&#34;&gt;Principles&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/archives/5835&#34; target=&#34;_blank&#34;&gt;No &amp;ldquo;soft&amp;rdquo; &lt;code&gt;log&lt;/code&gt; scale&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Both axes have tangible units&lt;/li&gt;
&lt;li&gt;Bigger is better on the $y$ axis&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;weak-scaling-fixed-work-per-processor&#34;&gt;Weak Scaling: Fixed work per processor&lt;/h2&gt;

&lt;p&gt;We&amp;rsquo;ve kept the problem size $n$ fixed thus far, but parallel computers are also used to solve large problems.  If we keep the amount of work per processor fixed, we are &lt;a href=&#34;https://en.wikipedia.org/wiki/Gustafson&#39;s_law&#34; target=&#34;_blank&#34;&gt;weak/Gustafson scaling&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;ns = 10*ps
plt.semilogx(ps, ns/exec_cost(.99, ps, n=ns, latency=1), &#39;o-&#39;)
ns = 100*ps
plt.semilogx(ps, ns/exec_cost(.99, ps, n=ns, latency=1), &#39;s-&#39;)
plt.title(&#39;Weak scaling&#39;)
plt.xlabel(&#39;procs&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_14_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for w in np.geomspace(0.1, 1e3, 20):
    ns = w*ps
    plt.semilogx(exec_time(.99, ps, n=ns, latency=1),
                 ns/exec_cost(.99, ps, n=ns, latency=1), &#39;o-&#39;)
plt.title(&#39;Weak scaling&#39;)
plt.xlabel(&#39;time&#39;)
plt.ylabel(&#39;efficiency&#39;)
plt.ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_15_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;fuhrer-et-al-2018-near-global-climate-simulation-at-1-km-resolution-https-www-geosci-model-dev-net-11-1665-2018-gmd-11-1665-2018-pdf&#34;&gt;&lt;a href=&#34;https://www.geosci-model-dev.net/11/1665/2018/gmd-11-1665-2018.pdf&#34; target=&#34;_blank&#34;&gt;Fuhrer et al (2018): Near-global climate simulation at 1 km resolution&lt;/a&gt;&lt;/h2&gt;

&lt;p&gt;&lt;img src=&#34;fuhrer2018-fig4.png&#34; alt=&#34;Fuhrer (2018)&#34; /&gt;&lt;/p&gt;

&lt;p&gt;I replotted these data for &lt;a href=&#34;https://jedbrown.org/files/20190822-Latsis.pdf&#34; target=&#34;_blank&#34;&gt;my talk&lt;/a&gt; at the &lt;a href=&#34;https://latsis2019.ethz.ch/&#34; target=&#34;_blank&#34;&gt;Latsis Symposium&lt;/a&gt; last month.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;fuhrer2018-scaling-time-ann4.png&#34; alt=&#34;Fuhrer (2018) replotted&#34; /&gt;&lt;/p&gt;

&lt;h1 id=&#34;further-resources&#34;&gt;Further resources&lt;/h1&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://blogs.fau.de/hager/archives/5260&#34; target=&#34;_blank&#34;&gt;Hager: Fooling the masses&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Learn by counter-examples&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://htor.inf.ethz.ch/publications/index.php?pub=222&#34; target=&#34;_blank&#34;&gt;Hoefler and Belli: Scientific Benchmarking of Parallel Computing Systems&lt;/a&gt;

&lt;ul&gt;
&lt;li&gt;Recommended best practices, especially for dealing with performance variability&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Please read/watch something from this list and be prepared to share on Monday.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Introduction to Performance Modeling</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-modeling/</link>
      <pubDate>Wed, 04 Sep 2019 09:17:28 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-modeling/</guid>
      <description>

&lt;h2 id=&#34;why-model-performance&#34;&gt;Why model performance?&lt;/h2&gt;

&lt;p&gt;Models give is a conceptual and roughly quantitative framework by which to answer the following types of questions.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Why is an implementation exhibiting its observed performance?&lt;/li&gt;
&lt;li&gt;How will performance change if we:

&lt;ul&gt;
&lt;li&gt;optimize this component?&lt;/li&gt;
&lt;li&gt;buy new hardware? (Which new hardware?)&lt;/li&gt;
&lt;li&gt;run a different configuration?&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;While conceptualizing a new algorithm, what performance can we expect and what will be bottlenecks?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Models are a guide for performance, but not an absolute.&lt;/p&gt;

&lt;h3 id=&#34;terms&#34;&gt;Terms&lt;/h3&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Symbol&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;$n$&lt;/td&gt;
&lt;td&gt;Input parameter related to problem size&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$W$&lt;/td&gt;
&lt;td&gt;Amount of work to solve problem $n$&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$T$&lt;/td&gt;
&lt;td&gt;Execution time&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;$R$&lt;/td&gt;
&lt;td&gt;Rate at which work is done&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&#34;stream-triad&#34;&gt;STREAM Triad&lt;/h4&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (i=0; i&amp;lt;n; i++)
    a[i] = b[i] + scalar*c[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;$n$ is the array size and
$$W = 3 \cdot \texttt{sizeof(double)} \cdot n$$
is the number of bytes transferred.  The rate $R = W/T$ is measured in bytes per second (or MB/s, etc.).&lt;/p&gt;

&lt;h4 id=&#34;dense-matrix-multiplication&#34;&gt;Dense matrix multiplication&lt;/h4&gt;

&lt;p&gt;To perform the operation $C \gets C + A B$ where $A,B,C$ are $n\times n$ matrices.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (i=0; i&amp;lt;n; i++)
    for (j=0; j&amp;lt;n; j++)
        for (k=0; k&amp;lt;n; k++)
            c[i*n+j] += a[i*n+k] * b[k*n+j];
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Can you identify two expressions for the total amount of work $W(n)$ and the associated units?&lt;/li&gt;
&lt;li&gt;Can you think of a context in which one is better than the other and vice-versa?&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;estimating-time&#34;&gt;Estimating time&lt;/h3&gt;

&lt;p&gt;To estimate time, we need to know how fast hardware executes flops and moves bytes.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;%matplotlib inline
import matplotlib.pyplot as plt
import pandas
import numpy as np
plt.style.use(&#39;seaborn&#39;)

hardware = pandas.read_csv(&#39;data-intel.csv&#39;, index_col=&amp;quot;Name&amp;quot;)
hardware
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;Year&lt;/th&gt;
      &lt;th&gt;GFLOPs-SP&lt;/th&gt;
      &lt;th&gt;GFLOPs-DP&lt;/th&gt;
      &lt;th&gt;Cores&lt;/th&gt;
      &lt;th&gt;Mem-GBps&lt;/th&gt;
      &lt;th&gt;TDP&lt;/th&gt;
      &lt;th&gt;Freq(MHz)&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5482&lt;/th&gt;
      &lt;td&gt;2007&lt;/td&gt;
      &lt;td&gt;102&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5492&lt;/th&gt;
      &lt;td&gt;2008&lt;/td&gt;
      &lt;td&gt;108&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;26&lt;/td&gt;
      &lt;td&gt;150&lt;/td&gt;
      &lt;td&gt;3400&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon W5590&lt;/th&gt;
      &lt;td&gt;2009&lt;/td&gt;
      &lt;td&gt;106&lt;/td&gt;
      &lt;td&gt;53&lt;/td&gt;
      &lt;td&gt;4&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5680&lt;/th&gt;
      &lt;td&gt;2010&lt;/td&gt;
      &lt;td&gt;160&lt;/td&gt;
      &lt;td&gt;80&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon X5690&lt;/th&gt;
      &lt;td&gt;2011&lt;/td&gt;
      &lt;td&gt;166&lt;/td&gt;
      &lt;td&gt;83&lt;/td&gt;
      &lt;td&gt;6&lt;/td&gt;
      &lt;td&gt;32&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;3470&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2690&lt;/th&gt;
      &lt;td&gt;2012&lt;/td&gt;
      &lt;td&gt;372&lt;/td&gt;
      &lt;td&gt;186&lt;/td&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;51&lt;/td&gt;
      &lt;td&gt;135&lt;/td&gt;
      &lt;td&gt;2900&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2697 v2&lt;/th&gt;
      &lt;td&gt;2013&lt;/td&gt;
      &lt;td&gt;518&lt;/td&gt;
      &lt;td&gt;259&lt;/td&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;60&lt;/td&gt;
      &lt;td&gt;130&lt;/td&gt;
      &lt;td&gt;2700&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v3&lt;/th&gt;
      &lt;td&gt;2014&lt;/td&gt;
      &lt;td&gt;1324&lt;/td&gt;
      &lt;td&gt;662&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v3&lt;/th&gt;
      &lt;td&gt;2015&lt;/td&gt;
      &lt;td&gt;1324&lt;/td&gt;
      &lt;td&gt;662&lt;/td&gt;
      &lt;td&gt;18&lt;/td&gt;
      &lt;td&gt;68&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2300&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon E5-2699 v4&lt;/th&gt;
      &lt;td&gt;2016&lt;/td&gt;
      &lt;td&gt;1548&lt;/td&gt;
      &lt;td&gt;774&lt;/td&gt;
      &lt;td&gt;22&lt;/td&gt;
      &lt;td&gt;77&lt;/td&gt;
      &lt;td&gt;145&lt;/td&gt;
      &lt;td&gt;2200&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon Platinum 8180&lt;/th&gt;
      &lt;td&gt;2017&lt;/td&gt;
      &lt;td&gt;4480&lt;/td&gt;
      &lt;td&gt;2240&lt;/td&gt;
      &lt;td&gt;28&lt;/td&gt;
      &lt;td&gt;120&lt;/td&gt;
      &lt;td&gt;205&lt;/td&gt;
      &lt;td&gt;2500&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Xeon Platinum 9282&lt;/th&gt;
      &lt;td&gt;2018&lt;/td&gt;
      &lt;td&gt;9320&lt;/td&gt;
      &lt;td&gt;4660&lt;/td&gt;
      &lt;td&gt;56&lt;/td&gt;
      &lt;td&gt;175&lt;/td&gt;
      &lt;td&gt;400&lt;/td&gt;
      &lt;td&gt;2600&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;fig = hardware.plot(x=&#39;GFLOPs-DP&#39;, y=&#39;Mem-GBps&#39;, marker=&#39;o&#39;)
fig.set_xlim(left=0)
fig.set_ylim(bottom=0);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_2_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;So we have rates $R_f = 4660 \cdot 10^9$ flops/second and $R_m = 175 \cdot 10^9$ bytes/second.  Now we need to characterize some algorithms.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;algs = pandas.read_csv(&#39;algs.csv&#39;, index_col=&#39;Name&#39;)
algs[&#39;intensity&#39;] = algs[&#39;flops&#39;] / algs[&#39;bytes&#39;]
algs = algs.sort_values(&#39;intensity&#39;)
algs
&lt;/code&gt;&lt;/pre&gt;

&lt;div&gt;
&lt;style scoped&gt;
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
&lt;/style&gt;
&lt;table border=&#34;1&#34; class=&#34;dataframe&#34;&gt;
  &lt;thead&gt;
    &lt;tr style=&#34;text-align: right;&#34;&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;bytes&lt;/th&gt;
      &lt;th&gt;flops&lt;/th&gt;
      &lt;th&gt;intensity&lt;/th&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Name&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
      &lt;th&gt;&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;th&gt;Triad&lt;/th&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.083333&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;SpMV&lt;/th&gt;
      &lt;td&gt;12&lt;/td&gt;
      &lt;td&gt;2&lt;/td&gt;
      &lt;td&gt;0.166667&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stencil27-cache&lt;/th&gt;
      &lt;td&gt;24&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;2.250000&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;MatFree-FEM&lt;/th&gt;
      &lt;td&gt;2376&lt;/td&gt;
      &lt;td&gt;15228&lt;/td&gt;
      &lt;td&gt;6.409091&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;th&gt;Stencil27-ideal&lt;/th&gt;
      &lt;td&gt;8&lt;/td&gt;
      &lt;td&gt;54&lt;/td&gt;
      &lt;td&gt;6.750000&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;def exec_time(machine, alg, n):
    bytes = n * alg.bytes
    flops = n * alg.flops
    T_mem = bytes / (machine[&#39;Mem-GBps&#39;] * 1e9)
    T_flops = flops / (machine[&#39;GFLOPs-DP&#39;] * 1e9)
    return max(T_mem, T_flops)
    
exec_time(hardware.loc[&#39;Xeon Platinum 9282&#39;], algs.loc[&#39;SpMV&#39;], 1e8)
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code&gt;0.006857142857142857
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for _, machine in hardware.iterrows():
    for _, alg in algs.iterrows():
        ns = np.geomspace(1e4, 1e9, 10)
        times = np.array([exec_time(machine, alg, n) for n in ns])
        flops = np.array([alg.flops * n for n in ns])
        rates = flops/times
        plt.loglog(ns, rates, &#39;o-&#39;)
plt.xlabel(&#39;n&#39;)
plt.ylabel(&#39;rate&#39;);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_6_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;It looks like performance does not depend on problem size.&lt;/p&gt;

&lt;p&gt;Well, yeah, we chose a model in which flops and bytes were both proportional to $n$, and our machine model has no sense of cache hierarchy or latency, so time is also proportional to $n$.  We can divide through by $n$ and yield a more illuminating plot.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;for _, machine in hardware.iterrows():
    times = np.array([exec_time(machine, alg, 1) 
                      for _, alg in algs.iterrows()])
    rates = algs.flops/times
    intensities = algs.intensity
    plt.loglog(intensities, rates, &#39;o-&#39;, label=machine.name)
plt.xlabel(&#39;intensity&#39;)
plt.ylabel(&#39;rate&#39;)
plt.legend();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;./lecture_8_0.png&#34; alt=&#34;png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;We&amp;rsquo;re seeing the &amp;ldquo;roofline&amp;rdquo; for the older processors while the newer models are memory bandwidth limited for all of these algorithms.&lt;/p&gt;

&lt;h3 id=&#34;recommended-reading-on-single-node-performance-modeling&#34;&gt;Recommended reading on single-node performance modeling&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://doi.org/10.1145/1498765.1498785&#34; target=&#34;_blank&#34;&gt;Williams, Waterman, Patterson (2009): &lt;strong&gt;Roofline: An insightful visual performance model for multicore architectures&lt;/strong&gt;&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Vectorization and Instruction-Level Parallelism</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-vectorization/</link>
      <pubDate>Fri, 30 Aug 2019 11:00:00 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-vectorization/</guid>
      <description>

&lt;p&gt;Remember how single-thread performance has increased significantly
since ~2004 when clock frequency stagnated?&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.karlrupp.net/wp-content/uploads/2018/02/42-years-processor-trend.png&#34; alt=&#34;42 years of microprocessor data&#34; /&gt;&lt;/p&gt;

&lt;p&gt;This is a result of doing more per clock cycle.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.karlrupp.net/wp-content/uploads/2013/06/flops-per-cycle-sp.png&#34; alt=&#34;Flops per clock cycle&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Let&amp;rsquo;s visit some slides:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://moodle.rrze.uni-erlangen.de/pluginfile.php/12916/mod_resource/content/6/01_IntroArchitecture.pdf&#34; target=&#34;_blank&#34;&gt;Georg Hager (2019): Modern Computer Architucture&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://software.intel.com/sites/landingpage/IntrinsicsGuide/#&#34; target=&#34;_blank&#34;&gt;Intel Intrinsics Guide&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wikichip

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/intel/microarchitectures/cascade_lake&#34; target=&#34;_blank&#34;&gt;Intel Xeon: Cascade Lake&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/amd/cores/rome&#34; target=&#34;_blank&#34;&gt;AMD EPYC gen2: Rome&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://en.wikichip.org/wiki/ibm/microarchitectures/power9&#34; target=&#34;_blank&#34;&gt;IBM POWER9&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.agner.org/optimize/&#34; target=&#34;_blank&#34;&gt;Agner Fog&amp;rsquo;s website&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Intro to Architecture</title>
      <link>https://cucs-hpsc.github.io/fall2019/intro-architecture/</link>
      <pubDate>Wed, 28 Aug 2019 08:10:18 -0600</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/intro-architecture/</guid>
      <description>

&lt;h1 id=&#34;cores-caches-and-memory&#34;&gt;Cores, caches, and memory&lt;/h1&gt;

&lt;h3 id=&#34;a-von-neumann-architecture-https-en-wikipedia-org-wiki-von-neumann-architecture&#34;&gt;A &lt;a href=&#34;https://en.wikipedia.org/wiki/Von_Neumann_architecture&#34; target=&#34;_blank&#34;&gt;von Neumann Architecture&lt;/a&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/e/e5/Von_Neumann_Architecture.svg/2880px-Von_Neumann_Architecture.svg.png&#34; alt=&#34;von Neumann architecture&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-contemporary-architecture&#34;&gt;A contemporary architecture&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/physicalMemoryAccess.png&#34; alt=&#34;Core 2&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;my-laptop&#34;&gt;My laptop&lt;/h3&gt;

&lt;p&gt;We can get this kind of information for our machine using &lt;a href=&#34;https://www.open-mpi.org/projects/hwloc/&#34; target=&#34;_blank&#34;&gt;hwloc&lt;/a&gt;, which provides a library as well as the command-line tool &lt;code&gt;lstopo&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-python&#34;&gt;!lstopo --output-format svg &amp;gt; lstopo-local.svg
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;img src=&#34;lstopo-local.svg&#34; alt=&#34;lstopo&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;a-double-socket-compute-node-with-two-gpus&#34;&gt;A double-socket compute node with two GPUs&lt;/h3&gt;

&lt;p&gt;2x Xeon Ivy-Bridge-EP &lt;a href=&#34;https://ark.intel.com/content/www/us/en/ark/products/75277/intel-xeon-processor-e5-2680-v2-25m-cache-2-80-ghz.html&#34; target=&#34;_blank&#34;&gt;E5-2680v2&lt;/a&gt; + 2x NVIDIA GPUs (from 2013, with hwloc v1.11).
GPUs are reported as CUDA devices and X11 display :1.0: (from the &lt;a href=&#34;https://www-lb.open-mpi.org/projects/hwloc/lstopo/&#34; target=&#34;_blank&#34;&gt;hwloc gallery&lt;/a&gt;)
&lt;img src=&#34;https://www-lb.open-mpi.org/projects/hwloc/lstopo/images/2XeonE5v2+2cuda+1display_v1.11.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;block-diagrams&#34;&gt;Block diagrams&lt;/h3&gt;

&lt;p&gt;A block diagram from a vendor can include additional information about how cores are physically connected.&lt;/p&gt;

&lt;h4 id=&#34;ring-bus-xeon-e5-2600-family&#34;&gt;Ring bus (Xeon E5-2600 family)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/e3/a4/xeon-processor-scalable-family-tech-overview-fig04.png&#34; alt=&#34;Intel Xeon E5-2600&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;mesh-bus-xeon-scalable-family&#34;&gt;Mesh bus (Xeon Scalable family)&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/5a/03/xeon-processor-scalable-family-tech-overview-fig05.png&#34; alt=&#34;Intel Xeon Scalable&#34; /&gt;&lt;/p&gt;

&lt;h4 id=&#34;multi-socket-configurations&#34;&gt;Multi-socket configurations&lt;/h4&gt;

&lt;p&gt;&lt;img src=&#34;https://software.intel.com/sites/default/files/managed/77/f2/xeon-processor-scalable-family-tech-overview-fig07.png&#34; alt=&#34;4-socket ring&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview&#34; target=&#34;_blank&#34;&gt;https://software.intel.com/en-us/articles/intel-xeon-processor-scalable-family-technical-overview&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;multiple-nodes-go-into-racks-or-cabinets&#34;&gt;Multiple nodes go into &lt;strong&gt;racks&lt;/strong&gt; or &lt;strong&gt;cabinets&lt;/strong&gt;&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;BlueGenePRacks.png&#34; alt=&#34;Blue Gene/P Racks&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://www.olcf.ornl.gov/wp-content/uploads/2018/06/summit-1.jpg&#34; alt=&#34;OLCF Summit&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;terminology&#34;&gt;Terminology&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Core&lt;/strong&gt; (virtual and physical): has a single program counter (logically sequential processing of instructions)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Memory channel&lt;/strong&gt;: e.g., DDR4-2400: transfers 64 bits (8 bytes) at a rate of 2400 MHz = 15.36 GB/s&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Socket&lt;/strong&gt; or &lt;strong&gt;CPU&lt;/strong&gt;: contains multiple cores in a single piece* of silicon&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Non-Uniform Memory Access (NUMA)&lt;/strong&gt;: different channels may be different distances from a core&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Compute node&lt;/strong&gt;: one or more sockets, plus memory, network card, etc.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;how-expensive-is-it-to-access-memory&#34;&gt;How expensive is it to access memory?&lt;/h3&gt;

&lt;p&gt;What does that mean?  How would we measure?&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.rdrop.com/~paulmck/RCU/RCU.2013.01.22d.PLMW.pdf&#34; target=&#34;_blank&#34;&gt;McKenney (2013): Laws of Physics&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html&#34; target=&#34;_blank&#34;&gt;Interactive&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.anandtech.com/show/14694/amd-rome-epyc-2nd-gen/7&#34; target=&#34;_blank&#34;&gt;Variation by vendor&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&#34;how-your-program-accesses-memory&#34;&gt;How your program accesses memory&lt;/h1&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;double a[1000];

void foo() {
    for (int i=0; i&amp;lt;1000; i++)
        a[i] = 1.234 * i;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The compiler turns the loop body into instructions, which we can examine using &lt;a href=&#34;https://gcc.godbolt.org/z/gbhuZR&#34; target=&#34;_blank&#34;&gt;Godbolt&lt;/a&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;pxor xmm0, xmm0                  ; zero the xmm0 register
cvtsi2sd xmm0, eax               ; convert the integer i to double
mulsd xmm0, xmm1                 ; multiply by 1.234 (held in xmm1)
movsd QWORD PTR a[0+rax*8], xmm0 ; store to memory address a[i]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Only one instruction here accesses memory, and the performance will be affected greatly by where that memory resides (which level of cache, where in DRAM).&lt;/p&gt;

&lt;p&gt;Most architectures today have &lt;strong&gt;64-byte cache lines&lt;/strong&gt;: all transfers from main memory (DRAM) to and from cache operate in units of 64 bytes.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/L1CacheExample.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;let-s-compare-three-code-samples&#34;&gt;Let&amp;rsquo;s compare three code samples&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[i];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[(i*8) % N];
&lt;/code&gt;&lt;/pre&gt;

&lt;pre&gt;&lt;code class=&#34;language-c&#34;&gt;for (int i=0; i&amp;lt;N; i++)
    a[i] = b[random() % N];
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;what-happens-when-you-request-a-cache-line&#34;&gt;What happens when you request a cache line?&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;http://static.duartes.org/img/blogPosts/memoryRead.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;operating-system-effects&#34;&gt;Operating system effects&lt;/h2&gt;

&lt;p&gt;Most systems today use virtual addressing, so every address in your program needs to be translated to a physical address before looking for it (in cache or memory).  Fortunately, there is hardware to assist with this: the Translation Lookaside Buffer (TLB).&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://drawings.jvns.ca/drawings/pagetable.svg&#34; alt=&#34;Virtual memory and the page table&#34; /&gt;&lt;/p&gt;

&lt;h2 id=&#34;further-resources&#34;&gt;Further resources&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://jvns.ca/blog/2016/12/03/how-much-memory-is-my-process-using-/&#34; target=&#34;_blank&#34;&gt;Julia Evans (2016): How much memory is my process using?&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://manybutfinite.com/post/intel-cpu-caches/&#34; target=&#34;_blank&#34;&gt;Gustavo Duarte (2009): Cache: a place for concealment and safekeeping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://manybutfinite.com/post/getting-physical-with-memory/&#34; target=&#34;_blank&#34;&gt;Gustavo Duarte (2009): Getting Physical With Memory&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.akkadia.org/drepper/cpumemory.pdf&#34; target=&#34;_blank&#34;&gt;Ulrich Drepper (2007): What Every Programmer Should Know About Memory&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Trends</title>
      <link>https://cucs-hpsc.github.io/fall2019/trends/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://cucs-hpsc.github.io/fall2019/trends/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/&#34; target=&#34;_blank&#34;&gt;https://www.karlrupp.net/2018/02/42-years-of-microprocessor-trend-data/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/&#34; target=&#34;_blank&#34;&gt;https://www.karlrupp.net/2013/06/cpu-gpu-and-mic-hardware-characteristics-over-time/&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;Fischer2015-Latency.png&#34; alt=&#34;&#34; /&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
