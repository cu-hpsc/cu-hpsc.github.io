<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jed Brown">

  
  
  
    
  
  <meta name="description" content="Sampling probability distributions There are many applications in which one wishes to draw samples from probability distributions. For example, the function np.random.randn(t) draws samples from the &ldquo;standard normal&rdquo;, or Gaussian, distribution.
$$ p(t) = \frac{1}{\sqrt{2\pi}} e^{-t^2&frasl;2} . $$
%matplotlib inline import pandas import seaborn import matplotlib.pyplot as plt import numpy as np plt.style.use(&#39;ggplot&#39;) plt.rc(&#39;figure&#39;, figsize=(12,8)) def stdnormal(t): return np.exp(-t**2/2) / np.sqrt(2*np.pi) n = 1000 w = np.random.randn(n) plt.hist(w, bins=40, range=(-3,3), density=True) t = np.">

  
  <link rel="alternate" hreflang="en-us" href="https://cucs-hpsc.github.io/fall2019/data-probability/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.dd629241ea9333c62c071f4a25f829ff.css">

  

  
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://cucs-hpsc.github.io/fall2019/data-probability/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@five9a2">
  <meta property="twitter:creator" content="@five9a2">
  
  <meta property="og:site_name" content="HPSC">
  <meta property="og:url" content="https://cucs-hpsc.github.io/fall2019/data-probability/">
  <meta property="og:title" content="Data and Probability | HPSC">
  <meta property="og:description" content="Sampling probability distributions There are many applications in which one wishes to draw samples from probability distributions. For example, the function np.random.randn(t) draws samples from the &ldquo;standard normal&rdquo;, or Gaussian, distribution.
$$ p(t) = \frac{1}{\sqrt{2\pi}} e^{-t^2&frasl;2} . $$
%matplotlib inline import pandas import seaborn import matplotlib.pyplot as plt import numpy as np plt.style.use(&#39;ggplot&#39;) plt.rc(&#39;figure&#39;, figsize=(12,8)) def stdnormal(t): return np.exp(-t**2/2) / np.sqrt(2*np.pi) n = 1000 w = np.random.randn(n) plt.hist(w, bins=40, range=(-3,3), density=True) t = np."><meta property="og:image" content="https://cucs-hpsc.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://cucs-hpsc.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-11-13T06:49:25-06:00">
    
    <meta property="article:modified_time" content="2019-11-13T13:01:51-07:00">
  

  


  





  <title>Data and Probability | HPSC</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">HPSC</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/fall2019/"><span>Fall 2019</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/">Logistics</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/syllabus/">Syllabus</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/intro-architecture/">Lecture Notes</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/intro-architecture/">2019-08-28 Architecture</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-vectorization/">2019-08-30 Vectorization</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-modeling/">2019-09-04 Modeling</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-parallel-scaling/">2019-09-06 Parallel Scaling</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp/">2019-09-11 OpenMP Basics</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-2/">2019-09-13 More OpenMP</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-3/">2019-09-16 OpenMP Tasks</a>
      </li>
      
      <li >
        <a href="/fall2019/strategies/">2019-09-18 Reductions and Scans</a>
      </li>
      
      <li >
        <a href="/fall2019/sorting-graphs/">2019-09-23 More bitonic sorting, graphs</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-mpi/">2019-09-24 Introduction to MPI</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg/">2019-09-30 Dense Linear Algebra</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-2/">2019-10-02 Dense Linear Algebra and Orthogonality</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-3/">2019-10-04 Orthogonality and Conditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/elemental/">2019-10-07 Elemental</a>
      </li>
      
      <li >
        <a href="/fall2019/iterative-solvers/">2019-10-09 Sparse and Iterative</a>
      </li>
      
      <li >
        <a href="/fall2019/preconditioning/">2019-10-11 Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning/">2019-10-14 DD Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning-2/">2019-10-16 DD Preconditioning 2</a>
      </li>
      
      <li >
        <a href="/fall2019/mg-preconditioning/">2019-10-18 Multilevel Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/nonlinear/">2019-10-21 Nonlinear</a>
      </li>
      
      <li >
        <a href="/fall2019/transient/">2019-10-23 Transient</a>
      </li>
      
      <li >
        <a href="/fall2019/libceed/">2019-10-25 libCEED</a>
      </li>
      
      <li >
        <a href="/fall2019/coprocessor/">2019-10-28 Coprocessors</a>
      </li>
      
      <li >
        <a href="/fall2019/cuda/">2019-10-30 GPUs and CUDA</a>
      </li>
      
      <li >
        <a href="/fall2019/cuda-practical/">2019-11-01 Practical CUDA</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-target/">2019-11-04 ISP/OpenMP/OpenACC</a>
      </li>
      
      <li >
        <a href="/fall2019/io/">2019-11-06 HPC I/O</a>
      </li>
      
      <li >
        <a href="/fall2019/mpi-io/">2019-11-08 MPI-IO</a>
      </li>
      
      <li >
        <a href="/fall2019/data-methods/">2019-11-11 Data-intensive</a>
      </li>
      
      <li class="active">
        <a href="/fall2019/data-probability/">2019-11-13 Data and Probability</a>
      </li>
      
      <li >
        <a href="/fall2019/interactive/">2019-11-15 Dynamic/Interactive</a>
      </li>
      
      <li >
        <a href="/fall2019/nbody/">2019-11-18 Intro N-body</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/trends/">Resources</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/trends/">Trends</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#sampling-probability-distributions">Sampling probability distributions</a>
<ul>
<li><a href="#statistics-for-hackers">Statistics for Hackers</a></li>
<li><a href="#transforming">Transforming</a></li>
<li><a href="#multivariate-distributions">Multivariate distributions</a>
<ul>
<li><a href="#negative-log">Negative log</a></li>
<li><a href="#normalization">Normalization</a></li>
<li><a href="#sampling">Sampling</a></li>
</ul></li>
</ul></li>
<li><a href="#gaussian-processes">Gaussian processes</a>
<ul>
<li>
<ul>
<li><a href="#further-reading">Further reading</a></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Data and Probability</h1>

          <div class="article-style" itemprop="articleBody">
            

<h2 id="sampling-probability-distributions">Sampling probability distributions</h2>

<p>There are many applications in which one wishes to draw samples from probability distributions.  For example, the function <code>np.random.randn(t)</code> draws samples from the &ldquo;standard normal&rdquo;, or Gaussian, distribution.</p>

<p>$$ p(t) = \frac{1}{\sqrt{2\pi}} e^{-t^<sup>2</sup>&frasl;<sub>2</sub>} . $$</p>

<pre><code class="language-python">%matplotlib inline
import pandas
import seaborn
import matplotlib.pyplot as plt
import numpy as np
plt.style.use('ggplot')
plt.rc('figure', figsize=(12,8))

def stdnormal(t):
    return np.exp(-t**2/2) / np.sqrt(2*np.pi)

n = 1000
w = np.random.randn(n)
plt.hist(w, bins=40, range=(-3,3), density=True)
t = np.linspace(-3, 3)
plt.plot(t, stdnormal(t))
plt.xlabel('$t$')
plt.ylabel('$P(t)$');
</code></pre>

<p><img src="./lecture_1_0.png" alt="png" /></p>

<h3 id="statistics-for-hackers">Statistics for Hackers</h3>

<p>Statistical simulation as a simpler surrogate for tedious analysis (also a primer for more advanced methods in which analysis is intractable):</p>

<ul>
<li><a href="http://christopherroach.com/articles/statistics-for-hackers/" target="_blank">Notebook</a> version of <a href="https://youtu.be/Iq9DzN6mvYA" target="_blank">this talk</a> (<a href="https://speakerdeck.com/jakevdp/statistics-for-hackers" target="_blank">slides</a>)</li>
</ul>

<h3 id="transforming">Transforming</h3>

<p>To say that our sample $w$ is draw from a standard normal distribution, we write</p>

<p>$$ w \sim \mathcal N(0,1) . $$</p>

<p>How do we generate samples of a distribution with nonzero mean or non-unit variance?</p>

<pre><code class="language-python">import statsmodels

n = 1000
w = 2 + .5*np.random.randn(n)
plt.hist(w, bins=40, range=(-1,5), density=True)
plt.xlabel('$t$')
plt.ylabel('$P(t)$');
</code></pre>

<p><img src="./lecture_4_0.png" alt="png" /></p>

<h3 id="multivariate-distributions">Multivariate distributions</h3>

<p>Sometimes we have multiple variables that are related, such as the temperature in different cities.  On any given day, we observe the weather in Boulder, Denver, Fort Collins, and Seattle.  What is the probability of any given observation?</p>

<p>For convenience, suppose that each distribution is independently a Gaussian distribution.  Taking products, we can motivate a linear algebraic formulation,</p>

<p>$$ e^{-s^<sup>2</sup>&frasl;<sub>2</sub>} e^{-t^<sup>2</sup>&frasl;<sub>2</sub>} = e^{-\frac 1 2 \begin{bmatrix} s &amp; t \end{bmatrix} \begin{bmatrix} 1 &amp; 0 \ 0 &amp; 1 \end{bmatrix} \begin{bmatrix} s \ t \end{bmatrix}} $$</p>

<p>More generally, we may express a multidimensional distribution for $\mathbf x$ with mean $\mathbf \mu$ and covariance matrix $\Sigma$ as</p>

<p>$$ P(\mathbf x) = \frac 1 Z e^{-\frac 1 2 (\mathbf x - \mathbf \mu)^T \Sigma^{-1} (\mathbf x - \mathbf \mu)} $$</p>

<p>where $Z$ is a normalizing factor necessary for the integral to equal 1.  Covaniance matrices are symmetric positive definite, and rarely sparse, though they may have exploitable structure (such as low-rank off-diagonal blocks).</p>

<p>Many statistical computations involve</p>

<ul>
<li>drawing samples from such distributions (bootstrapping, etc., and Bayesian Monte-Carlo methods)</li>
<li>optimizing parameters (such as $\mathbf \mu$ and $\Sigma$) over a training set of observations (maximum likelihood estimation and variational inference)</li>
</ul>

<h4 id="negative-log">Negative log</h4>

<p>Probabilities become inconveniently small when far from the mean.</p>

<pre><code class="language-python">stdnormal(10)
</code></pre>

<pre><code>7.69459862670642e-23
</code></pre>

<p>Taking the negative log provides a more convenient expression</p>

<p>$$ -\log P(\mathbf x) = \frac 1 2 (\mathbf x - \mathbf \mu)^T \Sigma^{-1} (\mathbf x - \mathbf \mu) + \log Z $$</p>

<p>which involves a quadratic matrix expression (convenient for optimization) plus a regularization term.</p>

<h4 id="normalization">Normalization</h4>

<p>It can be shown that the normalization factor has the form</p>

<p>$$ Z = \sqrt{\det(2 \pi \Sigma)} . $$</p>

<p>In some circumstances, such as when estimating $\mathbf \mu$ given known $\Sigma$, it is not necessary to evaluate or optimize the determinant.  In other settings, it is necessary and a nontrivial cost.
Computing the determinant is typically done via factorization, such as</p>

<p>$$ L L^T = \Sigma $$</p>

<p>or</p>

<p>$$ L L^T = \Sigma^{-1} $$</p>

<p>if one is working directly with the &ldquo;precision matrix&rdquo; $\Sigma^{-1}$.  This can be advantageous when the precision matrix is sparse, which represents conditional independence and is common even when the covariance matrix is dense.</p>

<p>For example, the weather in Boulder is conditionally independent of the weather in Seattle: if we know the weather in Denver and Fort Collins, adding knowledge of the weather in Seattle provides us no additional information about the weather in Boulder.  This leads to a zero in $\Sigma^{-1}$.</p>

<p>However, knowing the weather in Seattle might help determine whether it is summer or winter, or whether we&rsquo;re in an El Niño year.  This leads to a nonzero entry in $\Sigma$.</p>

<h4 id="sampling">Sampling</h4>

<p>We wish to draw samples such that the expected covariance matches our $\Sigma$,</p>

<p>$$ \mathbb E\Big[ (\mathbf x - \mathbf \mu) (\mathbf x - \mathbf \mu)^T \Big] = \Sigma . $$</p>

<p>For this, we seek a transformation $\mathbf x = \mu + T \mathbf y$ such that each entry of $y \sim \mathcal N(0,1)$.  To this end,</p>

<p>$$ \Sigma = \mathbb E\Big[ T \mathbf y \mathbf y^T T^T \Big] = T \mathbb E[\mathbf y \mathbf y^T] T^T = T T^T $$
so we need to determine such a matrix $T$.</p>

<p>One approach is eigendecomposition,</p>

<p>$$ \Sigma = Q \Lambda Q^T = \big(Q \sqrt{\Lambda} \big) \big(Q \sqrt{\Lambda} \big)^T $$</p>

<p>and another is Cholesky factorization</p>

<p>$$ \Sigma = L L^T, $$</p>

<p>which is generally more efficient (if perhaps less intuitive).</p>

<h2 id="gaussian-processes">Gaussian processes</h2>

<p>A Gaussian process is a probability model for continuous independent variables.  In the temperature example, we might consider latitude and longitude as independent variables.  Given any finite sample of locations (Boulder, Denver, etc.), we build a covariance matrix between any two points $u$ and $v$ by evaluating a &ldquo;kernel&rdquo; function $k(u,v)$.  Sometimes one uses &ldquo;stationary&rdquo; kernels that depend only on distance,</p>

<p>$$ k(u,v) = \hat k\big(\lVert u - v \rVert \big) $$</p>

<p>and sometimes the kernels are squared exponentials,</p>

<p>$$ \hat k&reg; = e^{-r^2/\ell^2} $$</p>

<p>where $\ell$ is a length scale.  But these are not essential features.</p>

<p>Note: although the squared exponential kernel has the same functional form as a Gaussian distribution, this is entirely optional and not what &ldquo;Gaussian&rdquo; in &ldquo;Gaussian process&rdquo; refers to.</p>

<p>In a <a href="https://en.wikipedia.org/wiki/Kriging" target="_blank">Gaussian Process Regression</a> (also known as &ldquo;kriging&rdquo;), one &ldquo;trains&rdquo; (optimizes) kernel parameters $\theta$ in</p>

<p>$$ k(u, v; \theta) $$</p>

<p>such that the model fits some training data.  Once trained, predictions can be made at arbitrary points $u$, and those predictions come with uncertainty.</p>

<p>The classical training involves Cholesky factorization as part of each iteration of a gradient-based optimization algorithm.</p>

<h4 id="further-reading">Further reading</h4>

<ul>
<li><a href="https://planspace.org/20181226-gaussian_processes_are_not_so_fancy/" target="_blank">Gaussian Processes are Not So Fancy</a> (notebook)</li>
<li><a href="https://adamian.github.io/talks/Damianou_GP_tutorial.html" target="_blank">Gaussian process introductory tutorial in Python</a> (notebook)</li>
<li><a href="https://scikit-learn.org/stable/modules/gaussian_process.html" target="_blank">GPR in scikit-learn</a></li>
<li><a href="https://gpytorch.readthedocs.io/en/latest/" target="_blank">GPyTorch</a>, which contains some <a href="https://arxiv.org/abs/1809.11165" target="_blank">structure-exploiting methods</a></li>
</ul>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/fall2019/interactive/" rel="next">Dynamic/Interactive Parallelism</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/fall2019/data-methods/" rel="prev">Data-intensive workflows and parallelism</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Nov 13, 2019</p>

          
<p class="edit-page">
  <a href="https://github.com/cucs-hpsc/hpsc-class/edit/master/content/fall2019/data-probability/index.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>



          

        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/c.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
