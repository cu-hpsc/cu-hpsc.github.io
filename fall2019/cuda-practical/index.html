<!DOCTYPE html>
<html lang="en-us">

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.4.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Jed Brown">

  
  
  
    
  
  <meta name="description" content="GPUs have 2-4x greater floating point and bandwidth peak for the watts  also for the $ if you buy enterprise gear better for the $ if you buy gaming gear  Step 1 is to assess workload and latency requirements   Don&rsquo;t waste time with GPUs if  your problem size or time to solution requirements don&rsquo;t align if the work you&rsquo;d like to move to the GPU is not a bottleneck if the computation cost will be dwarfed by moving data to/from the GPU often you need to restructure so that caller passes in data already on the device can require nonlocal refactoring  Almost never: pick one kernel at a time and move it to the GPU  DOE ACME/E3SM (to pick on one high-profile application) has basically done this for five years and it still doesn&rsquo;t help their production workloads so they bought a non-GPU machine    Okay, okay, okay.">

  
  <link rel="alternate" hreflang="en-us" href="https://cucs-hpsc.github.io/fall2019/cuda-practical/">

  


  

  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.0/css/all.css" integrity="sha384-aOkxzJ5uQz7WBObEZcHvV5JvRW3TUc2rNPA7pe3AwnsUohiw1Vj2Rgx2KSOkF5+h" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.css" integrity="sha512-M2wvCLH6DSRazYeZRIm1JnYyh22purTM+FDB5CsyxtQJYeKq83arPe5wgbNmcFXGqiSH2XR8dT/fJISVA1r/zQ==" crossorigin="anonymous">
    

    

  

  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700|Roboto:400,400italic,700|Roboto+Mono&display=swap">
  

  
  
  
  <link rel="stylesheet" href="/css/academic.min.dd629241ea9333c62c071f4a25f829ff.css">

  

  
  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon-32.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://cucs-hpsc.github.io/fall2019/cuda-practical/">

  
  
  
  
    
    
  
  
  <meta property="twitter:card" content="summary">
  
  <meta property="twitter:site" content="@five9a2">
  <meta property="twitter:creator" content="@five9a2">
  
  <meta property="og:site_name" content="HPSC">
  <meta property="og:url" content="https://cucs-hpsc.github.io/fall2019/cuda-practical/">
  <meta property="og:title" content="Practical CUDA | HPSC">
  <meta property="og:description" content="GPUs have 2-4x greater floating point and bandwidth peak for the watts  also for the $ if you buy enterprise gear better for the $ if you buy gaming gear  Step 1 is to assess workload and latency requirements   Don&rsquo;t waste time with GPUs if  your problem size or time to solution requirements don&rsquo;t align if the work you&rsquo;d like to move to the GPU is not a bottleneck if the computation cost will be dwarfed by moving data to/from the GPU often you need to restructure so that caller passes in data already on the device can require nonlocal refactoring  Almost never: pick one kernel at a time and move it to the GPU  DOE ACME/E3SM (to pick on one high-profile application) has basically done this for five years and it still doesn&rsquo;t help their production workloads so they bought a non-GPU machine    Okay, okay, okay."><meta property="og:image" content="https://cucs-hpsc.github.io/img/icon-192.png">
  <meta property="twitter:image" content="https://cucs-hpsc.github.io/img/icon-192.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2019-11-01T06:49:25-06:00">
    
    <meta property="article:modified_time" content="2019-11-01T12:27:17-06:00">
  

  


  





  <title>Practical CUDA | HPSC</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        <input name="q" id="search-query" placeholder="Search..." autocapitalize="off"
        autocomplete="off" autocorrect="off" spellcheck="false" type="search">
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  
<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0 compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">HPSC</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav mr-auto">
        

        

        
        
        
          
        

        
        
        
        
        
        

        <li class="nav-item">
          <a class="nav-link  active" href="/fall2019/"><span>Fall 2019</span></a>
        </li>

        
        

      
      </ul>
      <ul class="navbar-nav ml-auto">
      

        

        
        <li class="nav-item">
          <a class="nav-link js-search" href="#"><i class="fas fa-search" aria-hidden="true"></i></a>
        </li>
        

        

        

      </ul>

    </div>
  </div>
</nav>


  

<div class="container-fluid docs">
  <div class="row flex-xl-nowrap">
    <div class="col-12 col-md-3 col-xl-2 docs-sidebar">
      





<form class="docs-search d-flex align-items-center">
  <button class="btn docs-toggle d-md-none p-0 mr-3" type="button" data-toggle="collapse" data-target="#docs-nav" aria-controls="docs-nav" aria-expanded="false" aria-label="Toggle section navigation">
    <span><i class="fas fa-bars"></i></span>
  </button>

  
  <input name="q" type="search" class="form-control" placeholder="Search..." autocomplete="off">
  
</form>

<nav class="collapse docs-links" id="docs-nav">
  
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/">Logistics</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/syllabus/">Syllabus</a>

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/intro-architecture/">Lecture Notes</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/intro-architecture/">2019-08-28 Architecture</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-vectorization/">2019-08-30 Vectorization</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-modeling/">2019-09-04 Modeling</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-parallel-scaling/">2019-09-06 Parallel Scaling</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp/">2019-09-11 OpenMP Basics</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-2/">2019-09-13 More OpenMP</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-3/">2019-09-16 OpenMP Tasks</a>
      </li>
      
      <li >
        <a href="/fall2019/strategies/">2019-09-18 Reductions and Scans</a>
      </li>
      
      <li >
        <a href="/fall2019/sorting-graphs/">2019-09-23 More bitonic sorting, graphs</a>
      </li>
      
      <li >
        <a href="/fall2019/intro-mpi/">2019-09-24 Introduction to MPI</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg/">2019-09-30 Dense Linear Algebra</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-2/">2019-10-02 Dense Linear Algebra and Orthogonality</a>
      </li>
      
      <li >
        <a href="/fall2019/dense-linalg-3/">2019-10-04 Orthogonality and Conditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/elemental/">2019-10-07 Elemental</a>
      </li>
      
      <li >
        <a href="/fall2019/iterative-solvers/">2019-10-09 Sparse and Iterative</a>
      </li>
      
      <li >
        <a href="/fall2019/preconditioning/">2019-10-11 Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning/">2019-10-14 DD Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/dd-preconditioning-2/">2019-10-16 DD Preconditioning 2</a>
      </li>
      
      <li >
        <a href="/fall2019/mg-preconditioning/">2019-10-18 Multilevel Preconditioning</a>
      </li>
      
      <li >
        <a href="/fall2019/nonlinear/">2019-10-21 Nonlinear</a>
      </li>
      
      <li >
        <a href="/fall2019/transient/">2019-10-23 Transient</a>
      </li>
      
      <li >
        <a href="/fall2019/libceed/">2019-10-25 libCEED</a>
      </li>
      
      <li >
        <a href="/fall2019/coprocessor/">2019-10-28 Coprocessors</a>
      </li>
      
      <li >
        <a href="/fall2019/cuda/">2019-10-30 GPUs and CUDA</a>
      </li>
      
      <li class="active">
        <a href="/fall2019/cuda-practical/">2019-11-01 Practical CUDA</a>
      </li>
      
      <li >
        <a href="/fall2019/openmp-target/">2019-11-04 ISP/OpenMP/OpenACC</a>
      </li>
      
      <li >
        <a href="/fall2019/io/">2019-11-06 HPC I/O</a>
      </li>
      
      <li >
        <a href="/fall2019/mpi-io/">2019-11-08 MPI-IO</a>
      </li>
      
      <li >
        <a href="/fall2019/data-methods/">2019-11-11 Data-intensive</a>
      </li>
      
      <li >
        <a href="/fall2019/data-probability/">2019-11-13 Data and Probability</a>
      </li>
      
      <li >
        <a href="/fall2019/interactive/">2019-11-15 Dynamic/Interactive</a>
      </li>
      
      <li >
        <a href="/fall2019/nbody/">2019-11-18 Intro N-body</a>
      </li>
      
      <li >
        <a href="/fall2019/nbody-longrange/">2019-11-20 Long-range N-body</a>
      </li>
      
      <li >
        <a href="/fall2019/md/">2019-11-22 Molecular Dynamics</a>
      </li>
      
      <li >
        <a href="/fall2019/git/">2019-12-02 Git Workflows</a>
      </li>
      
      <li >
        <a href="/fall2019/fft/">2019-12-04 Fourier</a>
      </li>
      
      <li >
        <a href="/fall2019/multigrid/">2019-12-06 Multigrid Intro</a>
      </li>
      
    </ul>
    

  </div>
  
  <div class="docs-toc-item">
    <a class="docs-toc-link" href="/fall2019/trends/">Resources</a>
    <ul class="nav docs-sidenav">
      
      <li >
        <a href="/fall2019/trends/">Trends</a>
      </li>
      
    </ul>
    

  </div>
  
  
</nav>

    </div>

    
    <div class="d-none d-xl-block col-xl-2 docs-toc">
      <ul class="nav toc-top">
        <li><a href="#" id="back_to_top" class="docs-toc-title">Contents</a></li>
      </ul>

      <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#terminology-intro">Terminology/intro</a>
<ul>
<li>
<ul>
<li><a href="#how-does-this-relate-to-the-hardware">How does this relate to the hardware?</a></li>
</ul></li>
</ul></li>
<li><a href="#practical-cuda">Practical CUDA</a>
<ul>
<li><a href="#cuda-best-practices-guide-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html"><a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html" target="_blank">CUDA Best Practices Guide</a></a>
<ul>
<li><a href="#occupancy">Occupancy</a></li>
<li><a href="#further-reading">Further reading</a></li>
</ul></li>
<li><a href="#memory">Memory</a>
<ul>
<li><a href="#getting-your-memory-into-position-is-often-the-hardest-part-of-cuda-programming">Getting your memory into position is often the hardest part of CUDA programming.</a></li>
<li><a href="#unified-managed-memory-https-devblogs-nvidia-com-unified-memory-cuda-beginners"><a href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/" target="_blank">Unified/managed memory</a></a></li>
</ul></li>
<li><a href="#on-memory-coalescing-and-strided-access-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html-strided-accesses">On memory coalescing and <a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#strided-accesses" target="_blank">strided access</a></a></li>
</ul></li>
</ul></li>
</ul>
</nav>

      
    </div>
    

    <main class="col-12 col-md-9 col-xl-8 py-md-3 pl-md-5 docs-content" role="main">

      <article class="article" itemscope itemtype="http://schema.org/Article">

        <div class="docs-article-container">
          <h1 itemprop="name">Practical CUDA</h1>

          <div class="article-style" itemprop="articleBody">
            

<ul>
<li>GPUs have 2-4x greater floating point and bandwidth peak for the watts

<ul>
<li>also for the $ if you buy enterprise gear</li>
<li>better for the $ if you buy gaming gear</li>
</ul></li>
<li>Step 1 is to assess workload and latency requirements</li>
</ul>

<p><img src="VecDot_CPU_vs_GPU_size.png" alt="" />
<img src="VecDot_CPU_vs_GPU_time.png" alt="" /></p>

<ul>
<li>Don&rsquo;t waste time with GPUs if

<ul>
<li>your problem size or time to solution requirements don&rsquo;t align</li>
<li>if the work you&rsquo;d like to move to the GPU is not a bottleneck</li>
<li>if the computation cost will be dwarfed by moving data to/from the GPU</li>
<li>often you need to restructure so that caller passes in data already on the device</li>
<li>can require nonlocal refactoring</li>
</ul></li>
<li>Almost never: pick one kernel at a time and move it to the GPU

<ul>
<li>DOE ACME/E3SM (to pick on one high-profile application) has basically done this for five years and it still doesn&rsquo;t help their production workloads so they bought a non-GPU machine
<br /></li>
</ul></li>
</ul>

<p><strong>Okay, okay, okay.  What if I have the right workload?</strong></p>

<h2 id="terminology-intro">Terminology/intro</h2>

<ul>
<li><a href="https://devblogs.nvidia.com/even-easier-introduction-cuda/" target="_blank">An even easier introduction to CUDA</a></li>

<li><p><a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#programming-model" target="_blank">CUDA Programming Model</a></p></li>

<li><p>On the CPU, we have a thread with vector registers/instructions</p></li>

<li><p>In CUDA, we write code inside a single vector lane (&ldquo;confusingly&rdquo; called a CUDA thread)</p></li>

<li><p>To get inside the lane, we launch a <strong>kernel</strong> from the CPU using special syntax</p>

<pre><code class="language-c">add&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;(N, x, y);
</code></pre>

<ul>
<li>needs to be compiled using <code>nvcc</code></li>
<li>Logically 1D/2D/3D rectangular tiled iteration space</li>
</ul></li>
</ul>

<p><img src="grid-of-thread-blocks.png" width="40%"></p>

<ul>
<li>There are <a href="https://en.wikipedia.org/wiki/CUDA#Version_features_and_specifications" target="_blank">many</a> constraints and limitations to the iteration &ldquo;grid&rdquo;</li>
</ul>

<p><img src="cuda-constraints.png" alt="" /></p>

<ul>
<li>Control flow for CUDA threads is nominally independent, but performance will be poor if you don&rsquo;t coordinate threads within each block.

<ul>
<li>Implicit coordination</li>
<li>Memory coalescing</li>
<li>Organize your algorithm to limit &ldquo;divergence&rdquo;</li>
<li>Explicit coordination</li>
<li>Shared memory</li>
<li><code>__syncthreads()</code></li>
<li>Warp shuffles</li>
</ul></li>
<li>We implement the kernel by using the <code>__global__</code> attribute

<ul>
<li>Visible from the CPU</li>
<li>Special <a href="https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#built-in-variables" target="_blank">built-in variables</a> are defined</li>
<li><code>gridDim</code></li>
<li><code>blockIdx</code></li>
<li><code>blockDim</code></li>
<li><code>threadIdx</code></li>
<li>There is also <code>__device__</code>, which is callable from other device functions</li>
<li>Can use <code>__host__ __device__</code> to compile two versions</li>
</ul></li>
</ul>

<p><img src="cuda_indexing.png" alt="" /></p>

<h4 id="how-does-this-relate-to-the-hardware">How does this relate to the hardware?</h4>

<ul>
<li>Each thread block is assigned to one streaming multiprocessor (SM)</li>
<li>Executed in warps (number of hardware lanes)</li>
<li>Multiple warps (from the same or different thread blocks) execute like hyperthreads</li>
</ul>

<h2 id="practical-cuda">Practical CUDA</h2>

<p><img src="https://images.dailykos.com/images/201610/story_image/Question_authority_says_who_Capture.PNG?1454006844" alt="" /></p>

<h3 id="cuda-best-practices-guide-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html"><a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html" target="_blank">CUDA Best Practices Guide</a></h3>

<h4 id="occupancy">Occupancy</h4>

<blockquote>
<p>Thread instructions are executed sequentially in CUDA, and, as a result, executing other warps when one warp is paused or stalled is the only way to hide latencies and keep the hardware busy. Some metric related to the number of active warps on a multiprocessor is therefore important in <strong>determining how effectively the hardware is kept busy</strong> [emphasis added]. This metric is occupancy.</p>
</blockquote>

<ul>
<li>Reality: occupancy is just one aspect, and often inversely correlated with keeping the hardware busy (and with performance).</li>
</ul>

<blockquote>
<p>Occupancy is the ratio of the number of active warps per multiprocessor to the maximum number of possible active warps.</p>
</blockquote>

<ul>
<li>If your kernel uses fewer registers/less shared memory, more warps can be scheduled.</li>

<li><p>Register/shared memory usage is determined by the compiler.</p>

<pre><code class="language-python">def render_c(filename):
from IPython.display import Markdown
with open(filename) as f:
    contents = f.read()
return Markdown(&quot;```c\n&quot; + contents + &quot;```\n&quot;)

render_c('add.cu')
</code></pre>

<pre><code class="language-c">__global__ void add(int n, float *x, float *y) {
int index = blockIdx.x * blockDim.x + threadIdx.x;
int stride = blockDim.x * gridDim.x;
for (int i = index; i &lt; n; i += stride)
y[i] += x[i];
}
</code></pre>

<pre><code class="language-python">! nvcc -arch sm_75 --resource-usage -c add.cu
</code></pre>

<p>ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &lsquo;<em>Z3addiPfS</em>&rsquo; for &lsquo;sm_75&rsquo;
ptxas info    : Function properties for <em>Z3addiPfS</em>
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 12 registers, 376 bytes cmem[0]</p>

<pre><code class="language-python">render_c('copy.cu')
</code></pre>

<pre><code class="language-c">__global__ void copy(float *dst, float *src) {
int iblock = blockIdx.x + blockIdx.y * gridDim.x;
int index  = threadIdx.x + TILE_SIZE * iblock * blockDim.x;
float a[TILE_SIZE]; // allocated in registers
for (int i=0; i&lt;TILE_SIZE; i++)
a[i] = src[index + i * blockDim.x];
for (int i=0; i&lt;TILE_SIZE; i++)
dst[index + i * blockDim.x] = a[i];
}
</code></pre>

<pre><code class="language-python">! nvcc -arch sm_75 --resource-usage -DTILE_SIZE=16 -c copy.cu
</code></pre>

<p>ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &lsquo;<em>Z4copyPfS</em>&rsquo; for &lsquo;sm_75&rsquo;
ptxas info    : Function properties for <em>Z4copyPfS</em>
    0 bytes stack frame, 0 bytes spill stores, 0 bytes spill loads
ptxas info    : Used 64 registers, 368 bytes cmem[0]</p></li>

<li><p>The <a href="https://docs.nvidia.com/cuda/cuda-occupancy-calculator/index.html" target="_blank">Occupancy Calculator</a> can compute occupancy based on the register and shared memory usage.</p></li>

<li><p>You can tell the compiler to reduce register usage, sometimes at the expense of spills.</p>

<pre><code class="language-python">! nvcc -arch sm_75 --resource-usage -DTILE_SIZE=16 --maxrregcount 24 -c copy.cu
</code></pre>

<p>ptxas info    : 0 bytes gmem
ptxas info    : Compiling entry function &lsquo;<em>Z4copyPfS</em>&rsquo; for &lsquo;sm_75&rsquo;
ptxas info    : Function properties for <em>Z4copyPfS</em>
    80 bytes stack frame, 76 bytes spill stores, 76 bytes spill loads
ptxas info    : Used 24 registers, 368 bytes cmem[0]</p></li>
</ul>

<h4 id="further-reading">Further reading</h4>

<ul>
<li>Vasily Volkov (2010) <a href="https://www.nvidia.com/content/GTC-2010/pdfs/2238_GTC2010.pdf" target="_blank"><strong>Better Performance at Lower Occupancy</strong></a> (slides)</li>
<li>Vasily Volkov (2016) <a href="https://www2.eecs.berkeley.edu/Pubs/TechRpts/2016/EECS-2016-143.pdf" target="_blank"><strong>Understanding Latency Hiding on GPUs</strong></a> (very in-depth)</li>
<li>Kasia Swirydowicz (2018) <a href="https://www.paranumal.com/single-post/2018/03/02/Finite-Element-Stiffness-Matrix-Action-monolithic-kernel-optimization-on-Titan-V" target="_blank"><strong>Finite Element Stiffness Matrix Action: monolithic kernel optimization on Titan V</strong></a></li>
</ul>

<h3 id="memory">Memory</h3>

<ul>
<li>GPU memory is not CPU memory</li>
</ul>

<p><img src="https://en.wikichip.org/w/images/4/47/summit_single-socket.svg" width="50%"></p>

<p><strong>Duh</strong>, so why does NVIDIA <a href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/" target="_blank">publish this</a>?</p>

<p><img src="https://devblogs.nvidia.com/wp-content/uploads/2017/06/Unified-Memory-MultiGPU.png" alt="" /></p>

<h4 id="getting-your-memory-into-position-is-often-the-hardest-part-of-cuda-programming">Getting your memory into position is often the hardest part of CUDA programming.</h4>

<ul>
<li><p>Allocate memory on the GPU</p>

<pre><code class="language-c">cudaMalloc(&amp;xdevice, N*sizeof(double));
</code></pre></li>

<li><p>Populate it from the host</p>

<pre><code class="language-c">cudaMemcpy(xdevice, xhost, N*sizeof(double), cudaMemcpyHostToDevice);
</code></pre></li>

<li><p>Repeat for all data, including control parameters</p></li>

<li><p>Easy to forget, ongoing maintenance/complexity cost</p></li>
</ul>

<h4 id="unified-managed-memory-https-devblogs-nvidia-com-unified-memory-cuda-beginners"><a href="https://devblogs.nvidia.com/unified-memory-cuda-beginners/" target="_blank">Unified/managed memory</a></h4>

<ul>
<li><p>Allocate &ldquo;managed&rdquo; memory, accessible from CPU and GPU</p>

<pre><code class="language-c">cudaMallocManaged(&amp;x, N*sizeof(float));
</code></pre></li>

<li><p>How?</p></li>
</ul>

<p><img src="maximizing-unified-memory.png" width="50%"></p>

<ul>
<li>With OpenACC, make all dynamic allocations in managed memory: <code>pgcc -ta=tesla:managed</code>

<ul>
<li>The GPU probably has a lot less memory than you have DRAM</li>
<li>Really convenient for incremental work in legacy code</li>
<li>Performance isn&rsquo;t great without <code>cudaMemPrefetchAsync</code>
<br /></li>
</ul></li>
</ul>

<p><img src="pngbase6479f3c9825c97fa94.png" alt="" /></p>

<p><strong>Further reading</strong>: <a href="https://devblogs.nvidia.com/maximizing-unified-memory-performance-cuda/" target="_blank">Maximizing Unified Memory Performance in CUDA</a></p>

<h3 id="on-memory-coalescing-and-strided-access-https-docs-nvidia-com-cuda-cuda-c-best-practices-guide-index-html-strided-accesses">On memory coalescing and <a href="https://docs.nvidia.com/cuda/cuda-c-best-practices-guide/index.html#strided-accesses" target="_blank">strided access</a></h3>

<pre><code class="language-c">__global__ void strideCopy(float *odata, float* idata, int stride) {
    int xid = (blockIdx.x*blockDim.x + threadIdx.x)*stride;
    odata[xid] = idata[xid];
}
</code></pre>

<p><img src="adjacent-threads-accessing-memory-with-stride-of-2.png" alt="" /></p>

<p>Lose half your bandwidth for <code>stride=2</code>.</p>

<p><img src="performance-of-stridecopy-kernel.png" alt="" /></p>

          </div>

          



          
          <div class="article-widget">
            
<div class="post-nav">
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="/fall2019/openmp-target/" rel="next">ISPC, OpenMP target, OpenACC, and all that</a>
  </div>
  
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="/fall2019/cuda/" rel="prev">GPUs and CUDA</a>
  </div>
  
</div>

          </div>
          
        </div>

        <div class="body-footer">
          <p>Last updated on Nov 1, 2019</p>

          
<p class="edit-page">
  <a href="https://github.com/cucs-hpsc/hpsc-class/edit/master/content/fall2019/cuda-practical/index.md">
    <i class="fas fa-pen pr-2"></i>Edit this page
  </a>
</p>



          

        </div>

      </article>

      <footer class="site-footer">
  

  <p class="powered-by">
    

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
  </p>
</footer>


    </main>
  </div>
</div>


      

    
    
    
    <script src="/js/mathjax-config.js"></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mermaid/8.0.0/mermaid.min.js" integrity="sha256-0w92bcB21IY5+rGI84MGj52jNfHNbXVeQLrZ0CGdjNY=" crossorigin="anonymous" title="mermaid"></script>
      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/highlight.min.js" integrity="sha256-aYTdUrn6Ow1DDgh5JTc3aDGnnju48y/1c8s1dgkYPQ8=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/r.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/python.min.js"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.15.6/languages/c.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.2.0/leaflet.js" integrity="sha512-lInM/apFSqyy1o6s89K4iQUKg6ppXEgsVxT35HbzUupEVRh2Eu9Wdl4tHj7dZO0s1uvplcYGmt3498TtHq+log==" crossorigin="anonymous"></script>
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    
    
    <script>
      const search_index_filename = "/index.json";
      const i18n = {
        'placeholder': "Search...",
        'results': "results found",
        'no_results': "No results found"
      };
      const content_type = {
        'post': "Posts",
        'project': "Projects",
        'publication' : "Publications",
        'talk' : "Talks"
        };
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.1/anchor.min.js" integrity="sha256-pB/deHc9CGfFpJRjC43imB29Rse8tak+5eXqntO94ck=" crossorigin="anonymous"></script>
    <script>
      anchors.add();
    </script>
    

    
    
    <script id="search-hit-fuse-template" type="text/x-template">
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script>
    

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js" integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js" integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin="anonymous"></script>
    

    
    

    
    

    
    
    
    
    
    
    
    
    
      
    
    
    
    
    <script src="/js/academic.min.16bbb3750feb7244c9bc409a5a4fe678.js"></script>

    






  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
